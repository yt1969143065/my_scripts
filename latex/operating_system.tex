\documentclass{book}
\newcommand {\kw}  [1] {\textbf{#1}}
\newcommand {\www} [1] {\texttt{#1}}
\newcommand {\sys} [1] {\textsl{#1}}
\newcommand {\cmd} [1] {\texttt{#1}}
%\newcommand {\cmd} [1] {{\color{Blue}#1}}
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frontmatter
\chapter{Preface}
Most books on operating systems are strong on thoery and weak on practice. 
This one aims to provide a better balance between the two.
It covers all the fundamental principles in great detail, 
including processes, interprocess communication, semaphores, monitors, message passing, 
scheduling algorithms, input/output, deadlocks, device driver, memory management, paging algorithms,
file system design, security, and protection mechanisms.
But it also discusses one particular system MINIX 3, a UNIX-compatible operating system in detail, 
and even provides a source code listing for study.
This arrangement allows the reader not only to learn the principles, but also to see how they are applied in a real operating system.

When the first edition of this book appeared in 1987, it caused something of a small revolution in the way operating systems coursed were taught.
Untill then, most courses just covered theory.
With the appearance of MINIX, 
many schools began to have laboratory courses in which students examined a real operating system to see how it worked inside.
We consider this trend highly desirable and hope it continues.

In its first 10 years, MINIX underwent many changes.
The original code was designed for a 256K 8088-based IBM PC with two diskette drivers and no hard disk.
It was also based on UNIX Version 7. 
As time went on, MINIX evolved in many ways: it supported 32-bit protected mode machined with large memories and hard disks.
It also changed from being based on Version 7, to being based on the international POSIX standard (IEEE 1003.1 and ISO 9945-1).
Finally, many new features were added, perhaps too many in our view, but too few in the view of some other people, which led to the creation of Linux.
In addition, MINIX was ported to many other platforms, including the Macintosh, Amiga, Atari, and SPARC.
A second edition of the book, covering this system, was published in 1997 and was widely used at universities.

The popularity of MINIX has continued, as can be observed by examining the number of hits for MINIX found by Google.
 
This third edition of the book has many changes throughout.
Nearly all of the material on principles has been revised, and considerable new material has been added.
However, the main change is the discussion of the new version of the system, called MINIX 3, and the inclusion of the new code in this book.
Although loosely based on MINIX 2, MINIX 3 is fundamentally different in many key ways.

The design of MINIX 3 was inspired by the observation that operating system are becoming bloated, slow, and unreliable. 
They crash far more often than other electronic devices such as televisons, cell phones, and DVD players 
and have so many features and options that practically nobody can understand them fully or manage them well.
And of cource, computer viruses, worms, spyware, spam, and other forms of malware have become epidemic.

To a large extent, many of these problems are caused by a fundamental design flaw in current operating systems: their lack of modularity. 
The entire operating system is typically millions of lines of C/C++ code compiled into a single massive executable program run in kernrl mode.
A bug in any one of those millions of lines of code can cause the system to malfunction.
Getting all this code correct is impossible, especially when about 70\% consists of device drivers, written by third parties, 
and outside the purview of the people maintaining the operating system.

With MINIX 3, we demonstrate that this monolithic design is not the only possibility. 
The MINIX 3 kernel is only about 4000 lines of executable code, not the millions found in Windows, Linux, Mac OSX, or FreeBSD.
The rest of the system, including all the device drivers(except the clock driver), is a collection of small, modular, user-mode processes, 
each of which is tightly restricted in what it can do and with which other processes it may communicate.

While MINIX 3 is a work in progress, we believe that this model of building an operating system as a collection of highly-encapsulated user-mode 
processes holds promise for building more reliable system in the future.
MINIX 3 is especially focused on smaller PCs
(such as those commonly found in Third-World countries and on embedded systems, which are always resource constrained).
In any event, this design makes it much easier for students to lear how an operating system works than attempting to study a huge monolithic system.

The CD-ROM that is included in this book is a live CD. 
You can put it in your CD-ROM drive, reboot the computer, and MINIX 3 will give a login prompt within a few seconds. 
You can log in as root and give the system a try without first having to install it on your hard disk.
Of course, it can also be installed on the hard disk.
Detailed installation instructions are given in Appendix A.

As suggested above, MINIX 3 is rapidly evolving, with new versions being issued frequently.
To download the current CD-ROM image file for burning, please go to the offical Website: www.minix3.org.
This site also contains a large amount of new software, documentation, and news about MINIX 3 development.
For discussions about MINIX 3, or to ask questions, there is a USENET newsgroup: comp.os.minix.
People without newsreaders can follow discussions on the Web at http://groups.google.com/group/comp.os.minix.

As an alternative to installing MINIX 3 on your hard disk, it is possible to run it on any one of several PC simulators now available.
Some of these are listed on the main page of the Website.

Instructors who are using the book as the text for a university course can get the problem solutions from their local Prentice Hall representative. 
The book has its own Website.
It can be found by going to www.prenhall.com/tanenbaum and selecting this title.

We have been extremely fortunate in having the help of many people during the course of this project.
First and foremost, Ben Gras and Jorrit Herder have done most of the programming of the new version.
They did a great job under tight time constraints, including responding to e-mail well after midnight on many occasions. 
They also read the manuscript and made many useful comments.
Our deepest appreciation to both of them.

Kees Bot also helped greatly with previous versions, giving us a good base to work with.
Kees wrote large chunks of code for versions up to 2.0.4, repaired bugs, and answered numerous questions.
Philip Homburg wrote most of the networking code as well as helping out in numerous other useful ways, 
especially providing detailed feedback on the manuscript.

People too numerous to list contributed code to the very early versions, helping to get MINIX off the ground in the first place.
There were so many of them and their contributions have been so varied that we cannot even begin to list them all here,
so the best we can do is a generic thank you to all of them.

Several people read parts of the manuscript and made suggestions.
We would like to give our special thanks to Gojko Babic, Michael Crowley, Joseph M. Kizza, Sam Kohn Alexander Manov, and Du Zhang for their help.

Finally, we would like to thank our families. 
Suzanne has been through this 16 times now. 
Barbara has been through it 15 times now.
Marvin has been through it 14 times now.
It's kind of getting to be routine, but the love and support is still much appreciated.(AST)

AI's Barbara has been through this twice now.
Her support, patience, and good humor were essential.
Gordon has been a patient listener.
It is still a delight to have a son who understands and cares about the things that fascinate me.
Finally, step-grandson Zain's first birthday coincides with the release of MINIX 3.
Some day he will appreciate this.(ASW)

Andrew S. Tanenbaum

Albert S. Woodhull


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter
\chapter{Introduction}
Without its software, a computer is basically a useless lump of metal.
With its software, a computer can store, process, and retrieve information; 
play music and videos; send e-mail, search the Internet; and engage in many other valuable activities to earn its keep.
Computer software can be divided into two kinds: system programs, which manage the operation of the computer itself, 
and application programs, which perform the actual work the user wants.
The most fundamental system program is the \kw{operating system}, whose job is to control all the computer's resources and 
provide a base upon which the application programs can be written.
Operating systems are the topic of this book.
In particular, an operating system called MINIX 3 is used as a model, to illustrate design principles and the realities of implementing a design.

A modern computer system consists of one or more processors, some main memory, disks, 
printers, a keyboard, a display, network interfaces, and other input/output devices. 
All in all, a complex system.
Writing programs that keep track of all these components and use them correctly, let alone optimally, is an extremely difficult job.
If every programmer had to be concerned with how disk drives work, and with all the dozons of things that could go wrong when reading a disk block, 
it is unlikely that many programs could be written at all.

Many years ago it became abundantly clear that some way had to be found to shield programmers from the complexity of the hardware.
The way that has evolved gradually is to put a layer of software on top of the bare hardware, 
to manage all parts of the system, and present the user with an interface or \kw{virtual machine} that easier to understand and program.
This layer of software is the operating system.

The placement of the operating system is shown in Fiq. 1-1.
At the bottom is the hardware, which, in many cases, is itself composed of two or more levels (or layers).
The lowest level contains physical devices, consisting of integrated circuit chips, wires, power supplies, cathode ray tubes, and similar physical devices.
How these are constructed and how they work is the province of the electrical engineer.

Next comes the \kw{microarchitecture level}, in which the physical devices are grouped together to form functional units.
Typically this level contains some registers internal to the CPU (Central Processing Unit) and a data path containing an arithmetic logic unit.
In each clock cycle, one or two operands are fetched from the registers and combined in the arithmetic logic unit 
(for example, by addition or Boolean AND) .
The result is stored in one or more registers.
On some machines, the operation of the data path is controlled by software, called \kw{microprogram}.
On the other machines, it is controlled directly by hardware circuits.

The purpose of the data path is to execute some set of instructions.
Some of these can be carried out in one data path cycle; others may require multiple data path cycles.
These instructions may use registers or other hardware facilities.
Together, the hardware and instructions visible to an assembly language programmer form the \kw{ISA (Instruction Set Architecture)}.
This level is often called \kw{machine language}.

The machine language typically has between 50 and 300 instructions, mostly for moving data around the machine, doing arithmetic, and comparing values.
In this level, the input/output devices are controlled by loading the values into special \kw{device registers}.
For example, a disk can be commanded to read by loading the values of the disk address, main memory address, byte count, 
and direction (read or write) into its registers.
In practice, many more parameters are needed, and the status returned by the device after an operation may be complex.
Furthermore, for many I/O (Input/Output) devices, timing plays an important role in the programming.

A major function of the operating system is to hide all this complexity and give the programmer a more conveninent set of instructions to work with.
For example, read block from file is conceptually much simple than having to worry about the details of moving disk heads, 
waiting for them to settle down, and so on.

On top of the operating system is the rest of the system software.
Here we find the command interpreter (shell), window system, compilers, editors, and similar application-independent programs.
It is important to realize that these programs are definitely not part of the operating system, 
even though they are typically supplied preinstalled by the computer manufacturer, 
or in a package with the operating system if it is installed after purchase.
This is a crucial, but subtle, point.
The operating system is (usaully) that portion of the software that run in \kw{kernel mode} or \kw{supervisor mode}.
It is protected from user tampering by the hardware 
(ignoring for the moment some older or low-end microprocessors that do not have hardware protection at all).
Compilers and editors run in \kw{user mode}.
If a user does not like a particular compiler, he is free to write his own if he so chooses; 
he is not free to write his own clock interrupt handler, which is part of the operating system 
and is normally protected by hardware against attempts by user to modify it.

This distinction, however, is sometimes blurred in embedded systems (which may not have kernel mode) 
or interpreted systems (such as Java-based systems that use interpretation, not hardware , to seperate the components).
Still, for traditional computers, the operating system is what runs in kernel mode.

That said, in many systems there are programs that run in user mode but which help the operating sytem or perform privileged functions.
For example, there is often a program that allows users to change their passwords.
This program is not part of the operating system and does not run in kernel mode, but it clearly carries out a sensitive function 
and has to be protected in a specail way.

In some systems, including MINIX 3, this idea is carried to an extreme form, 
and pieces of what is traditionally considered to be the operating system (such as the file system) run in user space.
In such systems, it is difficult to draw a clear boundary.
Everything runing in kernel mode is clearly part of the operating system, 
but some programs running outside it are arguably also part of it, or at least closely associated with it.
For example, in MINIX 3, the file system is simply a big C program running in uer-mode.

Finally, above the system programs come the application programs.
These programs are purchased (or written by) the user to solve their particular problems, 
such as word processing, spreadsheets, engineering calculations, or storing information in a database.

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{What Is an Operating System?}
Most computer users have had some experience with an operating system, but it is difficult to pin down precisely what an operating system is.
Part of the problem is that operating systems perform two basically unreleated functions, extending the machine and managing resources, 
and depending on who is doding the talking, you hear mostly about one function or the other.
Let us now look at both.

\subsection{The Operating System as an Extended Machine}
As mentioned earlier, the architecture (instruction set, memory organization, I/O, and bus structure) of most computers 
at the machine language level is primitive and awkward to program, especially for input/output.
To make this point more concrete, let us briefly look at how floppy disk I/O is done 
using the NEC PD765 compatible controller chips used on many Intel-based personal computers.
(Throughout this book we will use the term``floppy disk'' and ``diskette'' interchangeably.)
The PD765 has 16 commands, each specified by loading between 1 and 9 bytes into a device register.
Those commands are for reading and writing data, moving the disk arm, and formatting tracks, 
as well as initializing, sensing, resetting, and recalibrating the controller and the drives.

The most basic commands are read and write, each of which requires 13 parameters, packed into 9 bytes.
These parameters specify such items as the address of the disk block to be read, the number of sectors per track, 
the recording mode used on the physical medium, the intersector gap spacing, and what to do with a deleted-data-address-mark.
If you do not understand this mumbo jumbo, do not worry; that is precisely the pointit is rather esoteric.
When the operation is completed, the controller chip returns 23 status and error fields packed into 7 bytes.
As if this were enough, the floppy disk programmer must also be constantly aware of whether the motor is on or off.
If the motor is off, it must be turned on (with a long startup delay) before data can be read or write.
The motor cannot be left on too long, however, or the floppy disk will wear out.
The programmer is thus forced to deal with the trade-off between long startup delays versus wearing out floppy disks (and losing the data on them).

Without going the real details, it should be clear that the average programmer probably does not want to 
get too intimately involved with the programming of floppy disks (or hard disks, which are just as complex and quite different).
Instead, what the programmer wants is a simple, highlevel abstraction to deal with.
In the case of disks, a typical abstraction would be that the disk contains a collection of named files.
Each file can be opened for reading or writing, then read or written, and finally closed.
Details such as whether or not recording should use modified frequency modulation and 
what the current state of the motor is should not appear in the abstraction presented to the user.

The program that hides the truth about the hardware from the programmer and 
presents a nice, simple view of named files can be read and written is, of course, the operating system.
Just as the operating system shields the programmer from the disk hardware and presents a simple file-oriented interface, 
it also conceals a lot of unpleasant business concerning interrupts, timers, memory management, and other low-level features.
In each case, the abstraction offered by the operating system is simpler and easier to use than that offered by the underlying hardware.

In this view, the function of the operating system is to present the user with the equivalent of an \kw{extended machine} or \kw{virtual machine} 
that is easier to program than the underlying hardware.
How the operating system achives this goal is a long story, which we will study in detail throuout this book.
To summarize it in a nutshell, the operating system provides a variety of services 
that programs can obtain using special instructions called system calls.
We will examine some of the more common system calls later in this chapter.

\subsection{The Operating System as a Resource Manager}
The concept of the operating system as primarily providing its users with a convient interface is a top-down view.
An alternative, bottom-up, view holds that the operating system is there to manage all the pieces of a complex system. 
Modern computers consist of processors, memories, timers, disks, mice, network interfaces, printers, and a wide variety of other devices.
In the alternative view, the job of the operating system is to provide for an orderly and controlled allocation 
of the processors, memories, and I/O devices among the various programs competing for them.

Imagine what would happen if three programs running on some computer all tried to print their output simultaneously on the same printer.
The first few lines of printout might be from program 1, the next few from program 2, then some from program 3, and so forth.
The result would be chaos.
The operating system can bring order to the potential chaos by buffering all the output destined for the printer on the disk.
When one program is finished, the operating system can then copy its output from the disk file where it has been stored to the printer, 
while at the same time the other program can continue generating more output, 
oblivious to the fact that the output is not really going to the printer (yet).

When a computer (or network) has multiple users, the need for managing and protecting the memory, I/O devices, and other resources is even greater, 
since the users might otherwise interface with one another.
In addition, users often need to share not only hardware, but information (files, databases, etc.) as well.
In short, this view of the operating system holds that its primary task is to keep track of who is using which resource, 
to grant resource requests, to account for usage, and to mediate conflicting requests from different program and users.

Resource management includes multiplexing (sharing) resources in two ways: in time and in space.
When a resource is time multiplexed, different programs or users turns using it.
First one of them gets to use the resource, then another, and so on.
For example, with only one CPU and multiple programs that want to run on it, the operating system first allocates the CPU to one program, 
then after it has run long enough, another one gets to use the CPU, then another, and then eventually the first one again.
Determining how the resource is time multiplexed, who goes next,  and for how long is the task of the operating system.
Another example of time multiplexing is sharing the printer.
When multiple print jobs are queued up for printing on a single printer, a decision has to be made about which one is to be printed next.

The other kind of multiplexing is space multiplexing. 
Instead of the customers taking turns, each one gets part of the resource.
For example, main memory is normally divided up among several running programs, so each one can be resident at the same time 
(for example, in order to take turns using the CPU).
Assuming there is enough memory to hold multiple programs, 
it is more efficient to hold several programs in memory at once rather than give one of them all of it, 
especially if it only needs a small fraction of the total.
Of course, this raises issues of fairness, protection, and so on, and it is up to the operating system to solve them.
Another resource that is space multiplexed is the (hard) disk.
In many systems a single disk can hold files from many users at the same time.
Allocating disk space and keeping track of who is using which disk blocks is a typical operating system resource management task.

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{History of Operating Systems}
Operating systems have been evolving through the years.
In the following sections we will breifly look at a few of the highlights.
Since operating systems have historically been closely tied to the architecture of the computers on which they run, 
we will look at successive generations of computers to see what their operating systems were like.
This mapping of operating system generations to computer generations is crude, but it dose provide some structure where there would otherwise be none.

The first true digital computer was designed by the English mathematician Charles Babbage(1792-1871).
Although Babbage spent most of his life and fortune trying to build his ``analytical engine'', 
he never got it working properly because it was purely mechanical, 
and the technology of his day could not produce the required wheels, gears, and cogs to the high precision that he needed.
Needless to say, the analytical engine did not have an operating system.

As an intersting historical aside, Babbage realized that he would need software for his analytical engine, 
so he hired a young woman naned Ada Lovelace, who was the daughter of the famed British poet Lord Byron, as the world's first programmer.
The programming language Ada was named after her.

\subsection{The First Generation(194555) Vacuum Tubes and Plugboards}
After Babbage's unsuccessful efforts, little progress was made in constructing digital computers untill World War II.
Around the mid-1940s, Howard Aiken at Harvard University, John Von Neumann at the Institute for Advanced Study in Princeton, 
J. Presper Eckert and John Mauchley at the University of Pennsylvania, and Konrad Zuse in Germany, 
among others, all succeeded in building caculating engines.
The first ones used mechanical relays but were very slow, with cycle times measured in seconds.
Relays were later replaced by vacuum tubes.
These machines were enormous, filling up entire rooms with tens of thousands of vacuum tubes, 
but they were still millions of times slower than even the cheapest personal computers available today.

In these early days, a single group of people designed, built, programmed, operated, and maintained each machine.
All programming was done in absolute machine language, often by wiring up plugboards to control the machine's basic functions.
Programming languages were unknown (even assembly language was unknow).
Operating systems were unheard of.
The usual mode of operation was for the programmer to sign up for a block of time on the signup sheet on the wall, 
then come down to the machine room, insert his or her plugboard into the computer, 
and spend the next few hours hoping that none of the 20,000 or so vacuum tubes would burn out during the run.
Virtually all the problems were straitforward numerical calculations, such as grinding out tables of sines, cosines, and logarithms.

By the early 1950s, the routine had improved somewhat within the introduction of punched cards.
It was now possible to write programs on card and read them in instead of using plugboards; otherwise, the procedure was the same.

\subsection{The Second Generation(195565) Transistors and Batch Systems}
The introduction of the transistor in the mid-1950s changed the picture radically.
Computers became reliable enough that they could be manufactured and sold to paying customers with the expectation 
that they would continue to function long enough to get some useful work done.
For the first time, there was a clear separation between designers, builders, operators, programmers, and maintenance personnel.

These machines, now called \kw{mainframes}, were locked away in specially airconditioned computer rooms, 
with staffs of special-trained professional operators to run them.
Only big corporation or major government agencies or universities could afford their multimillion dollar price tags.
To run a \kw{job}(i.e., a program or set of programs), a programmer would first write the program on paper 
(in FORTRAN or possibly even in assembly language), then punch it on cards.
He would then bring the card deck down to the input room and hand it to one of the operators and go drink coffee untill the output was ready.

When the computer finished whatever job it was currently running, an operator would go over to the printer and tear off the output
and carry it over to the output-room, so that the programmer could collect it later. 
Then he would take one of the card decks that had been brought from the input room and read it in.
If the FORTRAN compiler was needed, the operator would have to get it from a file cabinet and read it in.
Much computer time was wasted while operators were walking around the machine room.

Given the high cost of the equipment, it is not surprising that people quickly looked for ways to reduce the wasted time.
The solution generally adopted was the \kw{batch system}.
The idea behind using a small (relatively) inexpensive computer, such as the IBM 1401, 
which was very good at reading cards, copying tapes, and printing output, but not at all good at numerical calculations.
Others, much more expensive machines, such as the IBM 7094, were used for the real computing.
This solution is show in Fig. 1-2.

After about an hour of collecting a batch of jobs, the tape was rewound and brought into the machine room, where it was mounted on a tape drive.
The operator then loaded a special program (the ancestor of today's operating system), which read the first job from tape and ran it.
The output was written onto a second tape, instead of being printed.
After each job finished, the operating system automatically read the next job from the tape and began running it.
When the whole batch was done, the operator removed the input and output tapes, replaced the input tape with the next batch, 
and brought the output tape to a 1401 for printing \kw{off line} (i.e., not connected to the main computer).

The structure of a typical input job is show in Fig. 1-3.
It started out with a \$JOB card, specifying the maximum run times in minutes, the account number to be charged, and the programmer's name.
Then came a \$FORTRAN card, telling the operating system to load FORTRAN compiler from the system tape.
It was followed by the program to be compiled, and then a \$LOAD card, directing the operating system to load the object program just compiled.
(Compiled programs were often written on scratch tapes and had to be loaded explicitly.)
Next came the \$RUN card, telling the operating system to run the program with the data following it.
Finally, the \$END card marked the end of the job.
These primitive control cards were the forerunners of modern job control language and command interpreters.

Large second-generation computers were used mostly for scientific and engineering calculations, 
such as solving the partial differential equations that often occur in physics and engineering.
They were largely programmed in FORTRAN and assembly labguage.
Typical operating systems were FMS (the Fortran Monitor System) and IBSYS, IBM'S operating system for the 7094.

\subsection{The Third Generation (19651980) ICs and Multiprogramming}
By the early 1960s, most computer manufactures had two distinct, and totally incompatible, product lines.
On the one hand there were the word-oriented, large-scale scientific computers, such as the 7094, 
which were used for numerical caculations in science and engineering.
On the other hand, there were the character-oriented, commercial computers, such as the 1401, 
which were widely used for tape sorting and printing by banks and insurance companies.

Developing, maintaining, and marketing two completely different product lines was expensive proposition for the computer manufactures.
In addition, many new computer customers initially needed a small machine but later outgrew it and wanted a bigger machine 
that had the same architectures as their current one so it could run all their old programs, but faster.

IBM attempted to solve both of these problems at a single stroke by introducing the System/360.
The 360 was a series of software-compatible machines ranging from 1401-size to much more powerful than the 7094.
The machines differed only in price and performance (maximum memory, processor speed, number of I/O devices permitted, and so forth).
Since all the machines had the same architecture and instruction set, programs written for one machine could run on all the others, at least in theory.
Furthermore, the 360 was designed to handle both scientific (i.e., numerical) and commertial computing.
Thus a single family of machines could satisfy the needs of all customers.
In subsequent years, IBM has come out with compatible successors to the 360 line, using more modern technology, 
known as the 370, 4300, 3080, 3090, and Z series.

The 360 was the first major computer line to use (small-scale) Integrated Circuits (ICs), 
thus providing a major price/performance advantage over the second-generation machines, which were built up from individual transistors.
It was an immediate success, and the idea of a family of compatible cpmputers was soon adopted by all the other major manufactures.
The descendants of these machines are still use at computer centers today.
Nowadays they are often used for managing huge databases (e/g., for airline reservation systems) 
or as servers for World Wide Web sites that must process thousands of requests per second.

The greatest strenth of the ``one family'' idea was simultaneously its greatest weakness.
The intention was that all software, including the operating system, \kw{OS/360}, had to work on all models.
It had to run on small system, which often just replaced 1401s for copying cards to tape, 
and on very large systems, which often replaced 7094s for doing weather forecasting and other heavy computing.
It had to be good on systems with few peripherals and on systems with many peripherals.
It had to work in commercial environments and in scientific environments.
Above all, it had to be efficient for all of these different uses.

There was no way that IBM(or anybody else) could write a piece of software to meet all those conflicting requirements.
The result was an enormous and extraordinarily complex operating system, probably two to three orders of magnitude larger than FMS.
It consisted of millions of lines of assembly language written by thousands of programmers, 
and contained thousands upon thousands of bugs, which necessitated a continuous stream of new releases in an attempt to correct them.
Each new release fixed some bugs and introduced new ones, so the number of bugs probably remained constant in time.

One of the designers of OS/360, Fred Brooks, subsequently wrote a witty and incisive book describing his experiences with OS/360 (Brooks, 1995).
While it would be impossible to summarize the book here, suffice it to say that the cover shows a herd of prehistoric beasts stuck in a tar pit.
The cover of Silberschatz et al.(2004) makes a similar point about operating systems being dinosaurs.

Despite its enormous size and problems, OS/360 and the similar third-generation operating systems produced by other computer manufacturers 
actually satisfied most of their customers reasonably well.
They also popularized several key techniques absent in second-generation operating systems.
Probably the most important of these was \kw{multiprogramming}.
On the 7094, when the current job paused to wait for a tape or other I/O operation to complete, the CPU simply sat idle untill the I/O finished.
With heavily CPU-bound scientific caculations, I/O is infrequent, so this wasted time is not significant.
With commercial data processing, the I/O wait time can often be 80 or 90 percent of the total time, 
so something had to be done to avoid having the (expensive) CPU be idle so much.

The solution that evolved was to partition memory into several pieces, with different job in each partition, as shown in Fig. 1-4.
While one job was waiting for I/O to complete, another job could be using the CPU.
If enough jobs could be held in main memory at once, the CPU could be kept busy nearly 100 percent of the time.
Having multiple jobs safely in memory at once requires special hardware to protect each job against snooping and mischief by the other ones,
but the 360 and other third-generation systems were equipped with this hardware.

Another major feature present in third-generation operating systems was the ability to read jobs from cards onto the disk 
as soon as they were brought to the computer room.
Then, whenever a running job finished, the operating system could load a new job from the disk into the now-empty partion and run it.
This technique is called \kw{spooling} (from Simultaneous Peripheral Operation On Line) and was used for output.
With spooling, the 1401s were no longer needed, and much carrying of tapes disappeared.

Although third-generation operating systems were well suited for big scientific caculations and massive commercial data processing runs, 
they were still basically batch systems.
Many programmers pined for the first-generation days when they had the machine all to themselves for a few hours, 
so they could debug their programs quickly.
With third-generation systems, the time between submitting a job and getting back the output was often hours, 
so a single misplaced comma could cause compilation to fail, and the programmer to waste half day.

The desire for quick response time paved the way for \kw{timesharing}, a variant of multiprogramming, in which each user has an online terminal.
In a timesharing system, if 20 users are logged in and 17 of them are thinking or talking or drinking coffee, 
the CPU can be allocated in turn to the three jobs that want service.
Since people debugging programs usually issue short commands (e.g., compile a five-page procedure) 
rather than long ones (e.g., sort a million-record file), the computer can provide fast, 
interactive service to a number of users and perhaps also work on big batch jobs in the backgroud when the CPU is otherwise idle.
The first serious timesharing system, \kw{CTSS} (Compatible Time Sharing System), was developed at M.I.T. 
on a special modified 7094 (Corbato et al., 1962). 
However, timesharing did not really become popular until the necessary protection hardware became widespread during the third generation. 

After the success of the CTSS system, MIT, Bell Labs, and General Electric (then a major computer manufacturer) decided to embark on 
the development of a ``computer utility'', a machine that would support hundreds of simultaneous timesharing users.
Their model was the electricity distribution system:
when you need electric power, you just stick a plug in the wall, and within reason, as much power as you need will be there.
The designer of this system, known as \kw{MULTICS} (MULTiplexed Information and Computing Service), 
envisioned one huge machine providing computing power for everyone in the Boston area.
The idea that machines far more powerful than their GE-645 mainframe would be sold for under a thousand dollars by the millions only 30 years later 
was pure science fiction, like the idea of supersonic trans-Atlantic underse a trains would be now.

MULTICS was a mixed success.
It was designed to support hundreds of users on a machine only slightly more powerful than an Intel 80386-base PC,
although it had much more I/O capacity.
This is not quite as crazy as it sounds, since people knew how to write small, efficent programs in those days, a skill that has subsequntly been lost.
There were many reasons that MULTICS did not take over the world, not the least of which is that it was written in PL/I, 
and the PL/I compiler was years late and barely worked at all when it finally arrived.
In addition, MULTICS was enormously ambitious for its time, much like Charles Babbage's analytical engine in the nineteenth century.

MULTICS introduced many seminal ideas into the computer literature, 
but turning it into a serious products and commercial success was a lot harder than anyone had expected.
Bell Labs dropped out of the project, and General Electric quit the computer business altogether.
However, M.I.T. persisted and eventually got MULTICS working.
It was ultimately sold as a commertial product by the company that bought GE's computer business (Honeywell) 
and installed by about 80 major companies and universities worldwide.
While their numbers were small, MULTICS users were fiercely loyal.
General Motors, Ford, and the U.S. National Security Agency, for example, only shut down their MULTICS systems in the late 1990s.
The last MULTICS running, at the Canadian Department of National Defence, shut down in October 2000.
Despite its lack of commertial success, MULTICS had huge influence on subsequent operating systems.
A great deal of information about it exists 
(Corbato et al., 1972; Corbato and Vyssotsky, 1965; Daley and Dennis, 1968; Organick, 1972; and Saltzerm 1974).
It also has a still active Web site, \www{www.multicians.org}, with a great deal of information about the system, its designers, and its users.

The phrase ``computer utility'' is no longer heard, but the idea has gained new life in recent years.
In its simplest form, PCs or workstation (high-end PCs) in a business or a classroom 
may be connected via a \kw{LAN (Local Area Network)} to a \kw{file server} on which all programs and data are stored.
An administrator then has to install an protect only one set of programs and data, 
and can easily reinstall local software on a malfunctioning PC or workstation without worrying about retrieving or preserving local data.
In more heterogeneous environments, a class software called \kw{middleware} has evolved 
to bridge the gap betwwen local users and the files, programs, and databases they use on remote servers.
Middleware makes networked computers look local to individual users' PCs or workstations 
and presents a consistent user interface even though there may be a wide variety of different servers, PCs, and workstations in use.
The World Wide Web is an example.
A web brower presents documents to a user in a uniform way, and a document as seen on a user's brower can consist of next from one server 
and graphics from another server, presented in a format determined by a style sheet on yet another sever.
Businesses and universities commonly use a web interface to access databases and run programs on a computer in another building or even another city.
Middleware appears to be the operating system of a \kw{distributed system}, 
but it is not really an operating system at all, and is beyond the scope of this book.
For more on distributed systems see Tanenbaum and Van Steen (2002).

Another major development during the third generation was the phenomental growth of minicompputers, 
starting with the Digital Equipment Company (DEC) PDP-1 in 1961.
The PDP-1 had only 4K of 18-bit words, but at \$120,000 per machine (less than 5 percent of the price of a 7094), it sold like hotcakes.
For certain kinds of nonnumerical work, it was almost as fast as the 7094 and gave birth to a whole new industry.
It was quickly followed by a series of other PDPs (unlike IBM's family all incompatible) culminating in the PDP-11.

One of the computer scientists at Bell Labs who had worked on the MULTICS project, Ken Thompson, 
subsequently found a small PDP-7 minicomputer that no one was using and set out to write a stripped-down, one-user version of MULTICS.
This work later developed into the \kw{UNIX} operating system, which became popular in the academic world, 
with government agencies, and with many companies.

The history of UNIX has been told elsewhere (e.g., Salus, 1994).
Because the source code was widely available, various organizations developed their own (incompatible) versions, which lead to chaos.
Two major versions developed, \kw{System V}, from AT\&T, and \kw{BSD}, (Berkeley Software Distribution) from the University of California at Berkeley.
These had minor variants as well, now including FreeBSD, OpenBSD, and NetBSD.
To make it possible to write programs that could run on any UNIX system, IEEE developed a standard for UNIX, called \kw{POSIX},
that most versions of UNIX now support.
In fact, some other operating system now also support the POSIX interface.
The information needed to write POSIX-compliant software is available in books (IEEE, 1990; Lewine, 1991),
and online as the Open Group's ``Single UNIX Specification'' at \www{www.unix.org}.
Later in this chapter, when we refer to UNIX, we mean all of these systems as well, unless stated otherwise.
While they differ internally, all of them support the POSIX X standard, so to the programmer they are quite similar.

\subsection{The Fourth Generation (1980Present) Personal Computers}
With the development of LSI (Large Scale Integration) circuits, chips containing thousands of transistors on a square centimeter of silicon,
the age of the \kw{microprocessor}-based personal computer dawned.
In terms of architecture, personal computers (initially called \kw{microcomputers}) were not all that different from minicomputers of the PDP-11 class, 
but in terms of price they certainly were different.
The minicomputer made it possible for a department in a cpmpany or university to have its own computer.
The microcomputer made it possible for an individual to have his or her own computer.

There were several families of microcomputers.
Intel came out with the 8080, the first general-purpose 8-bit microprocessor, in 1974.
A number of companies produced complete systems using the 8080 (or the compatible Zilog Z80) 
and the \kw{CP/M} (Control Program for Microcomputers) operating system from a company called Digital Research was widely used with these.
Many application programs were written to run on CP/M, and it dominated the personal computing world for about 5 years.

Motorola also produced an 8-bit microprocessor, the 6800.
A group of Motorola engineers left to form MOS Technology and manufacture the 6502 CPU after Motorola rejected their suggested improvements to the 6800.
The 6502 was the CPU of several early systems.
One of these, the Apple II, became a major competitor for CP/M systems in the home and educational markets.
But CP/M was so popular that many owners of Apple II computers purchased Z-80 coprocessor add-on cards to run CP/M, 
since the 6502 CPU was not compatible with CP/M.
The CP/M cards were sold by little company called Microsoft, which also had a market niche supplying BASIC interpreters 
used by a number of microcomputers running CP/M.

The next generation of microprocessors were 16-bit systems.
Intel came out with the 8086, and in the early 1980s, IBM designed the IBM PC around Intel's 8088 (an 8086 on the inside, with an 8bit external data path).
Microsoft offered IBM a package which included Microsoft's BASIC and an operating system, 
\kw{DOS} (Disk Operating System) originally developed by another company.
Microsoft bought the product and hired the original author to improve it.
The revised system was renamed \kw{MS-DOS} (MicroSoft Disk Operating System) and quickly came to dominate the IBM PC market.

CP/M, MS-DOS, and the Apple DOS were all command-line systems: user typed commands at the keyboard.
Years earlier, Doug Engelbart at Stanford Research Institute had invented the \kw{GUI (Graphical User Interface)}, pronounced ``gooey'', 
complete with windows, icons, menus, and mouse.
Apple's Steve Jobs saw the possibility of a truly \kw{user-friendly} personal computer 
(for users who knew nothing about computers and did not want to learn), and the Apple Macintosh was announced in early 1984.
It used Motorola's 16-bit 68000 CPU, and had 64KB of \kw{ROM (Read Only Memory)}, to support the GUI.
The Macintosh has envolved over the years.
Subsequent Motorola CPUs were true 32-bit systems, and later still Apple moved to IBM PowerPC CPUs, with RISC 32-bit (and later, 64-bit) architecture.
In 2001 Apple made a major operating system change, releasing \kw{Mac OS X}, with a new version of the Macintosh GUI on top of Berkeley UNIX.
And in 2005 Apple announced that it would be switching to Intel processors.

To compete with the Macintosh, Microsoft invented Windows.
Originally Windows was just a graphical environment on top of 16-bit MS-DOS (i.e., it was more like a shell than a true operating system).
However, current versions of Windows are descendant of Windows NT, a full 32-bit system, rewritten from scratch.

The other major contender in the personal computer world is UNIX (and its various derivatives).
UNIX is strongest on workstations and other high-end computers, such as network servers.
It is especially popular on machines powerd by high-performance RISC chips.
On Pentium-based computers, Linux is becoming a popular alternative to Windows for students and increasingly many corporate users.
(Throughout this book we will use the term ``Pentium'' to means the entire Pentium family, 
including the low-end Celeron, the high end Xeon, and compatible AMD microprocessors).

Although many UNIX users, especially experienced programmers, prefer a command-based interface to a GUI, 
nearly all UNIX systems support a windowing system called \kw{X Window} system developed at M.I.T.
This system handles the basic window management, allowing users to create, delete, move, and resize windows using a mouse.
Often a complete GUI, such as \kw{Motif}, is available to run on top of the X Window system 
giving UNIX a look and feel something like the Macintosh or Microsoft Windowns for those UNIX users who want such a thing.

An intresting development that began taking place during the mid-1980s is the growth of 
networks of personal computers running \kw{network operating systems} and \kw{distributed operating systems} (Tanenbauand Van Steen, 2002).
In a network operating system, the users are aware of the existence of multiple computers 
and can log in to remote machines and copy files from one machine to another.
Each machine runs its own local operating system and has its own local user (or users).
Basically, the machines are independent of one another.

Network operating systems are not fundamentally different from single-processor operating systems.
They obviously need a network interface controller and some low-level software to drive it, 
as well as programs to achieve remote login and remote file access, 
but these additions do not change the essential structure of the operating system.

A distributed operating system, in contrast, is one that appears to its users as a traditional uniprocessor system, 
even though it is composed of multiple processors.
The users should not be aware of where their programs are being run or where their files are located;
that should all be handled automatically and efficently by the operating system.

True distributed operating systems require more than just adding a little code to a uniprocessor operating system, 
because distributed and centralized systems differ in critical ways.
Distributed system, for example, often allow applications to run on several processors at the same time, 
thus requiring more complex processor scheduling algorithms in order to optimize the amount of parallelism.

Communication delays within the network often mean that these (and other) algorithms must run with incomplete, outdated, or even incorrect information.
This situation is radically different from a single-processor system in which the operating system has complete information about the system state.


\subsection{History of MINIX 3}
When UNIX was young (Version 6), the source code was widely available, under AT\&T license, and frequently studied.
John Lions, of the University of New South Wales in Australia, even wrote a little booklet describing its operation, line by line (Lions, 1996).
This booklet was used (with permission of AT\&T) as a text in many university operating system courses.

When AT\&T released Verion 7, it dimly began realize that UNIX was a valuable commercial product, 
so it issued Version 7 with a license that prohibited the source code from being studied in courses, 
in order to avoid endangering its status as a trade secret. 
Many universities complied by simply dropping the study of UNIX and teching only theory.

Unfortunately, teaching only theory leaves the student with a lopsided view of what an operating system is really like.
The theoretical topics that are usually covered in great detail in courses and books on operating systems, 
such as scheduling algorithms, are in practice not really that important. 
Subjects that really are important, such as I/O and file systems, are generally neglected because there is little about them.

To remedy this situation, one of the authors of this book (Tanenbaum) decided to write a new operating system from scratch 
that would be compatible with UNIX from the user's point of view,  but completely different on the inside.
By not using even one line of AT\&T code, this system avoided the licensing restrictions, so it could be used for class or individual study.
In this manner, readers could dissect a real operating system to see what is inside, just as biology students dissect frogs.
It was called \kw{MINIX} and was released in 1987 with its complete source code for anyone to study or modify.
The name MINIX stands for mini-UNIX because it is small enough that even a nonguru can understand how it works.

In addition to the advantage of eliminating the legal problems, MINIX had another advantage over UNIX.
It was written a decade after UNIX and was structured in a more modular way.
For instance, from the very first release of MINIX the file system and the memory manager 
were not part of the operating system at all but as user programs.
In the current release (MINIX 3) this modularization has been extended to the I/O device drivers, 
which (with the exception of the clock driver) all run as user programs.
Another difference is that UNIX was designed to be efficient; MINIX was designed to be readable 
(in as much as one can speak of any program hundreds of pages long as being readable).
The MINIX code, for example, has thousands of comments in it.

MINIX was originally designed for compatibility with Version 7 (V7) UNIX. Version 7 was used as the model because of its simplicity and elegance.
It is sometimes said that Version 7 was an improvement not only over all its predecessors, but also over all its successors.
With the advent of POSIX, MINIX began evolving toward the new standard, while maintaining backward compatibility with existing programs.
This kind of evolution is common in the computer industry, as no vendor wants to introduce a new system 
that none of its existing customers can use without great upheaval.
The version of MINIX described in this book, MINIX 3, is based on the POSIX standard.

Like UNIX, MINIX was written in the C programing language and intented to be easy to port to various computers.
The initial implementation was for the IBM PC.
MINIX was subsequently ported to several other platforms.
In keeping with the ``Small is Beautiful'' philosophy, MINIX originally did not even require a hard disk to run 
(in the mid-1980s hard disks were still an expensive novelty).
As MINIX grew in functionality and size, it eventually got the point that a hard disk was needed for PCs,
but in keeping with the MINIX philisophy, a 200-MB partion is sufficient (for embedded applications, no hard disk is required though).
In contrast, even small Linux systems require 500-MB of disk space, and several GB will needed to install common applications.

To the average user sitting at an IBM PC, running MINIX is similar to runing UNIX.
All of the basic programs, such as \sys{cat, grep, ls, make}, and the shell are present and perform the same functions as their UNIX counterparts. 
Like the operating system itself, all these utility programs have been rewritten completely from scratch by the author, 
his students, and some other dedicated people, with no AT\&T or other proprietary code.
Many other freely-distributable programs now exist, and in many cases these have been successfully ported (recompiled) on MINIX.

MINIX continued to develop for a decade and MINIX 2 was released in 1997, 
together with the second edition of this book, which described the new release.
The changes between Versions 1 and 2 were substantial (e.g., from 16-bit real mode on an 8088 using floppy disks 
to 32-bit protected mode on a 386 using a hard disk) but evolutionary.

Development continued slowly but systematically until 2004, when Tanenbaum became convinced the software was getting too bloated and unreliable
and decide to pick up the slightly-dormant MINIX thread again.
Together with his students and programmers at the Vrije University in Amsterdam, he produced MINIX 3,
a major redesign of the system, greatly restructuring the kernel, reducing its size, and emphasizing modularity and reliability.
The new version was intended both for PCs and embedded systems, where compactness, modularity, and reliability are crucial.
While some people in the group called for a completely new name, it was eventually decide to call it MINIX 3 
since the name MINIX was already well known.
By way of analogy, when Apple abandoned it own operating system, Mac OS 9 and replaced it with a variant of Berkeley UNIX, 
the name chosen was Mac OS X rather than APPLIX or something like that.
Similar fundamental changes have happened in the Windows family while retaining the Windows name.

The MINIX kernel is well under 4000 lines of executable code, compared to millions of executable lines of code for Windows, Linux, FreeBSD, and other operating systems.
Small kernel size is important because kernel bugs are far more devastating than bugs in user-mode programs and more code means more bugs.
One careful study has shown that the number of \sys{detected} bugs per 1000 executable lines of code varies from 6 to 16 (Basili and Perricone, 1984).
The actual number of bugs is probably much higher since the researchers could only count reported bugs, not unreported bugs.
Yet another study (Ostrand et al., 2004) showed that even after more than a dozen releases, on the average 6\% of all files contained bugs 
that were later reported and after a certain point the bug level tends to stabilize rather than go asymptotically to zero.
This result is supported by the fact that when a very simple, automated, model-checker was let loose on stable versions of Linux and Open BSD, 
it found hundreds of kernel bugs, overwhelmingly in device drivers (Chou et al., 2001; and Engler et al., 2001).
This is the reason the device drivers were moved out of the kernel in MINIX 3; they can do less damage in user mode.

Throughout this book MINIX 3 will be used as an example.
Most of the comments about the MINIX 3 system calls, however (as opposed to comments abount the actual code), also apply to other UNIX systems.
This remark should be kept in mind when reading the text.

A few words about Linux and its relationship to MINIX may possibly be of interest to some reader.
Shortly after MINIX released, a USENET newsgroup, \www{comp.os.minix}, was formed to discuss it.
Within weeks, it had 40,000 subscribers, most of whom wanted to add vast numbers of new features to MINIX 
to make it bigger and better (well, at least bigger).
Every day, several hundred of them offered suggestions, ideas, and frequently snippets of source code.
The author of MINIX was able to successfully resist this onslaught for several years, 
in order to keep MINIX clean enough for students to understand and small enough that it could run on computers that students could afford.
For people who thought little of MS-DOS, the existence of MINIX (with source code) as an alternative was even a reason fo finally go out and buy a PC.

One of these people was a Finnish student named Linus Torvalds.
Torvalds installed MINIX on his new PC and studied the source code carefully.
Torvalds wants to read USENET newsgroups (such as \www{comp.os.minix}) on his own PC rather than his university, 
but some features he needed were lacking in MINIX, so he wrote a program to do that, but soon discovered he needed a different terminal driver,
so he wrote that too.
Then he wanted to download and save postings, so he wrote a disk driver, and then a file system.
By Aug. 1991 he had produced a primitive kernel.
On Aug. 25, 1991, he announced it on \www{comp.os.minix}.
This announcement attracted other people to help him, and on March 13, 1994 Linux 1.0 was released.
Thus was Linux born.

Linux has become one of the notable successes of the \kw{open source} movement (which MINIX helped start).
Linux is challenging UNIX (and Windows) in many environments, partly because commodity PCs which support Linux are now available with performance that rivals the proprietary RISC systems required by some UNIX implementations.
Other open source software, notably the Apache Web server and the MySQL database, 
and the open source Perl and PHP programming labguages are often used together on Web servers and sometimes referred to by the acronym \kw{LAMP}.
For more on the history of Linux and open source software see DiBona et al. (1999), Moody (2001), and Naughton (2000).

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{Operating System Concepts}
The interface between the operating system and the user programs is defined by the set of ``extended instructions'' that the operating system provides.
These extended instructions have been traditionally known as \kw{system call}, although they can be implemented in several ways.
To really understand what operating system do, we must examine this interface closely.
The calls available in the interface vary from operating system to operating system (although the underlying concepts tend to be similar).

We are thus forced to make a choice between (1) vague generalities (``operating systems have system calls for reading files'')
and (2) some specific system (``MINIX 3 has a \cmd{read} system call with three parameters: 
one to specify the file, one to tell where the data are to be put, and one to tell how many bytes to read'').

We have chosen the latter approach.
It's more work that way, but it gives more insight into what operating systems really do.
In Sec. 1.4 we will look closely at the basic system calls present in UNIX (including the various version of BSD), Linux, and MINIX 3.
For simplicity's sake, we will refer only to MINIX 3, but the corresponding UNIX and Linux system calls are based on POSIX in most cases.
Before we look at the actual system calls, however, it is worth taking a bird's-eye view of MINIX 3, 
to get a general feel for what an operating system is all about.
this overview applies equally well to UNIX and Linux, as mentioned above.

The MINIX 3 system calls fall roughly in two broad categories: those dealing with processes and those dealing with the file system.
We will now examine each of these in turn.

\subsection{Processes}
A key concept in MINIX 3, and in all operating systems, is the \kw{process}.
A process is basically a program in execution.
Associated with each process is its \kw{address space}, a list of memory locations from some minimum (usually 0) to some maximum,
which the process can read and write.
The address space contains the executable program, the program's data, and its stack.
Also associated with each process is some set of registers, including the program counter, stack pointer, and other hardware registers, 
and all the other information needed to run the program.
 
We will come back to the process concept in much more detail in Chap. 2, but for the time being, 
the easiest way to get a good intuitive feel for a process is to think about multiprogramming systems.
Periodically, the operating system decides to stop running one process and start running another, for example, 
because the first one has had more than its share of CPU time in the past second.

When a process is suspended temporarily like this, it must later be restarted in exactly the same state it had when it was stopped.
This means that all information about the process must be explicitly saved somewhere during the suspension.
For example, the process may have several files open for reading at once.
Associated with each of these files is a pointer giving the current position (i.e., the number of the byte or record to be read next).
When a process is temporarily suspended, all these pointers must be saved so that 
a \cmd{read} call executed after the process is restarted will read the proper data.
In many operating systems, all the information about each process, other than the contents of its own address space, 
is stored in an operating system table called \kw{process table}, which is an array (or linked list) of structures, 
one for each process currently in existence.

Thus, a (suspended) process consists of its address space, usually called the \kw{core image} 
(in honor of the magnetic core memories used in days of yore),
and its process table entry, which contains its registers, among other things. 

The key process management system calls are those dealing with the creation and termination of processes.
Consider a typical example.
A process called the \kw{command interpreter} or \kw{shell} reads commands from a terminal.
The user has just typed a command requesting that a program be compiled.
The shell must now create a nre process that will run the compiler.
When that process has finished the compilation, it executes a system call to terminate itself.

On Windows and other operating systems that have a GUI, (double) clicking on a desktop icon launches a program in much the same way 
as typing its name at the command prompt.
Although we will not discuss GUIs much, they are really simple command interpreters.

If a process can create one or more other processes (usually referred to as \kw{child process}) and these processes in turn can create child processes, 
we quickly arrive at the process tree structure of Fig. 1-5.
Related processes that are cooperating to get some job done often need to communicate with one another and synchronize their activities.
This communication is called \kw{interprocess communication}, and will be addressed in detail in Chap. 2.

Other process system calls are available to request more memory (or release unused memory),
wait for a child process to terminate, and overlay its program with a different one.

Occasionally, there is a need to convey information to a running process that is not sitting around waiting for it.
For example, a process that is communicating with another process on a different computer does so 
by sending messages to the remote process over a network.
To guard against the possibility that a message or its reply is lost, the sender may request that its own operating system notify it 
after a specified number of seconds, so that it can retransmit the message if no acknowledgement has been received yet.
After setting this timer, the program may continue doing other work.

When the specified number of seconds has elapsed, the operating system sends an \kw{alarm signal} to the process.
The signal causes the process to temporarily suspend whatever it was doing, save its registers on the stack, 
and start running a special signal handling procedure, for example, to retransmit a presumably lost message.
When the signal handler is done, the running process is restarted in the state it was in just before the signal.
Signals are the software analog of hardware interrupts.
They are generated by a variety of causes in addition to timers expiring.
Many traps detected by hardware, such as executing an illegal instruction or using a invalid address, 
are also converted into signals to the guilty process.

Each person authorized to use a MINIX 3 system is assigned a \kw{UID} (User IDentification) by the system administrator.
Every process started has the UID of the person who started it.
The child process has the same UID as its parent.
Users can be members of groups, each of which has a \kw{GID} (Group IDentification).

One UID, called the \kw{superuser} (in UNIX), has special power and may violate many of the protection rules.
In large installations, only the system administrator knowns the password needed to become superuser, 
but many of the ordinary users (especially students) devote considerable effort to trying to find flaws in the system 
that allow them to become superuser without the password.

We will study processes, interprocess communication, and related issues in Chap. 2.

\subsection{Files}
The other broad category of system calls relates to the file system.
As noted before, a major function of the operating system is to hide the peculiarities of the disks and other I/O devices 
and present the programmer with a nice, clean abstract model of device-independent files.
System calls are obviously needed to create files, remove files, read files, and write files.
Before a file can be read, it must be opened, and after it has been read it should be closed, so calls are provided to do these things.

To provide a place to keep files, MINIX 3 has the concept of a \kw{directory} as a way of grouping files together.
A student, for example, might have one directory for each course he is taking (for the programs needed for that course),
another directory for his electronic mail, and still another directories for his World Wide Web home page.
System calls are then needed to create and remove directories.
Calls are also provided to put an existing file into a directory, and to remove a file from a directory.
Directory entries may be either file or other directories.
This model also gives rise to a hierarchy, the file systems shown in Fig. 1-6.

The process and file hierarchies both are organized as trees, but the similarity stops there.
Process hierarchies usually are not very deep (more than three levels is unusual), 
whereas file hierarchies are commonly four, five, or even more levels deep.
Process hierarchies are typically short-lived, generally a few minutes at most, 
whereas the directory hierarchy may exist fo years.
Ownership and protection also differ to processes and files.
Typically, only a parent process may control or even access a child process, 
but mechanisms nearly always exist to allow files and directories to be read by a wider group than just the owner.

Every file within the directory hierarchy can be specified by giving its \kw{path name} from the top of the directory hierarchy, the \kw{root directory}.
Such absolute path names consist of the list of directories that must be traversed from the root directory to get to the file, 
with slashes separating the components.
In Fig. 1-6, the path for file CS101 is \sys{/Faculty/Prof.Brown/Courses/CS101}.
The leading slash indicates that the path is absolute, that is, starting at the root directory.
As an aside, in Windows, the backslash(\textbackslash) character is used as the seperator instead of the slash (/) character, 
so the file path given above would be written as $\backslash$Faculty$\backslash$Prof.Brown$\backslash$Courses$\backslash$CS101.
Throughout this book we will use the UNIX convention for paths.

At every instant, each process has a current \kw{working directory}, in which path names not beginning with a slash are looked for.
As an example, in Fig. 1-6, if /Faculty/Prof.Brown were the working directory, 
then use of the path name Courses/CS101 would yield the same file as the absolute path name given above. 
Processes can change their working directory by issuing a system call specifying the new working directory.

Files and directories in MINIX 3 are protected by assigning each one an 11-bit binary protection code.
The protection code consists of three 3-bit fields: one for the ower, one for other members of the owner's group 
(users are divided into groups by the system administrator), one for everyone else, and 2 bits we will discuss later.
Each field has a bit for read access, a bit for write access, and a bit for execute access.
These 3 bits are known as the \kw{rwx bits}.
For example, the protection code \sys{rwxr-x--x} means that the ower can read, write, or execute the file, 
other group members can read or execute (but no write) the file, and everyone else can execute (but not read or write) the file.
For a directory (as opposed to a file), \sys{x} indicates search permission.
A dash means that the corresponding permission is absent (the bit is zero).

Before a file can be read or written, it must be opened, at which time the permissions are checked.
If access is permitted, the system returns a small integer called a \kw{file descriptor} to use in subsequent operations.
If the access is prohibited, an error code (1) is returned.

Another important concept in MINIX 3 is mounted file system.
Nearly all personal computers have one or more CD-ROM drives into which CD-ROMs can be inserted and removed.
To provide a clean way to deal with removable media (CD-ROMs, DVDs, floppies, Zip drives, etc.), 
MINIX 3 allows the file system on a CD-ROM to be attached to the main tree.
Consider the situation of Fig. 1-7(a).
Before the \cmd{mount} call, the \kw{root file system}, on the hard disk, and a second file system, on a CD-ROM, are separate and unrelated.
 
Hoever, the file system on the CD-ROM cannot be used, because there is no way to specify path names on it.
MINIX 3 does not allow path names to be prefixed by a drive name or number;
That is precisely the kind of device dependence that operating systems ought to eliminate.
Instead, the \cmd{mount} system call allows the file system on the CD-ROM to be attached to the root file system wherever the program wants it to be.
In Fig. 1-7(b) the file system on drive 0 has been mounted on directory b, thus allowing access to file \sys{/b/x} and \sys{/b/y}.
If directory \sys{/b} had originally contained any files they would not be accessible while the CD-ROM was mounted, 
since \sys{/b} would refer to the root directory of drive 0.
(Not being able to access these file is not as serious as it at first seems: file systems are nearly always mounted on empty directories.)
If a system contains multiple hard disks, they can all be mounted into a single tree as well.

Another important concept in MINIX 3 is the \kw{special file}.
Special files are provided in order to make I/O devices look like files.
That way, they can be read and written using the same system calls as are used for reading and writing files.
Two kinds of special files exist: \kw{block special files} and \kw{character special files}.
Block special files are normally used to model devices that consist of a collection of randomly addressable blocks, such as disks.
By opening a block special file and reading, say, block 4, a program can directly access the fourth block on the device, 
without regard to the structure of the file system contained on it.
Similarly, character special files are used to model printers, modems, and other devices that accept or output a character stream.
By convention, the special files are kept in the \sys{/dev} directory.
For example, \sys{/dev/lp} might be the line printer.

The last feature we discuss in this overview is one that relates to both processes and files: pipes.
A \kw{pipe} is a sort of pseudofile that can be used to connect two processes, as shown in Fig. 1-8.
If processes A and B wish to talk using a pipe, they must set it up in advance.
When process A wants to send data to process B, it writes on the pipe as though it were an output file.
Process B can read the data by reading from the pipe as though it were an input file.
Thus, communication between process in MINIX 3 looks very much like ordinary file reads and writes.
Stronger yet, the only way a process can discover that the output file it is writing on is not really a file, 
but a pipe, is by making a special system call.

\subsection{The Shell}
The operating system is the code that carries out the system calls.
Editors, compilers, assemblers, linkers, and command interpreters definitely are not part of the operating system, 
even though they are important and useful.
At the risk of confusing things somewhat, in this section we will look briefly at the MINIX 3 command interpreter, called the \kw{shell}.
Although it is not part of the operating system, it makes heavy use of many operating system features 
and thus serves as a good example of how the system calls can be used.
It is also the primary interface between a user sitting at his terminal and the operating system, 
unless the user is using a graphical user interface.
Many shell exist, including \sys{csh, zsh} and \kw{bash}.
All of them support the functionality described below, which derives from the original shell (\sys{sh}).

When any user logs in, a shell is started up.
The shell has terminal as standard input and standard output.
It starts out by typing the \kw{prompt}, a character such as a dollar sign, 
which tell the user that the shell is waiting to accept a command.
If the user types\\
\cmd{data}\\
for example, the shell creates a child process and runs the \sys{data} program as the child.
While the child process is running, the shell waits for it to terminate.
When the child finishes, the shell types the prompt again and tries to read the next input line.

The user can specify that standard output be redirected to a file, for example\\
\cmd{data >file}\\
Similarly, standard input can be redirected, as in\\
\cmd{sort <file1 >file2}\\
which invokes the sort program with input taken from \sys{file1} and output sent to \sys{file2}.

The output of one program can be used as the input for another program by connecting them with a pipe. Thus\\
\cmd{cat file1 file2 file3 | sort >/dev/lp}\\
invokes the \sys{cat} program to concatenate three files and send the output to \sys{sort} to arrange all the lines in alphabetical order.
The output of \sys{sort} is redirected to the file \sys{/dev/lp}, typically the printer.

If a user puts an ampersand after a command, the shell does not wait for it to complete.
Instead it just gives a prompt immediately. Consequently,\\
\cmd{cat file1 file2 file3 | sort >/dev/lp \&}\\
starts up the sort as a backgroud job, allowing the user to continue working normally while the sort is going on.
The shell has a number of other interesting features, which we do not have space to discuss here.
Most books for UNIX beginners are useful for MINIX 3 users who want to learn more about using the system.
Examples are Ray and Ray (2003) and Herborth (2005).

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{System Calls}
Armed with our general knowledge of how MINIX 3 deals with processes and files, 
we can now begin to look at the interface between the operating system and its application programs, that is, the set of system calls.
Although this discussion specially refers to POSIX (International Standard 9945-1), hence also to MINIX 3, UNIX, and Linux, 
most other modern operating systems have system calls that perform the same functions, even if the details differ.
Since the actual mechanics of issuing a system call are highly machine dependent, and often must be expressed in assembly code, 
a procedure library provided to make it possible to make system calls from C programs.

It is useful to keep the following in mind: any single-CPU computer can execute only one instruction at a time.
If a process is running a user program in user mode and needs asystem service, such as reading data from a file, 
it has to execute a trap or system call instruction to transfer control to the operating system.
The operating system then figures out what the calling process wants by inspecting the parameters.
Then it carries out the system call and returns control to the instruction following the system call.
In a sense, making a system call is like making a special kind of procedure call, 
only system calls enter the kernel or other privileged operating system components and procedure calls do not.

To make the system call machanism clearer, let us take a quick look at \cmd{read}.
It has three parameters: 
the first one specifying the file, the second one specifying the buffer, and the third one specifying the number of bytes to read.
A call to \cmd{read} from a C program might look like this:\\
\cmd{count = read(fd, buffer, nbytes);}\\
The system call (and the library procedure) return the number of bytes actually read in \sys{count}.
This value is normally the same as \sys{nbytes}, but may be smaller, if, for example, end-of-file is encountered while reading.

If the system call cannot be carried out, either due to an invalid parameter or a disk error, \sys{count} is set to 1, 
and the error number is put in a global variable, \sys{errno}.
Programs should always check the results of a system call to see if an error occurred.

MINIX 3 has a total of 53 main system calls.
These are listed in Fig. 1-9, grouped for convenience in six categories.
A few other calls exist, but they have very specialized uses so we will omit them here.
In the folloing sections we will briefly examine each of the calls of Fig. 1-9 to see what it does.
To a large extent, the services offered by these calls determine most of what the operating system has to do, 
since the resource management on personal computers is minimal (at least compared to big machines with many users).
\\
\\
\kw{Process management}\\
\cmd{pid = fork}()\\
Create a child process identical to the parent
\\
\cmd{pid = waitpid(pid, \$statloc, opts)}\\
Wait for a child to terminate
\\
\cmd{S = wait(\&status)}\\
Old version of waitpid
\\
\cmd{S = execve(name, argv, envp)}\\
Replace a process core image
\\
\cmd{exit(status)}\\
Terminate process execution and return status
\\
\cmd{size = brk(addr)}\\
Set the size of the data segment
\\
\cmd{pid = getpid()}\\
Return the caller's process id
\\
\cmd{pid = getpgrp()}\\
Return the id of the caller's process group
\\
\cmd{pid = setsid()}\\
Create a new session and return its proc. group id
\\
\cmd{| = ptrace(req, pid, addr, data)}\\
Used for debugging
\\
\\
\kw{Signals}\\
\cmd{S = sigaction(sig, \&act, \&oldact)}\\
Define action to take on signals
\\
\cmd{S = sigreturn(\&contex)}\\
Return from a signal
\\
\cmd{S = sigprocmask(how, \&set, \&old)}\\
Examine or change the signal mask
\\
\cmd{S = sigsuspend(sigmask)}\\
Replace the signal mask and suspend the process
\\
\cmd{S = kill(pid, sig)}\\
Send a signal to a process
\\
\cmd{residual = alarm(seconds)}\\
Set the alarm clock
\\
\cmd{S = pause()}\\
Suspend the caller until the next signal
\\
\\
\kw{File Mnagement}\\
\cmd{fd = creat(name, mode)}\\
Obsolete way to creat a new file
\\
\cmd{fd = mknod(name, mode, addr)}\\
Create a regular, special, or directory i-node
\\
\cmd{fd = open (file, how, ...)}\\
OPen a file for reading, writing, or both
\\
\cmd{S = close (fd)}\\
Close an open file
\\
\cmd{n = read (fd, buffer, nbytes)}\\
Read data from a file into a buffer
\\
\cmd{n = write (fd, buffer, nbytes)}\\
Write data from a buffer into a file
\\
\cmd{pos = lseek (fd, offset, whence)}\\
MOve the file pointer
\\
\cmd{S = stat (name, \&buf)}\\
Get a file's status information
\\
\cmd{S = fstat (fd, \&buf)}\\
Get a file's status information
\\
\cmd{fd = dup (fd)}\\
Allocate a new file descriptor for an open file
\\
\cmd{S = pipe (\&fd[0])}\\
Create a pipe
\\
\cmd{S = ioctl (fd, request, argp)}\\
Performance special operations on a file
\\
\cmd{S = rename (old, new)}\\
Give a file new name
\\
\cmd{S = fcntl(fd, cmd, ...)}\\
File locking and other operations
\\
\\
\kw{Dir. \& File System Mgt.}\\
\cmd{S = mkdir (name, mode)}\\
Create a new directory
\\
\cmd{S = rmdir (name)}\\
Remove an empty directory
\\
\cmd{S = link (name1, name2)}\\
Create a new entry, name2, pointing to name1
\\
\cmd{S = unlink (name)}\\
Remove a directory entry
\\
\cmd{S = mount (special, name, flag)}\\
Mount a file system
\\
\cmd{S = unmount (special)}
Unmount a file system
\\
\cmd{S = sync()}\\
Flush all cached blocks to the disk
\\
\cmd{S = chdir(dirname)}\\
Change the working directory
\\
\cmd{S = chroot (dirname)}\\
Change the root directory
\\
\\
\kw{Protection}\\
\cmd{S = chmod (name, mode)}\\
Change a file's protection bits
\\
\cmd{uid = getuid()}\\
Get the caller's uid
\\
\cmd{gid = getgid ()}\\
Get the caller's gid
\\
\cmd{S = setuid(uid)}\\
Set the caller's uid
\\
\cmd{S = setgid(gid)}\\
Set the caller's gid
\\
\cmd{S = chown(name, owner, group)}\\
Change a file's owner and group
\\
\cmd{oldmask = umask(complmode)}\\
Change the mode mask
\\
\\
\kw{Time Management}\\
\cmd{seconds = time (\&seconds)}\\
Get the elapsed time since Jan. 1, 1970
\\
\cmd{S = stime(tp)}\\
Set the elapsed time since Jan.1, 1970
\\
\cmd{S = utime(file, timep)}\\
Set a file's ``last access'' time
\\
\cmd{S = times (buffer)}\\
Get the user and system times used so far
\\

This is a good place to point out the mapping of POSIX procedure calls onto system calls is not necessarily one-to-one.
The POSIX standard specifies a number of procedures that a conformant system must supply, 
but it does not specify wether they are system calls, library calls, or something else.
In some cases, the POSIX procedures are supported as library routines in MINIX 3.
In others, several required procedures are only minor variations of one other, and one system call handles all of them.

\subsection{System Calls for Process Management}
The first group of calls in Fig. 1-9 deals with process management.
\cmd{Fork} is a good place to start the discussion.
\cmd{Fork} is the only way to create a new process in MINIX 3.
It creats an exact duplicate of the original process, including all the file descriptors, registers, everything.
After the \cmd{Fork}, the original process and the copy (the parent and child) go their seperate ways.
All the variables have identical values at the time of the \cmd{fork}, but since the parent's data are copied to create the child, 
subsequent changes in one of them do not affect the other one.
(The program text, which is unchangeable, is shared between parent and child.)
The \cmd{Fork} call returns a value, which is zero in the child and equal to the child's process identifier or \kw{PID} in the parent.
Using the returned PID, the two processes can see which one is the parent process and which one is the child process.

In most cases, after a \cmd{fork}, the child will need to execute different code from the parent.
Consider the shell.
It reads a command from the terminal, forks off a child process, waits for the child to execute the command, 
and then reads the next command when the child terminates.
To wait for the child finish, the parent executes a \cmd{waitpis} system call, 
which just waits until the child terminates (any child of more than one exists).
\cmd{Waitpid} can wait for a specific child, or for any old child by setting the first parameter to 1.
When \cmd{waitpid} completes, the address pointed by the second parameter, \sys{statioc}, 
will be set to the child's exit status (normal or abnormal termination and exit value).
Various options are provided, specified by the third parameter.
The \cmd{waitpid} call replaces the previous \cmd{wait} call, which is now obsolete but is provided for reasons of backward compatibility.

Now consider how \cmd{fork} is used by the shell.
When a command is typed, the shell forks off a new process.
This child process must execute the user command.
It does this by using the \cmd{execve} system call, which causes its entire core image to be replaced by the file named in its first parameter.
(Actually, the system call itself is \cmd{exec}, 
but several different library procedures call it with different parameters and slightly different names. 
We will treat these as system calls here.)
A highly simplified shell illustrating the use of \cmd{fork}, \cmd{waitpid}, and \cmd{execve} is shown in Fig. 1-10.

In the most general case, \cmd{execve} has three parameters: the name of the file to be executed, 
a pointer to the argument array, and a pointer to the environment array.
These will be described shortly.
Various library rountines, including \cmd{execl, execv, execle}, and \cmd{execve}, 
are provided to allow the parameters to be ommitted or specified in various ways.
Through this book we will use the name \cmd{exec} to represent the system call invoked by all of these.

Let us consider the case of a command such as\\
\cmd{cp file1 file2}\\
used to copy \sys{file1} to \sys{file2}.
After the shell has forked, the child process locates and executes the file \sys{cp} and passes to it the names of the source and target files.

The main program of \sys{cp} (and main program of most other C programs) contains the declaration\\
\cmd{main (argc, argv, envp)}\\
where \sys{argc} is a count of the number of items on the command line, including the program name.
For example above, \sys{argc} is 3.

The second parameter, \sys{argv}, is a pointer to an array.
Element \sys{i} of that array is a pointer to the \sys{i-th} string on the command line.
In our example, \sys{argv[0]} would point to the string ``cp'', \sys{argv[1]} would point to the string ``file1'', 
and \sys{argv[2]} would point to the string ``file2''.

The third parameter of \sys{main}, \sys{envp}, is a pointer to the environment, and array of strings containing assignments 
of the form \sys{name = value} used to pass information such as the terminal type and home directory name to a program.
In Fig. 1-10, no environment is passed to the child, so the third parameter of \sys{execve} is a zero.

If \cmd{exec} seems complicated, do not dispair; it is (semantically) the most complex of all the POSIX system calls.
All the other ones are much simpler.
As an example of a simple one, consider \cmd{exit}, which processes should use when they are finished executing.
It has one parameter, the exit status (0 to 255), which is returned to the parent via \sys{statloc} in the \cmd{waitpid} system call.
The low-order byte of status contains the termination status, with 0 being normal termination and the other values being various error conditions.
The high-order byte contains the child's exit status (0 to 255).
For example, if a parent process executes the statement\\
\cmd{n = waitpid(1, \&statloc, options);}\\
it will be suspended until some child process terminates.
If the child exits with, say, 4 as the parameter to \sys{exit}, the parent will be awakened with \sys{n} set to the child's PID 
and \sys{statloc} set to 0x0400 (the C convention of prefixing hexadecimal constants with 0x will be used throughout this book).

Processes in MINIX 3 have their memory divided up into three segments: the \kw{text segment} (i.e., the program code),
the \kw{data segment} (i.e., the variables), and the \kw{stack segment}.
The data segment grows upward and the stack grows downward, as shown in Fig. 1-11.
Between them is a gap of unused address space.
The stack grows into the gap automatically, as needed, but expansion of the data segment is done explicitly by using a system call, 
\cmd{brk}, which specifies the new address where the data segment is to end.
This address may be more than the current value (data segment is growing) or less than the current value (data segment is shringking).
The parameter must, of course, be less than the stack pointer or the data and stack segments would overlap, which is forbidden.

As a convenience for programmers, a library routine \sys{sbrk} is provided that also changes the size of the data segment, 
only its parameter is the number of bytes to add to the data segment (negtive parameters make the data segment smaller).
It works by keeping track of the current size of the data segment, which is value returned by \cmd{brk}, 
computing the new size, and making a call asking for that number of bytes. 
The \cmd{brk} and \cmd{sbrk} calls, however, are not defined by the POSIX standard.
Programmers are encouraged to use the \sys{malloc} library procedure for dynamiclly allocating storage, 
and the underlying implementation of \sys{malloc} was not thought to be a suitable subject for standadization 
since few programmers use it directly.

The next process system call is also the simplest, \cmd{getpid}.
It just returns the caller's PID.
Remember that in \cmd{fork}, only the parent was given the child's PID.
If a child wants to find out its own PID, it must use \cmd{getpid}.
The \cmd{getpgrp} call returns the PID of the caller's process group.
\cmd{setsid} creates a new session and sets the process group's PID to the caller's.
Sessions are related to an optional feature of POSIX, \kw{job control}, which is not supported by MINIX 3 and which will not concern us further.

The last process management system call, \cmd{ptrace}, is used by debugging programs to control the program being debugged.
It allows the debugger to read and write the controlled process' memory and manage it other ways.

\subsection{System Calls for Signaling}
Although most forms of interprocess communication are planned, 
situation exist in which unexpected communications is needed.
For example, if a user accidently tells a text editor to list the entire contents of a very long file,
and then realizes the error, some way is needed to interrupt the editor.
In MINIX 3, the user can hit the CTRL-C key on the keyboard, which sends a \kw{signal} to the editor.
The editor catches the signal and stops the print-out.
Signals can also be used to report certain traps detected by the hardware, such as illegal instruction or floating point overflow.
Timeouts are also implemented as signals.

When a signal is sent to a process that has not announced its willingness to accept that signal,
the process is simply killed without further ado.
To avoid this fate, a process can use the \cmd{sigaction} system call to announce that it is prepared to accept some signal type,
and to provide the address of the signal handling procedure and a place to store the address of the current one.
After a \cmd{sigaction} call, if a signal of the relevant type is generated (e.g., by pressing CTRL-C), 
the state of the process is pushed onto its own stack, and then the signal handler is called.
It may run for as long as it wants to and perform any system calls it wants to.
In practice, though, signal handlers are usually fairly short.
When the signal handling procedure is done, it calls \cmd{sigreturn} to continue where it left off before the signal.
The \cmd{sigaction} call replaces the older \cmd{signal} call, which is now provided as a library procedure, 
however, for backward compatibility.

Signals can be blocked in MINIX 3.
A blocked signal is held pending until it is unblocked.
It is not delivered, but also not lost.
The \cmd{sigprocmask} call allows a process to define the set of blocked signals by presenting the kernel with a bitmap.
It is also possible for a process to ask for the set of signals currently pending but not allowed to be delivered due to their being blocked.
The \cmd{sigpending} call returns this set as a bitmap.
Finally, the \cmd{sigsuspend} call allows a process to atomically set the bitmap of blocked signals and suspend itself.

Instead of providing a function to catch a signal, the program may also specify the constant SIG\_IGN 
to have all subsequent signals of the specified type ignored, or SIG\_DFL to restore the default action of the signal when it occurs.
The default action is either to kill the process or ignore the signal, depending upon the signal.
As an example of how SIG\_IGN is used, consider what happens when the shell forks off a backgroud process as a result of\\
\cmd{command \&}\\
It would be undesirable for a SIGINT signal (generated by pressing CTRL-C) to affect the background process,
so after the \cmd{fork} but before the \cmd{exec}, the shell does\\
\cmd{sigaction (SIGINT, SIG\_IGN, NULL);}\\
and\\
\cmd{sigaction (SIGQUIT, SIG\_IGN, NULL);}\\
to disable the SIGINT amd GIGQUIT signals.
(SIGQUIT is generated by CTRL-\textbackslash; it is the same as SIGINT generated by CTRL-C 
except that if it is not caught or ignored it makes a core dump of the process killed.)
For foreground process (no ampersand), these signals are not ignored.

Hitting CTRL-C is not the only way to send a signal.
The \cmd{kill} system call allows a process to signal another process 
(provided they have the same UID, unrelated processes cannot signal each other).
Getting back to the example of backgroud process used above, suppose a backgroud process is started up, 
but later it is decided that the process should be terminated.
SIGINT and GIGQUIT have been disabled, so something else is needed.
The solution is to use the \sys{sys} program, which uses the \cmd{kill} system call to send a signal to any process.
By sending signal 9 (SIGKILL), to a backgroud process, that process can be killed.
SIGKILL cannot be caught or ignored.

For many real-time applications, a process needs to be interrupted after a specific time interval to do something, 
such as retransmit a potentially lost packet over an unreliable communication line.
To handle this situation, the \cmd{alarm} system call has been provided.
The parameter specifies an interval, in seconds, after which a SIGALARM signal is sent to the process.
A process may only have one alarm outstanding at any instant.
If an \cmd{alarm} call is made with a parameter of 10 seconds, 
and then 3 seconds later another \cmd{alarm} call is made with a parameter of 20 seconds,
only one signal will be generated, 20 seconds after the second call.
The first signal is canceled by the second call to \cmd{alarm}.
If the parameter to \cmd{alarm} is zero, any pending alarm signal is canceled.
If an alarm signal is not caught, the default action is taken and the signaled process is killed.

It sometimes occurs that the process has nothing to do until a signal arrives.
For example, consider a computer-aided-instruction program that is testing reading speed and comprehension.
It displays some text on the screen and then calls \cmd{alarm} to signal it after 30 seconds.
While the student is reading the text, the program has nothing to do.
It could sit in a tight loop doing nothing, but would waste CPU time that another process or user might need.
A better idea is to use \cmd{pause}, which tells MINIX 3 to suspend the process untill the next signal.

\subsection{System Calls for File Management}
Many sytem calls relate to the file system.
In this section we will look at calls that operate on individual files; 
in the next one we will examine those that involve directories or the file system as a whole.
To create a new file, the \cmd{creat} call is used (why the call is \cmd{creat} and not \cmd{create} has been lost in the mists of time).
Its parameters provide the name of the file and the protection mode.
Thus\\
\cmd{fd = creat ("abc", 0751);}\\
creates a file called \sys{abc} with mode 0751 octal (in C, a leading zero means that a constant is in octal).
The low-order 9 bits of 0751 specify the \sys{rwx} bits for the owner (7 means read-write-execute permission),
his group (5 means read-execute), and others (1 means execute only).

\cmd{creat} not only creates a new file but also opens it for writing, regardless of the file's mode.
The file descriptor returnd, \sys{fd}, can be used to write the file.
If a \cmd{creat} is done on an existing file, that file is truncated to lenghth 0, provided, of course, that the permissions are all right.
The \cmd{creat} call is obsolete, as \cmd{open} can now create new files, but it has been included for backward compatibility.

Special files are created using \cmd{mknod} rather than \cmd{creat}.
A typical call is\\
\cmd{fd = mknod ("/dev/ttyc2", 020744, 0x0402);}\\
which creates a file named \sys{/dev/ttyc2} (the usual name for console 2) 
and gives it mode 020744 octal (a character special file with protection bits rwxr--r--).
The third parameter contains the major device (4) in the high-order byte and the minor device (2) in the low-order byte.
The major device could have been anything, but a file named \sys{/dev/ttyc2} ought to be minor device 2.
Calls to \cmd{mknod} fail unless the caller is the superuser.

To read or write an existing file, the file must first be opened using \cmd{open}.
This call specifies the file name to be opened, either as an absolute path name or relative to the working directory, 
and a code of \sys{O\_RDONLY}, \sys{O\_WRONLY}, or \sys{O\_RDWR}, meaning open for reading, writing, or both.
The file descriptor returned can then be used for reading or writing.
Afterward, the file can be closed by \cmd{close}, which makes the file descriptor available for reuse on a subsequent \cmd{creat} or \cmd{open}.

The most heavily used calls are undoubtedly \cmd{read} and \cmd{write}.
We saw \cmd{read} earlier; \cmd{write} has the same parameters.

Although most programs read and write files sequentially, 
for some applications programs need to be able to access any part of a file at random.
Associated with each file is a pointer that indicates the current position in the file.
When reading (writing) sequentially, it normally points to the next byte to be read (written).
The \cmd{lseek} call changes the value of the position pointer, 
so that subsequent calls to \cmd{read} or \cmd{write} can begin anywhere in the file, or even beyond the end.

\cmd{lseek} has three parameters: the first is the file descriptor for the file, the second is a file position, 
and the third tells whether the file position is relative to the beginning of the file, the current position, or the end of the file.
The value returned by \cmd{lseek} is the absolute position in the file after changing the pointer.

For each file, MINIX 3 keeps track of the file mode (regular file, special file, directory, and so on),
size, time of last modification, and other information.
Programs can ask to see this information via the \cmd{stat} and \cmd{fstat} system calls.
These differ only in that the former specifies the file by name, whereas the latter takes a file descriptor, 
making it useful for open files, especially standard input and standard output, whose names may not be known.
Both calls provide as the second parameter a pointer to a structure where the information is to be put.
The structure is shown in Fig. 1-12.

When manipulating file descriptors, the \cmd{dup} call is occasionally helpful.
Consider, for example, a program that needs to close standard output (file descriptor 1), substitute another file as standard output, 
call a function that writes some output onto standard output, and then restore the original situation.
Just closing file descriptor 1 and opening a new file will make the new file standard output 
(assuming standard input, file descriptor 0, is in use),
but it will be impossible to restore the original situation later.

The solution is first to execute the statement\\
\cmd{fd = dup(1);}\\
which uses the \cmd{dup} system call to allocate a new file descriptor, \sys{fd}, and arrange for it to correspond to the same file as standard output.
Then standard output can be closed and a new file opened and used.
When it is time to restore the original situation, file descriptor 1 can be closed, and the\\
\cmd{n = dup(fd)}\\
executed to assign the lowest file descriptor, namely, 1 to the same file as \sys{fd}.
Finally, \sys{fd} can be closed and we are back where we started.

The \cmd{dup} call has a variant that allows an arbitrary unassigned file descriptor to be made to refer to a given open file.
It is called by\\
\cmd{dups(fd, fd2);}\\
where \sys{fd} refers to an open file and \sys{fd2} is the unassigned file descriptor that is to be made refer to the same file as \sys{fd}.
Thus if \cmd{fd} refers to standard input (file descriptor 0) and \sys{fd2} is 4, after the call, 
file descriptors 0 and 4 will both refer to standard input.

Interprocess communication in MINIX 3 uses pipes, as described earlier.
When a user types\\
\cmd{cat file1 file 2 | sort}\\
the shell creates a pipe and arranges for standard output of the first process to write to the pipe,
so standard input of the second process can read from it.
The \cmd{pipe} system call creates a pipe and returns two file descriptors, one for writing and one for reading.
The call is\\
\cmd{pipe (\&fd[0]);}\\
where \sys{fd} is an array of two integer and \sys{fd[0]} is the file descriptor for reading and \sys{fd[1]} is the one for writing.
Typically, a \cmd{fork} comes next, and the parent closes the file descriptor for reading 
and the child close the file descriptor for writing (or vice versa),
so when they are done, one process can read the pipe and the other can write on it.

Fig. 1-13 depicts a skeleton procedure that creates two processes, with the output of the first one piped into the second one.
(A more realistic example would do error checking and handle arguments.)
First a pipe is created, and then the procedure forks, with the parent eventually becoming the first process in the pipeline 
and the child process becoming the second one.
Since the files to be executed, \sys{prcess1} and \sys{process2}, do not known  that they are part of a pipeline, 
it is essential that the file descriptors be manipulated so that the first process' standard output be the pipe 
and the second one's standard input be the pipe.
The parent first closes off the file descriptor for reading from the pipe.
Then it closes standard output and does a \cmd{dup} call that allows file descriptor 1 to write on the pipe.
It is important to realize that \cmd{dup} always returns the lowest available file descriptor, in this case, 1.
Then the program closes the other pipe file descriptor.

After the \cmd{exec} call, the process started will have file descriptors 0 and 2 be unchanged, 
and file descriptor 1 for writing on the pipe.
The child code is analogous.
The parameter to \sys{execl} is repeated because the first one is the file to be executed and the second one is the first parameter, 
which most programs expect to be the file name.

The next system call, \cmd{ioctl}, is potentially applicable to all special files.
It is, for instance, used by block device drivers like the SCSI driver to control tape and CD-ROM devices.
Its main use, however, is with special character files, primarily terminals.
POSIX defines a number of functions which the library translates into \cmd{ioctl} calls.
The \sys{tcgetattr} and \sys{tcsetattr} library functions use \cmd{ioctl} to change the characters used for 
correcting typing errors on the terminal, changing the \kw{terminal mode}, and so forth.

Traditionally, there are three terminal modes, cooked, raw, and cbreak.
\kw{Cooked mode} is the normal terminal mode, in which the erase and kill characters work normally, 
CTRL-S and CTRL-Q can be used for stopping and starting terminal output, 
CTRL-D means end of file, 
CTRL-C generates an interrupt signal, and 
CTRL-\textbackslash generates a quit signal to force a core dump.
 
In \kw{raw mode}, all of these functions are disabled; consequently, every character is passed directly to the program with no special processing.
Furthermore, in raw mode, a read from the terminal will give the program any characters that have been typed, 
even a partial line, rather than waiting for a complete line to be typed, as in cooked mode.
Screen editors often use this mode.

\kw{Cbreak mode} is in between.
The erase and kill characters for editing are disabled, as is CTRL-D, but CTRL-S, CTRL-Q, CTRL-C, and CTRL-\textbackslash are enabled.
Like raw code, partial lines can be returned to programs (if intraline editing is turn off there is no need 
to wait until a whole line has been received, the user cannot change his mind and detete it, as he can in cooked mode). 

POSIX does not use the term cooked, raw, and cbreak.
In POSIX terminology \kw{canonical mode} corresonds to cooked mode.
In this mode there are eleven special characters defined, and input is by lines.
In \kw{noncanonical mode} a minimum number of characters to accept and a time, specified in units of 1/10th of second, 
determine how a read will be satisfied.
Under POSIX there is a great deal of flexibility, and various flags can be set to make noncanonical mode behave like either cbreak or raw mode.
The older terms are more descriptive, and we continue to use them informally.

\cmd{Ioctl} has three parameters, for example a call to \sys{tcsetattr} to set terminal parameters will result in\\
\cmd{ioctl (fd, TCSETS, \&termios);}\\
The first parameter specifies a file, the second one specifies an operation, 
and the third one is the address of the POSIX structure that contains flags and the array of control characters.
Other operation codes instruct the system to postpone the changes until all output has been sent,
cause unread input to be discarded, and return the current values.

The \cmd{access} system call is used to determine whether a certain file access is permitted by the protection system.
It is needed because some programs can run using a differnt user's UID.
This SETUID mechanism will be described later.

The \cmd{rename} system call is used to give a file a new name.
The parameters specify the old and new names.

Finally, the \cmd{fcntl} call is used to control files, somewhat analogous to \cmd{ioctl} (i.e., both of them are horrible hacks).
It has several options, the most important of which is for advisory file locking.
Using \cmd{fcntl}, it is possible for a process to lock and unlock parts of files and test part of a file to see if it is locked.
The call does not enforce any lock semantics.
Programs must do this themselves.

\subsection{System Calls for Directory Management}
In this section, we will look at some system calls that relate more to directories or the file system as a whole,
rather than just to one specific file as in the previous section.
The first two calls, \cmd{mkdir} and \cmd{rmdir}, create and remove empty directories, respectively.
The next call is \cmd{link}.
Its purpose is to allow the same file to appear under two or more names, often in different directories.
A typical use is to allow several members of the same programming team to share a common file, 
with each of them having the file appear in his own directory, possibly under different names.
Sharing a file is not the same as giving every team member a private copy, 
because having a shared file means that changes that any member of the team makes are instantly visible to the other members,
there is only one file.
When copies are made of a file, subsequent changes made to one copy do not affect the other ones.
 
To see how \cmd{link} works, consider the situation of Fig. 1-14(a).
Here are two users, \sys{ast} and \sys{jim}, each having their own directories with some files.
If \sys{ast} now executes a program containing the system call\\
\cmd{link ("/usr/jim/memo", "usr/ast/note");}\\
the file \sys{memo} in \sys{jim}'s directory is now entered into \sys{ast}'s directory under the name \sys{note}.
Thereafter, \sys{/usr/jim/memo} and \sys{/usr/ast/note} refer to the same file.
 
Understanding how \cmd{link} works will probably make it clearer what it does.
Every file in UNIX has a unique number its i-number, that identifies it.
This number is an index into a table of \kw{i-nodes}, one per file, telling who owns the file, 
where its disk blocks are, and so on.
A directory is simply a file containing a set of (i-number, ASCII name) pairs.
In the first versions of UNIX, each directory entry was 16 bytes: 2 bytes for the i-number and 14-bytes for the name.
A more complicated structure is needed to support long file names, but conceptually a directory is still a set of (i-number, ASCII name) pairs.
In Fig. 1-14, \sys{mail} has i-number 16, and so on.
What \cmd{link} does is simply create a new directory entry with a (possibly new) name, using the i-number of an existing file.
In Fig. 1-14(b), two entries have the same i-number (70) and thus refer to the same file.
If either one is later removed, using the \cmd{unlink} system call, the other one remains.
If both are removed, UNIX sees that no entries to the file exist 
(a field in the i-node keeps track of the number of directory entries pointing to the file), so the file is removed from the disk.

As we have mentioned early, the \cmd{mount} system call allows two file systems to be merge into one.
A common situation is to have the root system containing the binary (executable) versions of the common commands 
and other heavily used files, on a hard disk.
The user can then insert a CD-ROM with files to be read into the CD-ROM drive.

By executing the \cmd{mount} system call, the CD-ROM file system can be attached to the root file system, as shown in Fig. 1-15.
A typical statement in C to perform the mount is\\
\cmd{mount ("/dev/cdrom0", "/mnt", 0);}\\
where the first parameter is the name of a block special file for CD-ROM drive 0, 
the second parameter is the place in the tree where it is to be mounted,
and the third one tells whether the file system is to be mounted read-write or read-only.

After the \cmd{mount} call, file on CD-ROM drive 0 can be accessed by just using its path from the root directory or the working directory,
without regard to which drive it is on.
In fact, second, third and fourth drives can also be mounted anywhere in the tree.
The \cmd{mount} call makes it possible to integrate removable media into a single integrated file hierarchy,
without having to worry about which device a file is on.
Although this example involves CD-ROMs, hard disks or portions of hard disks
(often called \kw{partitions} or \kw{minor devices}) can also be mounted this way.
When a file system is no longer needed, it can be unmounted with the \cmd{unmount} system call.

MINIX 3 maintains a \kw{block cache} cache of recently used blocks in main memory to avoid having to read them from the disk
if they are used again quickly.
If a block in the cache is modified (by a \cmd{write} on a file) and the system crashes before the modified block is written out to disk, 
the file system will be damaged.
To limit the potential damage, it is important to flush the cache periodically,
so that the amount of data lost by a crash will be small.
The system call \cmd{sync} tells MINIX 3 to write out all the cache blocks that have been modified since being read in.
When MINIX 3 is started up, a program called \sys{update} is started as a background process 
to do a \cmd{sync} every 30 seconds, to keep flushing the cache.

Two other calls that relate to directories are \cmd{chdir} and \cmd{chroot}.
The former changes the working directory and the latter changes the root directory.
After the call\\
\cmd{chdir ("/usr/ast/test");}\\
an open on the file \sys{xyz} will open \sys{/usr/ast/test/xyz}.
\cmd{chroot} works in an analogous way.
Once a process has told the system to change its root directory, 
all absolute path names (path names beginning with a ``/'') will start at the new root.
Why would you want to do that?
For security server programs for protocols such as \kw{FTP} (File Transfer Protocol) and \kw{HTTP} (HyperText Transfer Protocol) 
do this so remote users of these services can access only the portions of a file system below the new root.
Only superusers may execute \cmd{chroot}, and even superusers do not do it very often.

\subsection{System Calls for Protection}
In MINIX 3 every file has an 11-bit mode used for protection.
Nine of these bits are the read-write-execute bits for the owner, group, and others.
The \cmd{chmod} system call makes it possible to change the mode of a file.
For example, to make a file read-only by everyone except the owner, one could execute\\
\cmd{chmod ("file", 0644);}\\
The other two protection bits, 02000 and 04000, are the SETGID (set-group-id) and SETUID (set-user-id) bits, respectively.
When any user executes a program with the SETUID bit on, 
for the duration of that process the user's effective UID is changed to that of the file's owner.
This feature is heavily used to allow users to execute programs that perform superuser only functions, such as creating directories.
Creating a directory uses \cmd{mknod}, which is for the superuser only.
By arranging for the \sys{mkdir} program to be owned by the superuser and have mode 04755, 
ordinary users can be given the power to execute \cmd{mknod} but in a highly restricted way.

When a process executes a file that has the SETUID or SETGID bit on in its mode,
it acquires an effective UID or GID different from its real UID or GID.
It is sometimes important for a process to find out what its real and effective UID or GID is.
The system calls \cmd{getuid} and \cmd{getgid} have been provided to supply this information.
Each call returns both the real and effective UID or GID, so four library routines were needed to extract the proper information:
\sys{getuid}, \sys{getgid}, \sys{geteuid}, and \sys{getegid}.
The first two get the real UID/GID, and the last two the effective ones.

Ordinary users cannot change their UID, except by executing programs with the SETUID bit on,
but the superuser has another possibility: the \cmd{setuid} system call, which sets both the effective and real UIDs. 
\cmd{setgid} sets both GIDs.
The superuser has plenty of opportunity for violating all the protection rules,
which explains why so many students devote so much of their time to trying to become superuser.

The last two system calls in this category can be executed by ordinary user processes.
The first one, \cmd{umask}, sets an internal bit mask within the system, which is used to mask off mode bits when a file is created.
After the call\\
\cmd{umask (022);}\\
the mode supplied by \cmd{creat} and \cmd{mknod} will have the 022 bits masked off before being used.
Thus the call\\
\cmd{creat ("file", 0777);}\\
will set the mode to 0755 rather than 0777.
Since the bit mask is inherited by child processes, if the shell does a \cmd{umask} just after login, 
none of the user's processes in that session will accidently create files that other people can write on.
 
When a program owned by the root has the SETUID bit on, it can access any file, because its effective UID is the superuser.
Frequently it is useful for the program to know if the person who called the program has permission to access a given file.
If the program just tries the access, it will always succeed, and thus learn nothing.

What is needed is a way to see if the access is permitted for the real UID.
The \cmd{access} system call provides a way to find out.
The \sys{mode} parameter is 4 to check for read access, 2 for write access, and 1 for execute access.
Combinations of these values are also allowed.
For example, with \sys{mode} equal to 6, the call returns 0 if both read and write access are allowed for the real ID;
otherwise 1 is returned.
With \sys{mode} equal to 0, a check is made to see if the file exists and the directories leading up to it can be searched.

Although the protection mechanisms of all UNIX-like operating systems are generally similar, 
there are some differences and inconsistencies that lead to security vulnerabilities.
See Chen et al.(2002) for a discussion.

\subsection{System Calls for Time Management}
MINIX 3 has four system calls that involve the time-of-day clock.
\cmd{Time} just returns the current time in seconds, with 0 corresponding to Jan. 1, 1970 at midnight (just as the day was starting, not ending).
Of course, the system clock must be set at some point in order to allow it to be read later,
so \cmd{stime} has been provided to let the clock be set (by the superuser).
The third time call is \cmd{utime}, which allows the owner of a file (or the superuser) to change the time stored in a file's i-node.
Application of this system call is fairly limited, but a few programs need it, 
for example, \sys{touch}, which sets the file's time to the current time.

Finally, we have \cmd{times}, which returns the accounting information to a process,
so it can see how much CPU time it has used directly, 
and how much CPU time the system itself has expended on its behalf (handling its system calls).
The total user and system times used by all its children combined are also returned.

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{Operating System Structure}
Now that we have seen what operating systems look like on the outside (i.e., the programmer's interface),
it is a time to take a look inside.
In the following sections, we will examine five different structures that have been tried,
in order to get some idea of the spectrum of possibilities.
These are by no means exhaustive, but they give an idea of some designs that have been tried in practice.
The five designs are monolithic systems, layered systems, virtual machines, exokernels, and client-server systems.

\subsection{Monolithic Systems}
By far the most common organization, this approach might well be subtitled ``The Big Mess''.
The structure is that there is no structure.
The operating system is written as a collection of procedure, each of which can call any of the other ones whenever it needs to.
When this technique is used, each procedure in the system has a well-defined interface in terms of parameters and results,
and each one is free to call any other one, if the latter provides some useful computation that the former needs.

To construct the actual object program of the operating system when this approach is used, 
one first compiles all the individual procedures, or files containing the procedures, 
and then binds them all together into a single object file using the system linker.
In terms of information hiding, there is essentially none every procedure is visible to every other procedure
(as opposed to a structure containing modules or packages, in which much of the information is hidden away inside modules,
and only the officially designated entry points can be called from outside the module).  

Even in monolithic systems, however, it is possible to have at least a little structure.
The services (system calls) provided by the operating system are requested by 
putting the parameters in well-defined places, such as in registers or on the stack,
and then executing a special trap instruction known as a \kw{kernel call} or \kw{supervisor call}.

This instruction switches the machine from user mode to kernel mode and transfers control to the operating system.
(Most CPUs have two modes: kernel mode, for the operating system, in which all instructions are allowed;
and user mode, for user programs, in which I/O and certain other instructions are not allowed.)

This is a good time to look at how system calls are performed.
Recall that the \cmd{read} call is used like this:\\
\cmd{count = read(fd, buffer, nbytes);}

In preparation for calling the \sys{read} library procedure, which actually makes the \cmd{read} system call,
the calling program first pushes the parameters onto the stack, as shown in steps 13 in Fig. 1-16.
C and C++ compilers push the parameters onto the stack in reverse order for historical reasons
(having to do with making the first parameters to \sys{printf}, the format string, appear on top of the stack).
The first and third parameters are called by value, but the second parameter is passed by reference,
meaning that the address of the buffer (indicated by \&) is passed, not the contents of the buffer.
Then comes the actual call to the library procedure (step 4).
This instruction is the normal procedure call instruction used to call all procedures.

The library procedure, possibly written in assembly language, 
typically puts the system call number in place where the operating system expects it, such as register (step 5).
Then it executes a \cmd{trap} instruction to switch from user mode to kernel mode 
and start execution at a fixed address within the kernel (step 6).
The kernel code that starts examines the system call number and then dispatches to the correct system call handler,
usually via a table of pointers to system call handlers indexed on system call number (step 7).
At that point the system call handler runs (step 8).
Once the system call handler has completed its work, 
control may be returned to the user-pace library procedure at the instruction following the \cmd{trap} instruction (step 9).
This procedure then returns to the user program in the usual way procedure calls return (step 10).

To finish the job, the user program has to clean up the stack, as it does after any procedure call (step 11).
Assuming the stack grows downward, as it often does, 
the compiled code increments the stack pointer exactly enough to remove the parameters pushed before the call to \sys{read}.
The program is now free to do whatever it wants to do next.

In step 9 above, we said ``may be returned to the user-space library procedure'' for good reason.
The system call may block the caller, preventing it from continuing.
For example, if it is trying to read from the keyboard and nothing has been typed yet, the caller has to be blocked.
In this case, the operating system will look around to see if some other process can be run in next.
Later, when the desired input is available, this process will get the attention of the system and step 9-11 will occur.

This organization suggests a basic structure of the operating system:
\begin{enumerate}
  \item A main program that invokes the requested service procedure.
  \item A set of service procedures that carry out the system calls.
  \item A set of utility procedures that help the service procedures.
\end{enumerate}

In this model, for each system call there is one service procedure that takes care of it.
The utility procedures do things are needed by several service procedures, such as fetching data from user programs.
This division of the procedures into three layers is shown in Fig. 1-17.

\subsection{Layered Systems}
A generalization of the approach of Fig. 1-17 is to organize the operating system as a hierarchy of layers,
each one constructed upon the one below it.
The first system constructed in this way was THE system 
built at the Technische Hogeschool Eindhoven in the Netherlands by E.W. Dijkstra (1968) and his students.
The THE system was a simple batch system for a Dutch computer, the Electrologica X8,
which had 32K of 27-bit words (bits were expensive back then).

The system had 6 layers, as shown in Fig. 1-18.
Layer 0 dealt with allocation of the processor, switching between processes when interrupts occurred or timers expired.
Above layer 0, the system consisted of sequential processes, each of which could be programmed without having to worry about the fact 
that multiple process are running on a single processor.
In other words, layer 0 provided the basic multiprogramming of the CPU.

Layer 1 did the memory management.
It allocated space for processes in main memory and on a 512K word drum used for holding parts of processes (pages) 
for which there was no room in main memory.
Above layer 1, processes did not have to worry about wether they were in memory or on the drum;
the layer 1 software took care of making sure pages were brought into memory whenever they were needed.

Layer 2 handled communication between each process and the operator console.
Above this layer each process effectively had its own operator console.
Layer 3 took care of managing the I/O devices and buffering the information streams to and from them.
Above layer 3 each process could deal with abstract I/O devices with nice properties, 
instead of real devices with many peculiarities.
Layer 4 was where the user  programs were found.
They did not have to worry about process, memory, console, or I/O management.
The system operator process was located in layer 5.

A further generalization of the layering concept was present in the MULTICS system.
Instead of layers, MULTICS was organized as a series of concentric rings, with the inner ones being more privileged than the outer ones.
When a procedure in an outer ring wanted to call a procedure in an inner ring,
it has to make the equivalent of a system call, that is, a TRAP instruction
whose parameters were carefully checked for validity before allowing the call to proceed.
Although the entire operating system was part of the address space of each user process process in MULTICS,
the hardware made it possible to designate individual procedures (memory segments, actually)
as protected against reading, writing, or executing.

Whereas the THE layering scheme was really only a design aid, 
because all the parts of the system were ultimately linked together into a single object program, in MULTICS,
the ring mechanism was very much present at run time and enforced by the hardware.
The advantege of the ring mechanism is that it can easily be extended to structure user subsystems.
For example, a professor could write a program to test and grade student programs and run this program in ring \sys{n},
with the student programs running in ring \sys{n} + 1 so that they could not change their grades.
The Pentium hardware supports the MULTICS ring structure, but no major operating system uses it present.

\subsection{Virtual Machines}
The initial releases of OS/360 were strictly batch systems.
Neverthless, many 360 users wanted to have timesharing, so various groups, 
both inside and outside IBM decided to write timesharing system for it.
The official IBM timesharing system, TSS/360, was delivered late, 
and when it finally arrived it was so big and slow that few sites converted to it.
It was eventually abandoned after its development had consumed some \$50 million (Graham, 1970).
But a group at IBM'S Scientific Center in Cambridge, Massachusetts, 
produced a radically different system that IBM eventually accepted as a product,
and which is now used on its mainframes.

This system, originally called CP/CMS and later renamed VM/370 (Seawright and MacKinnon, 1979),
was based on a very astute observation: a timesharing system provides
(1) multiprogramming and
(2) an extended machine with a more convenient interface than the bare hardware.
The essence of VM/370 is to completely seperate these two functions.
 
The heart of the system, known as the \kw{virtual machine monitor}, runs on the bare hardware and does the multiprogramming,
providing not one, but several virtual machines to the next layer up, as shown in Fig. 1-19.
However, unlike all other operating systems, these virtual machines are not extended machines, with files and other nice features.
Instead, they are \sys{exact} copies of the bare hardware, 
including kernel/user mode, I/O, interrupts, and everything else real machine has.

Because each virtual machine is identical to the true hardware, 
each one can run any operating system that will run directly on the bare hardware.
Different virtual machines can, and frequently do, run different operating systems.
Some run one of the descendants of OS/360 for batch or transaction processing, 
while others run a single-user, interactive system called \kw{CMS} (Conversational Monitor System) for timingsharing users.

When a CMS program executes a system call, the call is trapped to operating-system in its own virtual machine,
not to VM/370, just as it would if it were running on a real machine instead of a virtual one.
CMS then issues the normal hardware I/O instructions for reading its virtual disk or whatever is needed to carry out the call.
These I/O instructions are trapped by VM/370, which then performs them as part of its simulation of the real hardware.
By making a complete separation of the functions of multiprogramming and providing an extended machine, 
each of the pieces can be much simpler, more flexible, and easier to maintain.

The idea of a virtual machine is used nowadays in a different contex: runing old MS-DOS programs on a Pentium.
When designing the Pentium and its software, both Intel and Microsoft realized that 
there would be a big demand for running old software on new hardware.
For this reason, Intel provided a virtual 8086 mode on the Pentium.
In this mode, the machine acts like an 8086 (which is identical to an 8088 from a software point of view),
including 16-bit addressing with a 1-MB limit.

This mode is used by Windows, and other operating systems for running old MS-DOS programs.
These programs are started up in virtual 8086 mode.
As long as they execute normal instructions, they run on the bare hardware.
However, when a program tries to trap to the operating system to make a system call,
or tries to do protected I/O directly, a trap to the virtual machine monitor occurs.

Two variants on this design are possible.
In the first one, MS-DOS itself is loaded into the virtual 8086's address space, 
so the virtual machine monitor just reflects the trap back to MS-DOS, just as would happen on a real 8086.
When MS-DOS later tries to do the I/O itself, that operation is caught and carried out by the virtual machine monitor.

In the other variant , the virtual nachine monitor just catches the first trap and does I/O itself,
since it knowns what all the MS-DOS system calls are and thus known what each trap is supposed to do.
This variant is less pure than the first one, since it emulates only MS-DOS correctly, and not other operating systems, as the first one does.
On the other hand, it is much faster, since it saves the trouble of starting up MS-DOS to do the I/O.
A further disadvantage of actually running MS-DOS in virtual 8086 mode is that MS-OS fiddles around with the interrupt enable/disable bit quite a lot, 
all of which must be emulated at considerable cost.

It is worth nothing that neither of these approaches are really the same as VM/370, 
since the machine being emulated is not a full Pentium, but only an 8086.
With the VM/370, it is possible to run VM/370, itself, in the virtual machine.
Even the earliest vertion of Windows require at least a 286 and cannot be run on a virtual 8086. 

Several virtual machine implementations are marked commercally.
For companies that provide web-hosting services, it can be more ecnomical to run multiple virtual machines 
on a single fast server (perhaps one with multiple CPUs) than to run many small computers, each hosting a single Web site.
VMWare and Microsoft's Virtual PC are marked for such installations.
These programms use large files on a host system as simulated disks for their guest systems.
To achive efficiency they analyze guest system program binaries and allow safe code to run directly on the host hardware,
trapping instructions that make operating system calls.
Such systems are also useful in education.
For instance, students working on MINIX 3 lab assignments can work using MINIX 3 as a guest operating system 
on VMWare on a Windows, Linux or UNIX host with no risk of damaging other software installed on the same PC.
Most professors teaching other subjects would be very nervous about sharing laboratory computers with an operating systems course 
where student mistakes could corrupt or erase disk data.

Another are a where virtual machines are used, but in a somewhat different way, is for running Java programs.
When Sun Microsystems invented the Java programming language, 
it also invented a virtual machine (i.e., a computer architecture) called \kw{JVM (Java Virtual Machine)}.
The Java compiler produces code for JVM, which then typically executed by a software JVM interpreter.
The advantage of this approach is that the JVM code can be shipped over the Internet to any computer 
that has a JVM interpreter and run there.
If the compiler had produced SPARC or Pentium binary programs, for example, they could not have been shipped and run anywhere as easily.
(Of course, Sun could have produced a compiler that produced SPARC binaries and then distributed a SPARC interpreter, 
but JVM is a much simpler architecture to interpret.)
Another advantage of using JVM is that if the interpreter is implemented properly, which is not completely trivial, 
incoming JVM programs can be checked for safety and then executed in a protected environment so they cannot steal data or do any damage.

\subsection{Exokernels}
With VM/370, each user process gets an exact copy of the actual computer.
With virtual 8086 mode on the Pentium, each user process gets an exact copy of a different computer.
Going one step further, researchers at M.I.T. built a system that gives each user a clone of the actual computer,
but with a subset of the resources (Engler et al., 1995; and Leschke, 2004).
Thus one virtual machine might get disk blocks 0 to 1023, 
the next one might get blocks 1024 to 2047, and so on.

At the bottom layer, running in kernel mode, is a program called \kw{exokernel}.
Its job is to allocate resources to virtual machines and then check attempts to use them 
to make sure no machine is trying to use somebody else's resources.
Each user-level virtual machine can run its own operating system, as on VM/370 and the Pentium virtual 8086s,
except that each one is restricted to using only the resources it has asked for and been allocated.

The advantage of the exokernel scheme is that it saves a layer of mapping.
In the other designs, each virtual machine thinks it has its own disk, with blocks running from 0 to some maximum,
so the virtual machine monitor must maintain tables to remap disk addresses (and all other resources).
With the exokernel, this remapping is not needed.
The exokernel need only keep track of which virtual machine has been assigned with resource.
This method still has the advantage of separating the multiprogramming (in the exokernel) from 
the user operating system code (in user space), but with less overhead,
since all the exokernel has to do is keep the virtual machines out of each other's hair.
 
\subsection{Client-Server Model}
VM/370 gains much in simplicity by moving a large part of the traditional operating system code 
(implementing the extended machine) into a higher layer, CMS.
Nevertheless, VM/370 itself is still a complex program because simulating a number of virtual 370s is not that simple
(especially if you want to do it reasonably efficiently).

A trend in modern operating systems is to take this idea of moving code up into higher layers even further 
and remove as much as possible from the operating system, leaving a minimal \kw{kernel}.
The usual approach is to implement most of the operating system functions in user processes.
To request a service, such as reading a block of a file, 
a user process (now known as the \kw{client process}) sends the request to a \kw{server process},
which then does the work and sends back the answer.

In this model, shown in Fig. 1-20, all the kernel does is handle the communication between clients and servers.
By splitting the operating system up into parts, each of which only handles one facet of the system,
such as file service, process service, terminal service, or memory service, each part becomes small and manageable.
Furthermore, because all the servers run as user-mode processes, and not in kernel mode, 
they do not have direct access to the hardware.
As a consequence, if a bug in the file server is triggered, the file service may crash, 
but this will not usually bring the whole machine down.

Another advantage of the client-server model is its adaptability to use in distributed systems (see Fig. 1-21).
If a client communicates with a server by sending it messages, 
the client need not know whether the message is handled locally in its own machine,
or whether it was sent across a network to a server on a remote machine.
As far as the client is concerned, the same thing happens in both cases: 
a request was sent and a reply came back.

The picture painted above of a kernel that handles only the transport of messages from clients to servers 
and back is not completely realistic.
Some operating system functions (such as loading commands into the physical I/O device registers) are difficult, 
if not impossible, to do from user space programs.
There are two ways of dealing with this problem.
One way is to have some critical server processes (e.g., I/O device drivers) actually run in kernel mode, 
with complete access to all the hardware, but still communicate with other processes using the normal message mechanism.
A variant of this mechanism was used in earlier version of MINIX where drivers were compiled into the kernel but ran as separate processes.

The other way is to build a minimal amount of \kw{mechanism} into the kernel but leave the \kw{policy} decisions up to servers in user space.
For example, the kernel might recognize that a message sent to a certain special address means to take the contents of that message
and load it into the I/O device registers for some disk, to start a disk read.
In this example, the kernel would not even inspect the bytes in the message to see if they were valid or meaningful;
it would just blindly copy them into the disk's device registers.
(Obviously, some scheme for limiting such message to authorized processes only must be used.)
This is how MINIX 3 works, drivers are in user space and use special kernel calls to request reads and writes of I/O registers or to access kernel information.
The split between mechanism and policy is an important concept; it occurs...

\section{Outline of the Rest of This Book}
Operating systems typically have four major components: 
process management, I/O device management, memory management, and file management.
MINIX 3 is also divided into these four parts.
The next four chapters deal with these four topics, one topic per chapter.
Chapter 6 is a list of suggested reading and a bibliography.

The chapters on processes, I/O, memory management, and file systems have the same general structure.
First the general principles of the subject are laid out.
Then comes an overview of the corresponding area of MINIX 3 (which also applied to UNIX).
Finally, the MINIX 3 implementation is discussed in detail.
The implementation section may be skimmed or skipped without loss of continuity by readers 
just interested in the principles of operating systems and not interested in the MINIX 3 code.
Readers who are interested in finding out how a real operating system (MINIX 3) works should read all the sections.

\section{Summary}
Operating systems can be viewed from two viewpoints: resource manager and extended machines.
In the resource manager view, the operating system's job is to efficently manage the different parts of the system.
In the extended machine view, the job of the system is to provide the users with a virtual machine 
that is more convenient to use than the actual machine.
 
Operating systems have a long history, starting from the days when they replaced the operator,
to modern multiprogramming systems.

The heart of any operating system is the set of system calls that it can handle.
These tell what the operating system really does.
For MINIX 3, these calls can be divided into six groups.
The first group of system calls relates to process creation and termination.
The second group handles signals.
The third group is for reading and writing files.
A fourth group is for directory management.
The fifth group protects information, and the sixth group is about keeping track of time.

Operating systems can be structured in several ways.
The most common ones are as a monolithic system, as a hierarchy of layers, as a virtual machine system,
using an exokernel, and using the client-server model.

\section{Problems}
\begin{enumerate}
\item What are the two main functions of an operating system?
\item What is the difference between kernel mode and user mode? Why is the difference important to an operating system?
\item What is multiprogramming?
\item What is spooling? Do you think that advanced personal computers will have spooling as a standard feature in the future?
\item One early computers, every byte of data read or written was directly handled by the CPU (i.e., there was no DMA Directed Memory Access).
      What implications does this organization have for multiprogramming?
\item Why was timesharing not widespread on second-generation computers?
\item Which of the following instructions should be allowed only in kernel mode?\\
      (a) Disable all interrupts.\\
      (b) Read the time-of-day clock.\\
      (c) Set the time-of-day clock.\\
      (d) Change the memory map.
\item List some differences between personal computer operating systems and mainframe operating systems.
\item Give one reason why a closed-source proprietary operating system like Windows should have better quality than 
      an open source operating system like Linux.
      Now give one reason why an open-source operating system like Linux should have better quality than 
      a closed-source proprietary operating system like Windows.
\item A MINIX file whose owner has UID = 12 and GID = 1 has mode \sys{rwxr-x---}.
      Another user with UID = 6, GID = 1 tries to execute the file. What will happen?
\item In view of the fact that the mere existence of a superuser can lead to all kinds of security problems, why does such a concept exist?
\item All versions of UNIX support file naming using both absolute paths (relative to the root) and 
      relative paths (relative to the working directory). 
      Would it be possible to dispose of one of these and just use the other?
      If so, which would you suggest keeping?
\item Why is the process table needed in a timesharing system?
      Is it also needed in personal computer systems in which only one process exists,
      that process taking over the entire machine until it is finished?
\item What is the essential difference between a block special file and a character special file?
\item In MINIX 3 if user 2 links to a file owned by user 1, then user 1 removes the file, what happens when user 2 tries to read the file?
\item Are pipes an essential facility? Would major functionality be lost if they were not available?
\item Modern consumer appliances such as stereos and digital cameras often have a display 
      where commands can be enterned and the results of entering those commands can be viewed.
      These devices often have a primitive operating system inside.
      To what part of a personal computer software is the command processing via the stereo or camera's display similar to?
\item Windows does not have a \cmd{fork} system call, yet it is able to create new processes.
      Make an educated guess about the semantics of the system call Windows uses to create new processes.
\item Why is the \cmd{chroot} system call limited to the superuser? (Hint: Think about protection problems.)
\item Examine the list of system calls in Fig. 1-9.
      Which call do you think is likely to execute most quickly.
      Explain your answer.
\item Suppose that a computer can execute 1 billion instructions/sec and that a system call takes 1000 instructions,
      including the trap and all the context switching.
      How many system calls can the computer execute per second and still have half the CPU  capacity for running application code?
\item There is a \cmd{mknod} system call in Fig. 1-16 but there is no \cmd{rmnod} call.
      Does this mean that you have to be very, very careful about making nodes this way because there is no way to every remove them?
\item Why does MINIX 3 have the program \sys{update} running in the background all the time?
\item Does it ever make any sense to ignore the SIGALARM signal?
\item The client-server model is popular in distributed systems.
      Can it also be used in a single-computer system?
\item The initial version of the Pentium could not sopport a virtual machine monitor.
      What essential characteristics is needed to allow a machine to be virtualizable?
\item Write a program (or series of programs) to test all the MINIX 3 system calls.
      For each call, try various sets of parameters, including some incorrect ones, to see if they are detected.
\item Write a shell that is similar to Fig. 1-10 but contains enough code that it actually works so you can test it.
      You might add some features such as redirection of input and output, pipes, and background jobs.
\end{enumerate}


\chapter{Processes}
We are now embark on a detailed study of how operating systems, ingeneral, and MINIX, in particalur, are designed and constructes.
The most central concept in any operating system is the \sys{process}: an abstraction of a running program.
Everything else hinges on this concept, and it is important that the operating system designer (and student) understand this concept well.

\section{Introduction to Processes}
All modern computers can do several things at the same time.
While running a user program, a computer can also be reading from a disk and outputting text to a screen or printer.
In a multiprogramming system, the CPU also swithches from program to program, 
running each for tens or hundreds of milliseconds.
While, strictly speaking, at any instant of time, the CPU is running only one program, 
in the course of 1 second, it may work on several programs, thus giving the users the illusion of parallelism.
Sometimes people speak of \kw{pseudoparallelism} in this context, 
to constrast it with the true hardware parallelism of \kw{multiprocessor} systems (which have two or more CPUs sharing the same physical memory).
Keeping track of multiple, parallel activities is hard for people to do.
Therefore, operating system designers over the years have evolved a conceptual model (sequential process) 
that makes parallelism easier to deal with.
That model, its uses, and some of its consequences form the subject of this chapter.

\subsection{The Process Model}
In this model, all the runnable software on the computer, sometimes including the operating system, 
is organized into a number of \kw{sequential processes}, or just \kw{processes} for short.
A process is just an executing program, including the current values of the program counter, registers, and variables.
Conceptually, each process has its own virtual CPU.
In reality, of course, the real CPU swithches back and forth from process to process,
but to understand the system, it is much easier to think about a collection of processes running in (pseudo) parallel,
than to try to keep track of how the CPU swithces from program to program.
This rapid switching back and forth is called \kw{multiprogramming}, as we saw in Chap. 1.

In Fig. 2-1(a) we see a computer multiprogramming four programs in memory.
In Fig. 2-1(b) we see four processes, each with its own flow of control (i.e., its own program counter), 
and each one running independently of the other ones.
Of course, there is only one physical program counter, so when each process runs, 
its logical program counter is loaded in to the real program counter. 
When it is finished for the time being, the physical program counter is saved in the process' logical program counter in memory.
In Fig. 2-1(c) we see that viewed over a long enough time interval, all the processes have made progress,
but at any given instant only one process is actually running.

With the CPU switching back and forth among the process, the rate at which a process performs its computation will not be uniform, 
and probably not even reproducible if the same processes are run again.
Thus, processes must not be programmed with built-in assumptions about timing.
Consider, for example, an I/O process that starts a streamer tape to restore backed up files,
executes an idle loop 10,000 times to let it get up to speed, and then issues a command to read the first record.
It the CPU decides to switch to another process during the idel loop,
the tape process might not runagain yntill after the first record was already past the read head.
When a process has critical real-time requirements like this, that is, 
particular events must occur within a specified number of milliseconds, special measures must be taken to ensure that they do occur.
Normally, however, most processes are not affected by the underlying multiprogramming of the CPU or the relative speeds of different processes.

The difference between a process and a program is subtle, but crucial.
An analogy may help make this pointer cleaner.
Consider a culinary-mind computer scientist who is backing birthdsy cake for his daughter.
He has a birthday cake recipe and a kitchen well stocked with the necessary input:
flour, eggs, sugar, extract of vanilla, and so on.
In this analogy, the recipe is the processor (CPU), and the cake ingredients are the input data.
The process is the activity consisting of our baker reading the recipe, fetching the ingredients, and baking the cake.
 
Now imagine that the computer scientist's son comes running in crying, saying that he has been stung by a bee.
The computer scientist records where he was in the recipe (the state of the current process is saved),
gets out a first aid book, and begins following the directions in it.
Here we see the processor being switched from one process (baking) to a higher priority process (administering medical care),
each having a different program (recipe vs. first aid book).
When the bee sting has been taken care of, the computer scientist goes back to his cake,
continuing the point where he left off.

The key idea here is that a process is an activity of some kind.
It has a program, input, output and a state.
A single processor may be shared among several processes, with some scheduling algorithm being used to do determine
when to stop work on one process and service a different one.

\subsection{Process Creation}
Operating systems need some way to make sure all the necessary processes exist.
In very simple systems, or in systems designed for running only a single application (e.g., controlling a device in real time),
it may be possible to have all the processes that will ever be needed be present when the system comes up.
In general-purpose systems, however, some way is needed to create and terminate processes as needed during operation.
We will now look at some of the issues.

There are four principal events that cause processes to be created:
\begin{enumerate}
  \item System initialization.
  \item Execution of a process creation system call by running process.
  \item A user request to create a new process.
  \item Inition of a batch job.
\end{enumerate}

When an operating system is booted, often several processes are created.
Some of these are foregroud process, that is, processes that interact with (human) user and perform work for them.
Others are backgroud processes, which are not associated with particular users, but instead have some special function.
For example, a backgroud process may be designed to accept incoming requests for web pages hosted on that machine,
waking up when a request arrives to service the request.
Processes that say in the backgroud to handle some activity such as web pages, printing, and so on are called \kw{daemons}.
Large systems commonly have dozens of them.
In MINIX 3, the \sys{ps} program can be used to list the running processes.

In addition to the processes created at boot time, new processes can be created afterwards as well.
Often a running process will issue system calls to create one or more new processes to help it do its job.
Creating new processes is particularly useful when the work to be done can easily be formulated in terms of several related,
but otherwise independent interacting processes.
For example, when compiling a large program, the \sys{make} program invokes the C compiler to convert source file to object code,
and then it invokes the \kw{install} program to copy the program to its destination, 
set ownership and permissions, etc.
In MINIX 3, the C compiler itself is actually several different programs, which work together.
These include a preprocessor, a C language parser, an assembly language code generator, an assembler, and a linker.

In interactive systems, users can start a program by typing a command.
In MINIX 3, virtual consoles allow a user to start a program, say a compiler, 
and then switch to an alternate console and start another program,
perhaps to edit documentation while the compiler is running.

The last situation in which processes are created applies only to the batch systems found on large mainframes.
Here users can submit batch jobs to the system (possibly remotely).
When the operating system decides that it has the resources to run another job,
it create a new process and runs the next job from the input queue in it.

Technically, in all these cases, a new process is created by having an existing process execute a process creation system call.
That process may be a running user process, 
a system process invoked from the keyboard or mouse,
or a batch manager process.
What that process does is execute a system call to create the new process.
This system call tells the operating system to create a new process and indicates, directly or indirectly,
which program to run in it.

In MINIX 3, there is only one system call to create a new process: \cmd{fork}.
This call creates an exact clone of the calling process.
After the \cmd{fork}, the two processes, the parent the child, have the same memory image, the same environment strings, and the same open files.
That is all there is.
Usually, the child process then executes \cmd{execve} or a similar system call to change its memory image and run a new program.
For example, when a user types a command, say, \sys{sort}, to the shell,
the shell forks off a child process and the child executes \sys{sort}.
The reason for this two-step process is to allow the child to manipulate its file descriptors after the \cmd{fork} 
but before the \cmd{execve} to accomplish redirection of standard input, standard output, and standard error.

In both MINIX 3 and UNIX, after a process is created both the parent and child have their own distinct address spaces.
If either process changes a word in its address space, the change is not visible to the other process.
The child's initial address space is a \sys{copy} of the parent's,
but there are two distinct address space involved; no writable memory is shared (like some UNIX implementations, 
MINIX 3 can share the program text between the two since that cannot be modified).
It is, however, possible for a newly created process to share some of its creator's other resources, such as open files.

\subsection{Process Termination}
After a process has been created, it starts running and does whatever its job is.
However, nothing lasts forever, not even processes.
Sooner or later the new process will terminate, usually due to one of the following conditions:
\begin{enumerate}
  \item Normal exit (voluntary).
  \item Error exit (voluntary).
  \item Fatal error (voluntary).
  \item Killed by another process (involuntary).
\end{enumerate}

Most processes terminate because they have done their work.
When a compiler has compiled the program given to it, 
the compiler executes a system call to tell the operating system that it is finished.
This call is \cmd{exit} in MINIX 3.
Screen-oriented programs also support voluntary termination.
For instance, editors always have a key combination that the user can invoke to tell the process to save the working file, 
remove any temporary file are open and terminate.

The second reason for termination is that the process discovers a fatal error.
For example, if a user types the command\\
\cmd{cc foo.c}\\
to compile the program \sys{foo.c} and no such file exists, the compiler simply exits.

The third reason for termination is an error caused by the process, perhaps due to a program bug.
Examples include executing an illegal instruction, referencing nonexistent memory, or dividing by zero.
In MINIX 3, a process can tell the operating system that it wishes to handle certain errors itself,
in which case the process is signaled (interrupted) instead of terminated when one of the errors occurs.

The fourth reason a process might terminate is that one process executes a system call telling the operating system to kill some other process.
In MINIX 3, this call is \cmd{kill}.
Of course, the killer must have the necessary authorization to do in the killee.
In some system, when a process terminates, either voluntarily or otherwise,
all processes it created are immediately killed as well.
MINIX 3 does work this way, however.

\subsection{Process Hierarchies}
In some systems, when a process creates another pprocess,
the parent and child continue to be associated in certain ways.
The child can itself create more process, forming a process hierarchy.
Unlike plants and animals that use sexual reproduction,
a process has only one parent (but zero, one, two, or more children).

In MINIX 3, a process, its children, and further descendants together may form a process group.
When a user sends a signal from the keyboard, the signal may be delivered to all members of the process group
associated with the keyboard (usaully all process that were created in the current window).
This is signal-dependent.
If a signal is sent to a group, each process can catch the signal, ignore the signal, or take the degault action,
which is to be killed by the signal.

As a simple example of how process trees are used, let us look at how MINIX initializes itself.
Two special processes, the \kw{reincarnation server} and \kw{init} are present in the boot image.
The reincarnation server's job is to (re)start drivers and servers.
It begins by blocking, waiting for a message telling it what to create.

In contrast, \sys{init} executes the \sys{/etc/rc} script that causes it to issue commands to the reincarnation server
to start the drivers and servers not present in the boot image.
This procedure make the drivers and servers so started children of the reincarnation server,
so if any of them ever terminate, the reincarnation server will be informed and can restart (i.e., reincarnation) them again.
This mechanism is intended to allow MINIX 3 to tolerate a driver or server crash because a new one will be started automatically.
IN practice, replacing a driver is much easier than replacing a server, however,
since there fewer repercussions elsewhere in the system.
(And, we do not say this always work perfectly; it is still work in progress.)

When \sys{init} has finished this, it reads a configuration file \sys{/etc/ttytab} to see which terminals and virtual terminal exist.
\sys{Init} \cmd{fork}s is a \sys{getty} process for each one, displays a login prompt on it, and then wait for input.
When a name is typed, \sys{getty} \cmd{exec}s a \sys{login} process with the name as its argument.
If the user succeeds in logging in, \sys{login} will \cmd{exec} the user's shell.
So the shell is a child of \sys{init}.
User commands create children of the shell, which are granchildren of \sys{init}.
This sequence of events is an example of how process trees are used.
As an aside, the code for the reincarnation server and \sys{init} is not listed in this book; neither is the shell.
The line had to be drawn somewhere.
But now you have the basic idea.

\subsection{Process Status}
Although each process is an independent entity, 
with its own program counter registers, stack, open files, alarms, and other internal state,
processes often need to interact, communicate, and synchronize with other processes.
One process may generate some output that another process uses as input, for example.
In the case, the data needs to be moved between processes.
In the shell command\\
\cmd{cat chapter1 chapter2 chapter3 | grep tree}\\
the first process, running \sys{cat}, concatenates and output three files.
The second process, running \sys{grep}, selects all lines containing the word ``tree''.
Depending on the relative speeds of the two processes (which depends on both 
the relative complexity of the programers and how much CPU time each one has had),
it may happen that \sys{grep} is ready to run, but there is no input waiting for it.
It must then \kw{block} until some input available.

When a process blocks, it does so because logically it cannot continue, 
typically because it is waiting for input that is not yet available.
It is also possible for a process that is conceptually ready and able to run to be stopped 
because the operating system has decided to allocate the CPU to another process for a while.
These two conditions are completely different.
In the first case, the suspension is inherent in the problem 
(you cannot process the user's command line until it has been typed).
In the second case, it is technically of the system (not enough CPUs to give each process its own private processor).
In Fig. 2-2 we see a state digram showing the three states a process may be in:
\begin{enumerate}
  \item Running (actually using the CPU at that instant).
  \item Ready (runnable; temporarily stopped to let another process run).
  \item Blocked (unable to run until some external event happens).
\end{enumerate}

Logically, the first two states are similar.
In both cases the process is willing to run, only in the second one, there is temporarily no CPU available for it.
The third state is different from the first two in that the process cannot run, even if the CPU has nothing else to do.

Four transitions are possible among these three states, as shown.
Transition 1 occurs when a process discovers that it cannot continue.
In some systems the process must execute a system call, \cmd{block} or \cmd{pause} to get into blocked state.
In other systems, including MINIX 3, when a process reads from a pipe or special file (e.g., a terminal) and there is no input available,
the process is automatically moved from the running state to the block state.

Transition 2 and 3 are caused by the process schedular, a part of the operating-system,
without the process even knowing about them.
Transition 2 occurs when the scheduler decides that the running process has run long enough,
and it is time to let another process have some CPU time.
Transition 3 occurs when all the other processes have had their fair share 
and it is time for the first process to get the CPU to run again.
The subject of scheduling deciding which process should run when and for how long is an important one.
Many algorithms have been devised to try to 
balance the competing demands of efficiency for the system as a whole and fairness individual processes.
We will look at sheduling and study some of these algorithms later in this chapter.

Transition 4 occurs when the external event for which a process was waiting (e.g, the arrival of some input) happens.
If no other process is running then, transition 3 will be triggered immediately,
and the process will start running.
Otherwise it may have to wait in \sys{ready} state for a little while untill the CPU is available.

Using the process model, it becomes much easier to think about what is going on inside the system.
Some of the process run programs that carry out commands typed by a user.
Other processes are part of the system and handle tasks such as carrying out requests for file services 
or managing the details of running a disk or a tape drive.
When a disk interrupt occurs, the system may make a decision to stop running the current process and run the disk process,
which was blocked waiting for the interrupt.
We say ``may'' because it depends upon relative priorities of the running process and the disk driver process.
But the point is that instead of thinking about interrupts, we can think about user processes, disk processes, terminal processes, and so on,
which block when thay are waiting for something to happen.
When the disk block has been read or the character typed, the process waiting for it is unblocked
and is eligible to run again.

This view gives rise to the model shown in Fig. 2-3.
Here the lowest level of the operating system is the schedular, with a variety of processes on top of it.
All the interrupt handling and details of actually starting and stopping processes are hidden away in the scheduler,
which is actually quite small.
The rest of the operating system is nicely structyred in process form.
The model of Fig. 2-3 is used in MINIX 3.
Of course, the ``scheduler'' is not the only thing in the lowest layer, 
there also support for interrupt handling and interprocess communication.
Neverthless, to a first approximation, it does show the basic structure.

\subsection{Implementation of Processes}
To implement the process model, the operating system maintains a table (an array of structures),
called the \kw{process table}, with one entry per process.
(SOme authors call these entries \kw{process control blocks}.)
This entry contains information about the process' state, its program counter, stack pointer, memory allocation,
the state of its open files, its accounting and scheduling information, alarms and other signals,
and everything else about the process that must be saved when the process is switched from \sys{running} to \sys{ready} state 
so that it can be restarted later as if it had never been stopped.

In MINIX 3, interprocess communication, memory management, and file management are each handled by seperate modules within the system,
so the process table is partitioned, with each module maintaining the fields that it needs.
Fig. 2-4 shows some of the more important fields.
The fields in the first column are the only ones relevant to this chapter.
The other two columns are provided just to give an idea of what information is needed elsewhere in the system.

Now that we have looked at the process table,
it is possible to explain a little more about how the illusion of multiple sequential process is maintained 
on a machine with one CPU and many I/O devices.
What follows is technically a description of how the ``scheduler'' of Fig. 2-3 works in MINIX 3 
but most modern operating systems work essentially the same way.
Associated with each I/O device class (e.g., floppy disks, hard disks, timers, terminals) is a data structure in a table 
called the \kw{interrupt descriptor table}.
The most important part of each entry in this table is called the \kw{interrupt vector}.
It contains the address of the interrupt service procedure.
Suppose that user process 23 is running when a disk interrupt occurs.
The program counter, program status word, and possibly one or more registers are pushed onto the (current) stack by the interrupt hardware.
The computer then jumps to the address specified in the disk interrupt vector.
That is all the hardware does.
From here on, it is up to the software.

The interrupt service procedure starts out by saving all the registers in the process table entry for the current process.
The current process number and a pointer to its entry are kept in global variables so they can be found quickly.
Then the information deposited by the interrupt is removed from the stack, 
and the stack pointer is set to a temporary stack used by the process handler. 
Actions such as saving the registers and setting the stack pointer cannot even be expressed in high-level languages such as C,
so they are performed by a small assembly language routine.
When this routine is finished, it calls a C procedure to do the rest of the work for this specific interrupt type.

Interprocess communication in MINIX 3 is via message,
so the next step is to built a message to be sent to the disk process,
which will be blocked waiting for it.
The message says that an interrupt occured,
to distinguish it from messages from user processes requesting disk blocks to be read and things like that.
The state of the disk process is now changed from \sys{blocked} to \sys{ready} and scheduler is called.
In MINIX 3, different processes have different priorities, 
to give better service to I/O device handlers than to user processes, for example.
If the disk process is now the highest priority runnable process, it will be scheduled to run.
If the process that was interrupted is just as important or more so, 
then it will be scheduled to run again, and the disk process will have to wait a little while.

Either way, the C procedure called by the assembly language interrupt code now returns,
and the assembly language code loads up the registers and memory map for the now-current process and starts it running.
Interrupt handling and scheduling are summarized in Fig. 2-5.
It is worth nothing that the details vary slightly from system to system.

\subsection{Threads}
In traditional operating systems, each process has an address space and a single thread of control.
In fact, that almost the definition of a process.
Nevertheless, there are often situations in which it is desirable to 
have multiple threads of control in the same address space running in quasi-parallel,
as though they were seperate processes (except for the shared address space).
These threads of control are usually just called \kw{threads},
although some people call them \kw{lightweight processes}.

One way of looking at a process is that it is a way to group related resources together.
A process has an address space containing program text and data, as well as other resources.
These resources may include open files, child processes, pending alarms, signal handlers, accounting information, and more.
By putting them together in the form of a process, they can be managed more easily.

The other concept a process has is a thread of execution, usually shortened to just \kw{thread}.
The thread has a program counter that keeps track of which instruction to execute next.
It has registers, which hold its current working variables.
It has a stack, which contains the execution history, with one frame for each procedure called but not yet returned from.
Although a thread must execute in some process, the thread and its process are different concepts and can be treated seperately.
Processes are used to group resources together; threads are the entities scheduled for execution on the CPU.

What threads add to the process model is to allow multiple executions to take place in the same process environment,
to a large degree independent of one another.
In Fig. 2-6(a) we see three traditional processes.
Each process has its own address space and a single thread of control.
In contrast, in Fig. 2-6(b) we see a single process with three threads of control.
Although in both cases we have three threads, in Fig. 2-6(a) each of them operates in a different address space, 
whereas in Fig. 2-6(b) all three of them share the same address space.

As an example of where multiple threads might be used, consider a web browser process.
Many web pages contain multiple small images.
For each image on a web page, the browser must set up a separate connection to the pages's home site and request the image.
A great deal of time is spent establing and releasing all these connections.
By having multiple threads within the browser, many images can be requested at the same time, 
greatly speeding up performance in most cases since with small images, 
the set-up time is the limiting factor, not the speed of the transmission line.

When multiple threads are present in the same address space, a few of the fields of Fig. 2-4 are not per process, but per thread,
so a separate thread table is needed, with one entry per thread.
Among the per-thread items are the program counter, registers, and state.
The program counter is needed because threads, like process, can be suspended and resumed.
The registers are needed because when threads are suspended, their registers must be saved.
Finally, threads, like processes, can be in \sys{running}, \sys{ready}, or \sys{blocked} state.
Fig. 2-7 lists some per-process and per-thread items.

In some systems, the operating system is not aware of the threads.
In other words, they are managed entirely in user space.
When a thread is about to block, for example, it chooses and starts its successor before stopping.
Several userlevel threads packages are in common use, including the POSIX \kw{P-threads} and Mach \kw{C-threads} packages.

In other operating systems, the operating system is aware of the existence of multiple threads per process,
so when a thread blocks, the operating system chooses the next one to run, either from the same process or a different one.
To do scheduling, the kernel must have a thread table that lists all the threads in the system,
anologous to the process table.

Although these two alternatives may seem equivalent, they differ considerably in performance.
Switching threads is much faster when thread management is done in user space than when a system call is needed.
This fact argues strongly doing thread management in user space.
On the other hand, when thread are managed entirely in user space and one thread blocks (e.g., waiting for I/O or a page fault to be handled),
the kernel blockes the entire process, since it is not even aware that other thread exist.
This fact as well as others argue for doing thread management in the kernel (Boehm, 2005).
As a consequence, both systems are in use, and various hybrid schemes have been proposed as well (Anderson et al., 1992).

No matter wether threads are managed by the kernel or in user space, they introduce a taft of problems
that must be solved and which change the programming model appreciably.
To start with, consider the effects of the \cmd{fork} system call.
If the parent process has multiple threads, should the child also have them?
If not, the process may not function properly, since all of them may be essential.

However, if the child process gets as many threads as the parent, 
what happens if thread was blocked on a \cmd{read} call, say, from the keyboard?
Are two threads now blocked on the keyboard?
When a line is typed, do both threads get a copy of it?
Only the parent?
Only the child?
The same problem exists with open network connections.

Another class of problems is related to the fact that threads share many data structures.
What happens if one thread closes a file while another one is still reading from it?
Suppose that one thread notices that there is too little memory and starts allocating more memory.
Then, part way through, a thread switch occurs, 
and the new thread also notices that there is too little memory and starts allocating more momery.
Does the allocation happen once or twice?
IN nearly all systems that were not designed with threads in mind,
the libraries (such a s the memory allocation procedure) are not reentrant,
and will crash if a second call is made while the first one still active.

Another problem relates to error reporting.
In UNIX, after a system call, the status of the call is put into a global variable, \sys{errno}.
What happens if a thread makes a system call, and before it is able to read \sys{errno},
another thread makes a system call, wiping out the original value?

Next, consider signals.
Some signals are logically thread specific; others are not.
For example, if a thread calls \sys{alarm}, it makes sense for the resulting signal to go to the thread that made the call.
When the kernel is aware of threads, it can usually make sure the right thread gets the signal.
When the kernel is not aware of threads, the threads package must keep track of alarms by itself.
An additional complication for user-level threads exists when (as in UNIX) a process may only have one alarm at a time pending
and several threads call \cmd{alarm} independently.

Other signals, such as a keyboard-initiated SIGINT, are not thread specific?
Who should catch them?
One designated thread?
All the threads?
A newly created thread?
Each of these solutions has problems.
Furthermore, what happens if one thread changes the signal handlers without telling other threads?

One last problem introduced by thread is stack management.
In many systems, when stack overflow occurs, the kernel just provides more stack, automatically.
When a process has multiple threads, it must also have multiple stacks.
If the kernel is nor aware of all these stacks, it cannot grow them automatically upon stack fault.
In fact, it may not even realize that a memory fault is related to stack growth.
 
\section{Interprocess Communication}
Process frequently need to communicate with other processes.
For example, in a shell pipeline, the output of the first process must be passed to the second process, and so on down the line.
Thus there is a need for communication between processes, 
preferably in a well-structured way not using interrupts.
In the following sections we will look at some of the issues related to this \kw{InterProcess Communication} or \kw{IPC}.

There are three issues here.
The first was alluded to above:how one process can pass information to another.
The second has to do with making sure two or more processes do not get each other's way 
when engaging in critical activities (suppose two processes each try to grab the last 1 MB of memory).
The third concerns proper sequencing when dependencies are present: if process A produces data and process B print it, 
B has to wait until A has produced some data before starting to print.
We will examine all three of these of these issues in this section.

It is also important to mention that two of these issues apply equally well to threads.
The first one passing informations easy for threads since they share a common address space 
(threads in different address space that need to communication fall under the heading of communicating processes).
However, the other two keeping out of each other's hair and proper sequencing apply as well to threads.
The same problems exist and the same solutions apply.
Below we will discuss the problem in the context of processes,
but please keep in mind that the same problems and solutions also apply to threads.

\subsection{Race Conditions}
In some operating systems, processes that we are working together may share some common storage
that each one can read and write.
The shared storage may be in main memory (possibly in a kernel data structure) or it may be shared file;
the location of the shared memory does not change the nature of the communication or the problems that arise.
To see how interprocess communication works in practice, let us consider a simple but common example, a print spooler.
When a process wants to print a file, it enters the file name in a special \kw{spooler directory}.
Another process, the \kw{printer daemon}, periodically checks to see if so are any files to be printed,
and if so removes their name from the directory.

Imagine that our spooler directory has a large number of slots, numberd 0, 1, 2, ..., 
each one capable of holding a file name.
Also imagine that there are two shared variables, 
\sys{out}, which points to the next file to be printed,
and \sys{in}, which points to the next free slot in the directory.
These two variables might well be kept in a two-word file available to all processes.
At a certaininstant, sots 0 to 3 are empty (the files have already been printed) and slots 4 to 6 are full (with the names of files to be printed).
More or less simultaneously, process A and B decide they want to queue a file for printing.
This situation is shown in Fig. 2-8.

In jurisdictions where Murphy's law is applicable, the following might well happen.
Process A reads \sys{in} and store the value, 7, in a local variable called \sys{next\_free\_slot}.
Just then a clock interrupt occurs and the CPU decides that process A has run long enough, 
so it switches to process B.
Process B also reads \sys{in}, and also gets a 7, so it stores the name of its file in slot 7 and update \sys{in} to be an 8.
Then it goes off and does other things.

Eventually, process A runs again, starting from the place it left off last time.
It looks at \sys{next\_free\_slot}, find a 7 there, and write its file name in slot 7, erasing the name that process B just put there.
Then it computes \sys{next\_free\_slot} + 1, which is 8, and set \sys{in} to 8.
The spooler directory is now internally consistent, so the printer daemon will not notice anything wrong,
but process B will never receive any output.
User B will hang around the printer room for yaers, wistfully hoping for output that never comes.
Situations like this, where two or more processes are reading or writing some shared data 
and the final result depends on who runs precisely when, called \kw{race conditions}.
Debugging programs containning race conditions is no fun at all.
The results of most test runs are fine, but once in a blue moon something weird and unexplained happens.

\subsection{Critical Sections}
How do we avoid race conditions?
The key to preventing trouble here and in many other situations involving shared memory, shared files, and shared everything else 
is to find some way to prohibit more than one process from reading and writing the shared data at the same time.
Put in other words, what we need is \kw{mutual exclusion} some way of making sure that
if one process is using a shared variable or file, the other processes will be excluded from doing the same thing.
The difficulty above occurred because process B started using one of the shared variables before process A was finished with it.
The choice of approprite primitive operations for achieving mutual exclusion is a major design issue in any operating system,
and a subject that we will now examine in great detail.

The problem of avoiding race conditions can also be formulated in an abstract way.
Part of the time, a process is busy doing internal computations and other things that do not lead to race conditions.
However, sometimes a process may be accessing shared memory or files.
That part of the program where the shared memory is accessed is called the \kw{critical region} or \kw{critical section}.
If we could arrange matters such that no two processes were ever in their critical regions at the same time, we could avoid race conditions.

Although this requirement avoids race conditions, 
this is not sufficient for having parallel processes cooperate correctly and efficiently using shared data.
We need four conditions to hold to have a good solution:
\begin{enumerate}
  \item No two processes may be simultaneously inside their critical regions.
  \item No assumptions may be made about soeeds or the number of CPUs.
  \item No process running outside its critical region may block other process.
  \item No process should have to wait forever to enter its critical region.
\end{enumerate}

The behavior that we wants is shown in Fig. 2-9.
Here process A enters its critical region at time \sys{T1}.
A little later, at time \sys{T2} process B attempts to enter its critical region but fails 
because another process is already in its critical region and we allow only one at a time.
Consequently, B is temporarily suspended until time \sys{T3} when A leaves its critical region, allowing B to enter immediately.
Eventually B leaves (at \sys{T4}) and we are back to the original situation with no processes in their critical regions.

\subsection{Mutual Exclusion with Busy Waiting}
iIn this section we will examine various proposals for achiving mutual exclusion,
so that while one process is busy updating shared memory in its critical region,
no other process will enter its critical region and cause trouble.
\subsubsection*{Disabling Interrupt}
The simplest solution is to have each process disable all interrupts just after entering its critical region 
reenable them just before leaving it.
With interrupts disabled, no clock interrupts can occur.
The CPU is only switched from process to process as a result of clock or other interrupts, after all,
and with interrupts turned off the CPU will not be switched to another process.
Thus, once a process has disabled interrupts, it can examine and update the shared memory without fear that any other process will intervence.

This approach is generally unattractive because it is unwise to give user processes the power to turn off interrupts.
Suppose that one of them did, and then never turned them on again?
That could be the end of the system.
Furthermore, if the system is a multiprocessor, with two or more CPUs, 
disabling interrupts affects only CPU that executed the disable instruction.
The other one will continue running and can access the shared memory.

On the other hand, it is frequently convenient for the kernel itself to disable interrupts 
for a few instructions while it is updating variables or lists.
If an interrupt occurred while the list of ready processes, for example, was in an inconsistent state, race conditions could occur.
The conclusion is: disabling interrupts is often a useful technique within the operating system itself
but is not appropriate as a general mutual exclusion mechanism for user processes.

\subsubsection*{Lock Variables}
As a second attempt, let us look for a software solution.
Consider having a single, shared, (lock) variable, initially 0.
When a process wants to enter its critical region, it first tests the lock.
If the lock is 0, the process sets it to 1 and enters the critical region.
If the lock is already 1, the process just waits until it becomes 0.
Thus, a 0 means that no process is in its critical region, and a 1 means that some process is in its critical region.

Unfortunately, this idea contains exactly the same fatal flaw that we saw in the spooler directory.
Suppose that one process reads the lock and sees that it is 0.
Before it can set the lock to 1, another process is scheduled, runs, and sets the lock to 1.
When the first process runs again, it will also set the lock to 1, and two processes will be in their critical regions at the same time.

Now you might think that we could get around this problem by first reading out the lock value,
then checking it again just before storing into it, but that really does not help.
The race now occurs if the second process modifies the lock just after the first process has finished its second check.

\subsubsection*{Strict Alternation}
A third approach to the mutual exclusion problem is shown in Fig. 2-10.
This program fragment, like most others in this book, is written in C.
C was chosen here because real operating systems are commonly written in C (or occasionally C++),
but hardly ever in languagees like Java.
C is powerful, efficient, and predictable, characteristics critical for writing operating systems.
Java, for example, is not predictable because it might run out of storage at a critical moment 
and need to invoke the garbage collector at a most inopportune time.
This cannot happen in C because there is no garbage collection in C.
A quantitative comparison of C, C++, Java, and four other languages is given by Prechelt (2000).

In fig. 2-10, the integer variable \sys{turn}, initially 0, keeps track of whose turn it is to enter the critical region
and examine or update the shared memory.
Initially, process 0 inspects \sys{turn}, finds it to be 0, and enters its critical region.
Process 1 also find it to be 0 and therefore sits in a tight loop continually testing \sys{turn} to see when it becomes 1.
Continuously testing a variable until some value appears is called \kw{busy waiting}.
It should usually be avoided, since it wastes CPU time.
Only when there is a reasonable expectation that the wait will be short is busy waiting used.
A lock that uses busy waiting is called a \kw{spin lock}.

When process 0 leaves the critical region, it sets \sys{turn} to 1, to allow process 1 to enter its critical region.
Suppose that process 1 finishes its critical region quickly, so both processes are in their noncritical regions,
with \sys{turn} set to 0.
Now process 0 executes its whole loop quickly, exiting its critical region and setting \sys{turn} to 1.
At this point \sys{turn} is 1 and both processes are executing in their noncritical regions.

Suddenly, process 0 finishes its noncritical region and goes back to the top of its loop.
Unfortunately, it is not it is not permitted to enter its critical region now, 
because \sys{turn} is 1 and process 1 is busy with its noncritical region.
It hangs in its \cmd{while} loop until process 1 sets \sys{turn} to 0.
Put differently, taking turns is not a good idea when one of the processes is much slower than the other.

This situation violates condition 3 set about above: 
process 0 is being blocked by a process not in its critical region.
Going back to the spooler directory discussed above,
if we now associate the critical region with reading and writing the spooler directory, 
process 0 would not be allowed to print another file because process 1 was doing something else.

In fact, this solution requires that the two processes strictly alternate in entering their critical regions,
for example, in spooling files.
Neither one would be permitted to spool two in a row.
While this algorithm does avoid all races, it is not really a serious candidate as a solution 
because it violates condition 3.

\subsubsection*{Peterson's Solution}
By combining the idea of taking turns with the idea of lock variables and warning variables,
a Dutch mathematician, T. Dekker, was the first one to devise a software solution to the mutual exclusion problem
that does not require strict alternation.
In 1981, G.l. Peterson discovered a much simpler way to achieve mutual exclusion, 
thus rendering Dekker's solution obsolete.
Peterson's algorithm is shown in Fig. 2-11.
This algorithm consists of two procedure written in ANSI C, 
which means that function prototypes should be supplied for all the functions defined and used.
However, to save space, we will not show the prototype in this or subsequent example.

Before using the shared variables (i.e., before entering its critical region),
each process calls \sys{enter\_region} with its own process number, 0 or 1, as the parameter.
This call will cause it to wait, if need be, until it is safe to enter.
After it has finished with the shared variables, the process calls \sys{leave\_region} to indicate that it is done 
and to allow the other process to enter, if so desires.

Let us see how this solution works.
INitially, neither process is in its critical region.
Now process 0 calls \sys{enter\_region}.
It indicates its interest by setting its array element and set \sys{turn} to 0.
Since 1 is not interested, \sys{enter\_region} returns immediately.
If process 1 now calls \sys{enter\_region}, it will hang there until \sys{intersted[0]} goes to FALSE, 
and event that only happens when process 0 calls \sys{leave\_region} to exit the critical region.

Now consider the case that both processes call \sys{enter\_region} almost simuteneously.
Both will store their process number in \sys{turn}.
Whichever store is done last is the one that counts; the first one is lost.
Suppose that process 1 stores last, so \sys{turn} is 1.
When both processes come to the \cmd{while} statement, process 0 executes it zero times and enters its critical region.
Process 1 loops and does not enter its critical region.

\subsubsection*{The TSL Instruction}
Now that let us look at a proposal that reuires a little help from the hardware.
many computers, especially those designed with multiple processors in mind, have an instruction\\
\cmd{TSL RX, LOCK}\\
(Test and Set Lock) that works as follows: 
it reads the contents of the memory word \sys{LOCK} into register \cmd{RX} 
and then stores a nonzero value at the memory address \sys{LOCK}.
The operations of reading the word and storing into it are guaranteed to be indivisible
no other processor can access the memory word until the instruction is finished.
The CPU executing the \cmd{TSL} instruction locks the memory bus to prohibit other CPUs from accessing memory until it is done.
 
To use the \cmd{TSL} instruction, we will use a shared variable, \sys{lock}, to coordinate access to shared memory.
When \sys{LOCK} is 0, any process may set it to 1 using the \cmd{TSL} instruction and then read or write the shared memory.
When it is done, the process sets \sys{LOCK} back to 0 using an ordinary \cmd{move} instruction.

How can this instruction be used to prevent two process from simultaneously entering their critical region?
The solution is given in Fig. 2-12.
There a four-instruction subroutine in a fictitious (but typical) assembly language is shown.
The first instruction copies the old value of \sys{LOCK} to the register and then sets \sys{lock} to 1.
Then the old value is compared with 0.
If it is nonzero, the lock was already set, so the program just goes back to the beginning and tests it again.
Sooner or later it will become 0 (when the process currently in its critical region is done with its critical region),
and the subroutine returns, with the lock set.
Clearning the lock is simple.
The program just stores a 0 in \sys{LOCK}.
No special instruction are needed.

One solution to the critical region problem is now straitforward.
Before entering its critical region, a process calls \sys{enter\_region}, which does busy waiting until the lock is free;
then it acquires the lock and returns.
After the critical region the process calls \sys{leave\_region}, which stores a 0 in \sys{LOCK}.
As with all solutions based on critical regions, the processes must call \sys{enter\_region} and \sys{leave\_region} 
at the correct times for the method to work.
If a process cheats, the mutual exclusion will fail.

\subsection{Sleep and Wakeup}
Both Peterson's solution and the solution using \cmd{TSL} are correct, but both have the defect of requiring busy waiting.
In essence, what these solutions do is this: when a process wants to enter its critical region, 
it checks to see if the entry is allowed.
If it is not, the process just sits in a tight loop waiting until it is.

Not only does this approach waste CPU time, but it can also have unexpected effects.
Consider a computer with two processes, H, with high priority and L, with low priority, which share a critical region.
The scheduling rules are such that H is run whenever it is in ready state.
At a certain moment, with L in its critical region, H becomes ready to run (e.g., an I/O operation completes).
H now begins busy waiting, but since L is never scheduled while H is running, 
L never gets the chance to leave its critical region, so H loops forever.
This situation is sometimes referred to as the \kw{priority inversion problem}.

Now let us look at some interprocess communication primitives that lock instead of wasting CPU time 
when they are not allowed to enter their critical region.
One of the simplest is the pair \cmd{sleep} and \cmd{wakeup}.
\cmd{sleep} is a system call that cause the caller to block, that is, be suspended until another process wakes it up.
The \cmd{wakeup} call has one parameter, the process to be awakened.
Alternatively, both \cmd{sleep} and \cmd{wakeup} each have one parameter, 
a memory address used to match up \cmd{sleep}s with \cmd{wakeup}s.

\subsubsection*{The Producer-Consumer Problem}
As an example of how these primitives can be used in practice,
let us consider the \kw{producer-consumer} problem (also known as the \kw{bounded buffer} problem).
Two processes share a common, fixed-size buffer.
One of them, the producer, puts information into the buffer, and the other one, the consumer, takes it out.
(It is also possible to generalize the problem to have \sys{m} producers and \sys{n} consumers, 
but we will only consider the case of one producer and one consumer because this assumption simplifies the solutions.)

Trouble arises when the producer wants to put a new item in the buffer, but it is already full.
The solution is for the producer to go to sleep, to be awakened when the consumer has removed one or more items.
Similarly, if the consumer wants to remove an item from the buffer and sees that the buffer is empty,
it goes sleep until the producer puts something in the buffer and wakes it up.

This approach sounds simple enough, but it leads to the same kinds of race conditions we saw earlier with the spooler directory.
To keep track of the number of items in the buffer, we will need a variable, \sys{count}.
If the maximum number of items the buffer can hold is N, the producer's code will first test to see if \sys{count} is N. 
If it is, the producer will go to sleep; if it is not, the producer will add an item and increment \sys{count}.

The consumer's code is similar: first test \sys{count} to see if it is 0.
If it is, go to sleep; if it is nonzero, remove an item and decrement the counter.
Each of the processes also tests to see if the other should be sleeping, and if not, wakes it up.
The code for both producer and consumer is shown in Fig. 2-13.

To express system calls such as \cmd{sleep} and \cmd{wakeup} in C, we will show them as calls to library routines.
They are not part of the standard C library but presumably would be available on any system that actually had these system calls.
The procedures \sys{enter\_item} and \sys{remove\_item}, which are not shown,
handle the bookkeeping of putting items into the buffer and taking items out of the buffer.

Now let us get back to the trace condition.
It can occur because access to \sys{count} is unconstrained.
The following situation could possibly occur.
The buffer is empty and the consumer has just read \sys{count} to see if it is 0.
At that instant, the scheduler decides to stop running the consumer temporarily and start running the producer.
The producer enters an item in the buffer, increments \sys{count}, and notice that it is now 1.
Reasoning that \sys{count} was just 0, and thus the consumer must be sleeping, 
the producer calls \sys{wakeup} to wake the consumer up.

Unfortunately, the consumer is not yet logically asleep, so the wakeup signal is lost.
When the consumer next runs, it will test the value of \sys{count} it previously read, find it to be 0, and go to sleep forever.

The essence of the problem here is that a wakeup sent to a process that not (yet) sleeping is lost.
If it were not lost, everything would work.
A quick fix is to modify the rules to add a \kw{wakeup waiting bit} to the picture.
When a wakeup is sent to a process that is still awake, this bit is set.
Later, when the process tries to go to sleep, if the wakeup waiting bit is on, it will be turned off,
but the process will stay awake.
The wakeup waiting bit is a piggy bank for wakeup signals.


While the wakeup waiting bit saves the day in this simple example, 
it is easy to construct examples with three or more processes in which one wakeup waiting bit is insufficient.
We could make another patch, and add a second wakeup waiting bit, or maybe 8 or 32 of them, but in principle the problem is still there.

\subsection{Semaphores}
This was the situation until E. W. Dijkstra (1965) suggested using an integer variable to count the number of wakeups saved for future use.
In his proposal, a new variable type, called a \kw{semaphore}, was introduced.
A semaphore could have the value 0, indicating that no wakeups were saves, 
or some positive value if one or more wakeups were pending.

Dijkstra proposed having two operations, \cmd{down} and \cmd{up} 
(which are generalization of \cmd{sleep} and \sys{wakeup}, respectively).
The \cmd{down} operation on a semaphore checks to see if the value is greater than 0.
If so, it decrements the value (i.e., uses up one stored wakeup) and just continues.
If the value is 0, the process is put to sleep without completing the \cmd{down} for the moment.
Checking the value, changing it, and possibly going  to sleep is all dones as a single, indivisible, \kw{atomic action}.
It is guaranteed that once a semaphore operation has started, 
no other process can access the semaphore untill the operation has completed or blocked.
This atomicity is absolutely essential to solving synchronization problems and avoiding race condition.

The \cmd{up} operation increments the value of the semaphore addresses.
If one or more processes were sleeping on that semaphore, unable to complete an earlier \cmd{down} operation,
one of them is chosen by the system (e.g., at random) and is allowed to complete its \sys{down}.
Thus, after an \cmd{up} on a semaphore with processes sleeping on it, the semaphore will still be 0,
but there will be one fewer process sleeping on it.
The operation of incrementing the semaphore and waking up one process is also indivisible.
No process ever blocks doing an \cmd{up}, just as no process ever blocks doing a \cmd{wakeup} in the earlier model.

As an aside, in Dijkstra's original paper, he used the names \cmd{p} and \cmd{v} instead of \cmd{down} and \cmd{up},
respectively, but since these have no mnemonic significance to people who do not speak Dutch (and only marginal significance to those who do),
we will use the terms \cmd{down} and \cmd{up} instead.

\subsubsection*{Solving the Producer-Consumer Problem using Semaphores}
Semaphores solve the lost-wakeup problem, as shown in Fig. 2-14.
It is essential that they be implemented in an indivisible way.
The normal way is to implement \cmd{up} and \cmd{down} as system calls,
with the operating system briefly disbling all interrupts while it is testing the semaphore,
updating it, and putting the process to sleep, if necessary.
As all of these actions take only a few instructions, no harm is done in disabling interrupts.
If multiple CPUs are being used, each semaphore should be protected by a lock variable, 
with the \cmd{TSL} instruction used to make sure that only one CPU at a time examines the semaphore.
But sure you understand that using \cmd{TSL} to prevent several CPUs from accessing the semaphore at the sime time 
is quite different from busy waiting by the producer or consumer waiting for the other to empty or fill the buffer.
The semaphore operation will only take a few microseconds, whereas the producer or consumer might take arbitrarily long.

This solution uses three semaphores: 
one called \sys{full} for counting the number of slots that are full,
one called \sys{empty} for counting the number of slots that are empty,
and one called \sys{mutex} to make sure the producer and consumer do not access the buffer at the same time.
\sys{Full} is initially 0, \sys{empty} is initially equal to the number of slots in the buffer,
and \sys{mutex} is initially 1.
Semaphores that are initialized to 1 and used by two or more processes to ensure that 
only one of them can enter its critical region at the same time are called \kw{binary semaphores}.
If each process does a \cmd{down} just before entering its critical region and an \cmd{up} just after leaving it, mutual exlusion is guaranteed.

Now that we have a good interprocess communication primitive at our disposal, 
let us go back and look at the interrupt sequence of Fig. 2-5 again. 
In a system-using semaphores, the natural way to hide interrupts is to have a semaphore, 
initially set to 0, associated with each I/O device.
Just starting an I/O device, the managing process does a \cmd{down} on the associated semaphore, thus blocking immediately.
When the interrupt comes in, the interrupt handler then does an \cmd{up} on the associated semaphore,
which makes the relevant process ready to run again.
In this model, step 6 in Fig. 2-5 consists of doing an \cmd{up} on the device's semaphore,
so that in step 7 the scheduler will be able to run the device manager.
Of course, if several processes are now ready, the scheduler may choose to run an even more important process next.
We will look at how scheduling is done later in this chapter.

In the example of Fig. 2-14, we have actually used semaphores in two different ways.
This difference is important enough to make explicit.
The \sys{mutex} semaphore is used for mutual exlusion.
It is designed to guarantee that only one process at a time will be reading or writing the buffer and the associated variables.
This mutual exlusion is required to prevent chaos.
We will study mutual exclusion and how to achive it more in the next section.

The other use of semaphore is for \kw{synchronization}.
The \sys{full} and \sys{empty} semaphores are needed to guarantee that certain event sequences do or do not occur.
In this case, they ensure that the producer stops running when the buffer is full, and the consumer stops running when it is empty.
This use is differnt from mutual exclusion.

\subsection{Mutexes}
When the semaphore's ability to count is not needed, a simplified version of the semaphore, called mutex, is sometimes used.
Mutexes are good only for managing mutual exclusion to some shared resources or piece of code.
They are easy and efficient to implement, which makes them especially useful in thread packages that are implemented entirely in user space.

A \kw{mutex} is a variable that can be in one of two states: unlocke dor locked.
Consequently, only 1 bit is required to represent it, but in practice an integer often is used, 
with 0 meaning unlocked and all other values meaning locked.
Two procedures are used with mutexes.
When a process (or thread) needs access to a critical region, it calls \sys{mutex\_lock}.
if the mutex is currently unlocked (meaning that the critical region is available),
the call succeeds and the calling thread is free to enter the critical region.

On the other hand, if the mutex is already locked, the caller is blocked until the process in the critical region is finished 
and calls \sys{mutex\_unclock}.
If multiple processes are blocked on the mutex, one of them is chosen at random and allowed to acquire the lock.

\subsection{Monitors}
With semaphores interprocess communication looks easy, right? Forget it.
Look closely at the order of the \cmd{down}s before entering or removing items from the buffer in Fig. 2-14.
Suppose that the two \cmd{down}s in the producer's code were reversed in order, 
so \sys{mutex} was decremented before \sys{empty} instead after it.
If the buffer were completely full, the producer would block, with \sys{mutex} set to 0.
Consequently, the next time the consumer tried to access the buffer, it would do a \cmd{down} on \sys{mutex}, and block too.
Both processes would stay blocked forever and no more work would ever be done.
This unfortunate situation is called a \kw{deadlock}.
we will study deadlocks in detail in Chap. 3.

This problem is pointed out to show how careful you must be when using semaphores.
One subtle error and everything comes to a gringding halt.
It is like programming in assembly language, only worse, 
because the errors are race conditions, deadlocks, and other forms of unpredictable and irreproducible behavior.

To make it easier to write correct programs, Brinch Hansen (1973) and Hoare (1974) 
proposed a higher level synchronization primitive called a \kw{monitor}.
Their proposals differed slightly, as described below.
A monitor is a collection of procedures, variables, and data structures 
that are all grouped together in a special kind of module or package.
Processes may call the procedures in a monitor whenever they want to,
but they cannot directly access the monitor's internal data structures from procedures declared outside the monitor.
This rule, which is common in modern object-oriented languages such as Java, was relatively unusual for its time,
although objects can be tracked back to Simula 67.
Fig. 2-15 illustrates a monitor written in an imaginary language, Pidgin Pascal.

Monitors have a key property that makes them useful for achieving mutual exclusion: 
only one process can be active in a monitor at any instant.
Monitors are a programming labguage construct, so the compiler knows they are special 
and can handle calls to monitor procedures differently from other procedure calls.
Typically, when a process calls a monitor procedure, 
the first few instructions of the procedure will check to see if any other process has left the monitor.
If no other process is using the monitor, the calling process may enter.

It is up to the compiler to implement the mutual exlusion on monitor entries,
but a common way is to use a mutex or binary semaphore.
Because the compiler, not the programmer, arranges for the mutual exclusion, it is much less likely that something will go wrong.
In any event, the person writing the monitor does not have to be aware of how the compiler aranges for mutual exclusion.
It is sufficient to know that by turning all the critical regions into monitor procedures, 
no two processes will ever execute their critical regions at the same time.


Although monitors provide an easy way to achieve mutual exlusion, as we have seen above, that is not enough.
We also need a way for processes to block when they cannot proceed.
In the producer-consumer problem, it is easy enough to put all the tests for buffer-full and buffer-empty in monitor procedures,
but how should the procedure block when it finds the buffer full?

The solution lies in the introduction of \kw{condition variables}, among with two operations on them, \cmd{wait} and \cmd{signal}.
When a monitor procedure discovers that it cannot continue (e.g., the procedure find the buffer full),
it does a \cmd{wait} on some condition variablle, say, \sys{full}.
This action causes the calling process to block.
It also allows another process that had been previously prohibited from entering the monitor to enter now.

The other process, for example, the consumer, can wake up its sleeping partner - 
by doing a \cmd{signal} on the condition variable that its patner is waiting on.
To avoid having two active processes in the monitor at the same time, we need a rule telling what happens after a \cmd{signal}.
Hoare proposed letting the newly awakened process run, suspending the other one.
Brinch Hansen proposed finessing tthe problem by requiring that a process doing a \cmd{signal} must exit the monitor immediately.
In other words, a \cmd{signal} statement may appear only as the final statement in a monitor procedure.
We will use Brinch Hansen's proposal because it is conceptually simpler and also easier to implement.
If a \cmd{signal} is done on a condition variable on which several processes are waiting, 
only one of them, determined by the system scheduler, is revived.

There is also a third solution, not proposed by either Hoare or Brinch Hansen.
This is to let the signaler continue to run and allow the waiting process to start running only after the signaler has exited the monitor.

Condition variables are not counters.
They do not accumulate signals for later use the way semaphores do.
Thus if a condition variable is signaled with no one waiting on it, the signal is lost.
In other words, the \cmd{wait} must come before the \cmd{signal}.
This rule makes the implementation much simpler.
In practice it is not a problem because it is easy to keep track of the state of each process with variables, if need be.





























%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

