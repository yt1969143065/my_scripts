\documentclass{book}
\newcommand {\kw}  [1] {\textbf{#1}}
\newcommand {\www} [1] {\texttt{#1}}
\newcommand {\sys} [1] {\textsl{#1}}
\newcommand {\cmd} [1] {\texttt{#1}}
%\newcommand {\cmd} [1] {{\color{Blue}#1}}
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frontmatter
\chapter{Preface}
Most books on operating systems are strong on thoery and weak on practice. 
This one aims to provide a better balance between the two.
It covers all the fundamental principles in great detail, 
including processes, interprocess communication, semaphores, monitors, message passing, 
scheduling algorithms, input/output, deadlocks, device driver, memory management, paging algorithms,
file system design, security, and protection mechanisms.
But it also discusses one particular system MINIX 3, a UNIX-compatible operating system in detail, 
and even provides a source code listing for study.
This arrangement allows the reader not only to learn the principles, but also to see how they are applied in a real operating system.

When the first edition of this book appeared in 1987, it caused something of a small revolution in the way operating systems coursed were taught.
Untill then, most courses just covered theory.
With the appearance of MINIX, 
many schools began to have laboratory courses in which students examined a real operating system to see how it worked inside.
We consider this trend highly desirable and hope it continues.

In its first 10 years, MINIX underwent many changes.
The original code was designed for a 256K 8088-based IBM PC with two diskette drivers and no hard disk.
It was also based on UNIX Version 7. 
As time went on, MINIX evolved in many ways: it supported 32-bit protected mode machined with large memories and hard disks.
It also changed from being based on Version 7, to being based on the international POSIX standard (IEEE 1003.1 and ISO 9945-1).
Finally, many new features were added, perhaps too many in our view, but too few in the view of some other people, which led to the creation of Linux.
In addition, MINIX was ported to many other platforms, including the Macintosh, Amiga, Atari, and SPARC.
A second edition of the book, covering this system, was published in 1997 and was widely used at universities.

The popularity of MINIX has continued, as can be observed by examining the number of hits for MINIX found by Google.
 
This third edition of the book has many changes throughout.
Nearly all of the material on principles has been revised, and considerable new material has been added.
However, the main change is the discussion of the new version of the system, called MINIX 3, and the inclusion of the new code in this book.
Although loosely based on MINIX 2, MINIX 3 is fundamentally different in many key ways.

The design of MINIX 3 was inspired by the observation that operating system are becoming bloated, slow, and unreliable. 
They crash far more often than other electronic devices such as televisons, cell phones, and DVD players 
and have so many features and options that practically nobody can understand them fully or manage them well.
And of course, computer viruses, worms, spyware, spam, and other forms of malware have become epidemic.

To a large extent, many of these problems are caused by a fundamental design flaw in current operating systems: their lack of modularity. 
The entire operating system is typically millions of lines of C/C++ code compiled into a single massive executable program run in kernrl mode.
A bug in any one of those millions of lines of code can cause the system to malfunction.
Getting all this code correct is impossible, especially when about 70\% consists of device drivers, written by third parties, 
and outside the purview of the people maintaining the operating system.

With MINIX 3, we demonstrate that this monolithic design is not the only possibility. 
The MINIX 3 kernel is only about 4000 lines of executable code, not the millions found in Windows, Linux, Mac OSX, or FreeBSD.
The rest of the system, including all the device drivers(except the clock driver), is a collection of small, modular, user-mode processes, 
each of which is tightly restricted in what it can do and with which other processes it may communicate.

While MINIX 3 is a work in progress, we believe that this model of building an operating system as a collection of highly-encapsulated user-mode 
processes holds promise for building more reliable system in the future.
MINIX 3 is especially focused on smaller PCs
(such as those commonly found in Third-World countries and on embedded systems, which are always resource constrained).
In any event, this design makes it much easier for students to lear how an operating system works than attempting to study a huge monolithic system.

The CD-ROM that is included in this book is a live CD. 
You can put it in your CD-ROM drive, reboot the computer, and MINIX 3 will give a login prompt within a few seconds. 
You can log in as root and give the system a try without first having to install it on your hard disk.
Of course, it can also be installed on the hard disk.
Detailed installation instructions are given in Appendix A.

As suggested above, MINIX 3 is rapidly evolving, with new versions being issued frequently.
To download the current CD-ROM image file for burning, please go to the offical Website: www.minix3.org.
This site also contains a large amount of new software, documentation, and news about MINIX 3 development.
For discussions about MINIX 3, or to ask questions, there is a USENET newsgroup: comp.os.minix.
People without newsreaders can follow discussions on the Web at http://groups.google.com/group/comp.os.minix.

As an alternative to installing MINIX 3 on your hard disk, it is possible to run it on any one of several PC simulators now available.
Some of these are listed on the main page of the Website.

Instructors who are using the book as the text for a university course can get the problem solutions from their local Prentice Hall representative. 
The book has its own Website.
It can be found by going to www.prenhall.com/tanenbaum and selecting this title.

We have been extremely fortunate in having the help of many people during the course of this project.
First and foremost, Ben Gras and Jorrit Herder have done most of the programming of the new version.
They did a great job under tight time constraints, including responding to e-mail well after midnight on many occasions. 
They also read the manuscript and made many useful comments.
Our deepest appreciation to both of them.

Kees Bot also helped greatly with previous versions, giving us a good base to work with.
Kees wrote large chunks of code for versions up to 2.0.4, repaired bugs, and answered numerous questions.
Philip Homburg wrote most of the networking code as well as helping out in numerous other useful ways, 
especially providing detailed feedback on the manuscript.

People too numerous to list contributed code to the very early versions, helping to get MINIX off the ground in the first place.
There were so many of them and their contributions have been so varied that we cannot even begin to list them all here,
so the best we can do is a generic thank you to all of them.

Several people read parts of the manuscript and made suggestions.
We would like to give our special thanks to Gojko Babic, Michael Crowley, Joseph M. Kizza, Sam Kohn Alexander Manov, and Du Zhang for their help.

Finally, we would like to thank our families. 
Suzanne has been through this 16 times now. 
Barbara has been through it 15 times now.
Marvin has been through it 14 times now.
It's kind of getting to be routine, but the love and support is still much appreciated.(AST)

AI's Barbara has been through this twice now.
Her support, patience, and good humor were essential.
Gordon has been a patient listener.
It is still a delight to have a son who understands and cares about the things that fascinate me.
Finally, step-grandson Zain's first birthday coincides with the release of MINIX 3.
Some day he will appreciate this.(ASW)

Andrew S. Tanenbaum

Albert S. Woodhull


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter
\chapter{Introduction}
Without its software, a computer is basically a useless lump of metal.
With its software, a computer can store, process, and retrieve information; 
play music and videos; send e-mail, search the Internet; and engage in many other valuable activities to earn its keep.
Computer software can be divided into two kinds: system programs, which manage the operation of the computer itself, 
and application programs, which perform the actual work the user wants.
The most fundamental system program is the \kw{operating system}, whose job is to control all the computer's resources and 
provide a base upon which the application programs can be written.
Operating systems are the topic of this book.
In particular, an operating system called MINIX 3 is used as a model, to illustrate design principles and the realities of implementing a design.

A modern computer system consists of one or more processors, some main memory, disks, 
printers, a keyboard, a display, network interfaces, and other input/output devices. 
All in all, a complex system.
Writing programs that keep track of all these components and use them correctly, let alone optimally, is an extremely difficult job.
If every programmer had to be concerned with how disk drives work, and with all the dozons of things that could go wrong when reading a disk block, 
it is unlikely that many programs could be written at all.

Many years ago it became abundantly clear that some way had to be found to shield programmers from the complexity of the hardware.
The way that has evolved gradually is to put a layer of software on top of the bare hardware, 
to manage all parts of the system, and present the user with an interface or \kw{virtual machine} that easier to understand and program.
This layer of software is the operating system.

The placement of the operating system is shown in Fiq. 1-1.
At the bottom is the hardware, which, in many cases, is itself composed of two or more levels (or layers).
The lowest level contains physical devices, consisting of integrated circuit chips, wires, power supplies, cathode ray tubes, and similar physical devices.
How these are constructed and how they work is the province of the electrical engineer.

Next comes the \kw{microarchitecture level}, in which the physical devices are grouped together to form functional units.
Typically this level contains some registers internal to the CPU (Central Processing Unit) and a data path containing an arithmetic logic unit.
In each clock cycle, one or two operands are fetched from the registers and combined in the arithmetic logic unit 
(for example, by addition or Boolean AND) .
The result is stored in one or more registers.
On some machines, the operation of the data path is controlled by software, called \kw{microprogram}.
On the other machines, it is controlled directly by hardware circuits.

The purpose of the data path is to execute some set of instructions.
Some of these can be carried out in one data path cycle; others may require multiple data path cycles.
These instructions may use registers or other hardware facilities.
Together, the hardware and instructions visible to an assembly language programmer form the \kw{ISA (Instruction Set Architecture)}.
This level is often called \kw{machine language}.

The machine language typically has between 50 and 300 instructions, mostly for moving data around the machine, doing arithmetic, and comparing values.
In this level, the input/output devices are controlled by loading the values into special \kw{device registers}.
For example, a disk can be commanded to read by loading the values of the disk address, main memory address, byte count, 
and direction (read or write) into its registers.
In practice, many more parameters are needed, and the status returned by the device after an operation may be complex.
Furthermore, for many I/O (Input/Output) devices, timing plays an important role in the programming.

A major function of the operating system is to hide all this complexity and give the programmer a more conveninent set of instructions to work with.
For example, read block from file is conceptually much simple than having to worry about the details of moving disk heads, 
waiting for them to settle down, and so on.

On top of the operating system is the rest of the system software.
Here we find the command interpreter (shell), window system, compilers, editors, and similar application-independent programs.
It is important to realize that these programs are definitely not part of the operating system, 
even though they are typically supplied preinstalled by the computer manufacturer, 
or in a package with the operating system if it is installed after purchase.
This is a crucial, but subtle, point.
The operating system is (usaully) that portion of the software that run in \kw{kernel mode} or \kw{supervisor mode}.
It is protected from user tampering by the hardware 
(ignoring for the moment some older or low-end microprocessors that do not have hardware protection at all).
Compilers and editors run in \kw{user mode}.
If a user does not like a particular compiler, he is free to write his own if he so chooses; 
he is not free to write his own clock interrupt handler, which is part of the operating system 
and is normally protected by hardware against attempts by user to modify it.

This distinction, however, is sometimes blurred in embedded systems (which may not have kernel mode) 
or interpreted systems (such as Java-based systems that use interpretation, not hardware , to seperate the components).
Still, for traditional computers, the operating system is what runs in kernel mode.

That said, in many systems there are programs that run in user mode but which help the operating sytem or perform privileged functions.
For example, there is often a program that allows users to change their passwords.
This program is not part of the operating system and does not run in kernel mode, but it clearly carries out a sensitive function 
and has to be protected in a specail way.

In some systems, including MINIX 3, this idea is carried to an extreme form, 
and pieces of what is traditionally considered to be the operating system (such as the file system) run in user space.
In such systems, it is difficult to draw a clear boundary.
Everything runing in kernel mode is clearly part of the operating system, 
but some programs running outside it are arguably also part of it, or at least closely associated with it.
For example, in MINIX 3, the file system is simply a big C program running in uer-mode.

Finally, above the system programs come the application programs.
These programs are purchased (or written by) the user to solve their particular problems, 
such as word processing, spreadsheets, engineering calculations, or storing information in a database.

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{What Is an Operating System?}
Most computer users have had some experience with an operating system, but it is difficult to pin down precisely what an operating system is.
Part of the problem is that operating systems perform two basically unreleated functions, extending the machine and managing resources, 
and depending on who is doding the talking, you hear mostly about one function or the other.
Let us now look at both.

\subsection{The Operating System as an Extended Machine}
As mentioned earlier, the architecture (instruction set, memory organization, I/O, and bus structure) of most computers 
at the machine language level is primitive and awkward to program, especially for input/output.
To make this point more concrete, let us briefly look at how floppy disk I/O is done 
using the NEC PD765 compatible controller chips used on many Intel-based personal computers.
(Throughout this book we will use the term``floppy disk'' and ``diskette'' interchangeably.)
The PD765 has 16 commands, each specified by loading between 1 and 9 bytes into a device register.
Those commands are for reading and writing data, moving the disk arm, and formatting tracks, 
as well as initializing, sensing, resetting, and recalibrating the controller and the drives.

The most basic commands are read and write, each of which requires 13 parameters, packed into 9 bytes.
These parameters specify such items as the address of the disk block to be read, the number of sectors per track, 
the recording mode used on the physical medium, the intersector gap spacing, and what to do with a deleted-data-address-mark.
If you do not understand this mumbo jumbo, do not worry; that is precisely the pointit is rather esoteric.
When the operation is completed, the controller chip returns 23 status and error fields packed into 7 bytes.
As if this were enough, the floppy disk programmer must also be constantly aware of whether the motor is on or off.
If the motor is off, it must be turned on (with a long startup delay) before data can be read or write.
The motor cannot be left on too long, however, or the floppy disk will wear out.
The programmer is thus forced to deal with the trade-off between long startup delays versus wearing out floppy disks (and losing the data on them).

Without going the real details, it should be clear that the average programmer probably does not want to 
get too intimately involved with the programming of floppy disks (or hard disks, which are just as complex and quite different).
Instead, what the programmer wants is a simple, highlevel abstraction to deal with.
In the case of disks, a typical abstraction would be that the disk contains a collection of named files.
Each file can be opened for reading or writing, then read or written, and finally closed.
Details such as whether or not recording should use modified frequency modulation and 
what the current state of the motor is should not appear in the abstraction presented to the user.

The program that hides the truth about the hardware from the programmer and 
presents a nice, simple view of named files can be read and written is, of course, the operating system.
Just as the operating system shields the programmer from the disk hardware and presents a simple file-oriented interface, 
it also conceals a lot of unpleasant business concerning interrupts, timers, memory management, and other low-level features.
In each case, the abstraction offered by the operating system is simpler and easier to use than that offered by the underlying hardware.

In this view, the function of the operating system is to present the user with the equivalent of an \kw{extended machine} or \kw{virtual machine} 
that is easier to program than the underlying hardware.
How the operating system achives this goal is a long story, which we will study in detail throuout this book.
To summarize it in a nutshell, the operating system provides a variety of services 
that programs can obtain using special instructions called system calls.
We will examine some of the more common system calls later in this chapter.

\subsection{The Operating System as a Resource Manager}
The concept of the operating system as primarily providing its users with a convient interface is a top-down view.
An alternative, bottom-up, view holds that the operating system is there to manage all the pieces of a complex system. 
Modern computers consist of processors, memories, timers, disks, mice, network interfaces, printers, and a wide variety of other devices.
In the alternative view, the job of the operating system is to provide for an orderly and controlled allocation 
of the processors, memories, and I/O devices among the various programs competing for them.

Imagine what would happen if three programs running on some computer all tried to print their output simultaneously on the same printer.
The first few lines of printout might be from program 1, the next few from program 2, then some from program 3, and so forth.
The result would be chaos.
The operating system can bring order to the potential chaos by buffering all the output destined for the printer on the disk.
When one program is finished, the operating system can then copy its output from the disk file where it has been stored to the printer, 
while at the same time the other program can continue generating more output, 
oblivious to the fact that the output is not really going to the printer (yet).

When a computer (or network) has multiple users, the need for managing and protecting the memory, I/O devices, and other resources is even greater, 
since the users might otherwise interface with one another.
In addition, users often need to share not only hardware, but information (files, databases, etc.) as well.
In short, this view of the operating system holds that its primary task is to keep track of who is using which resource, 
to grant resource requests, to account for usage, and to mediate conflicting requests from different program and users.

Resource management includes multiplexing (sharing) resources in two ways: in time and in space.
When a resource is time multiplexed, different programs or users turns using it.
First one of them gets to use the resource, then another, and so on.
For example, with only one CPU and multiple programs that want to run on it, the operating system first allocates the CPU to one program, 
then after it has run long enough, another one gets to use the CPU, then another, and then eventually the first one again.
Determining how the resource is time multiplexed, who goes next,  and for how long is the task of the operating system.
Another example of time multiplexing is sharing the printer.
When multiple print jobs are queued up for printing on a single printer, a decision has to be made about which one is to be printed next.

The other kind of multiplexing is space multiplexing. 
Instead of the customers taking turns, each one gets part of the resource.
For example, main memory is normally divided up among several running programs, so each one can be resident at the same time 
(for example, in order to take turns using the CPU).
Assuming there is enough memory to hold multiple programs, 
it is more efficient to hold several programs in memory at once rather than give one of them all of it, 
especially if it only needs a small fraction of the total.
Of course, this raises issues of fairness, protection, and so on, and it is up to the operating system to solve them.
Another resource that is space multiplexed is the (hard) disk.
In many systems a single disk can hold files from many users at the same time.
Allocating disk space and keeping track of who is using which disk blocks is a typical operating system resource management task.

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{History of Operating Systems}
Operating systems have been evolving through the years.
In the following sections we will breifly look at a few of the highlights.
Since operating systems have historically been closely tied to the architecture of the computers on which they run, 
we will look at successive generations of computers to see what their operating systems were like.
This mapping of operating system generations to computer generations is crude, but it dose provide some structure where there would otherwise be none.

The first true digital computer was designed by the English mathematician Charles Babbage(1792-1871).
Although Babbage spent most of his life and fortune trying to build his ``analytical engine'', 
he never got it working properly because it was purely mechanical, 
and the technology of his day could not produce the required wheels, gears, and cogs to the high precision that he needed.
Needless to say, the analytical engine did not have an operating system.

As an intersting historical aside, Babbage realized that he would need software for his analytical engine, 
so he hired a young woman naned Ada Lovelace, who was the daughter of the famed British poet Lord Byron, as the world's first programmer.
The programming language Ada was named after her.

\subsection{The First Generation(194555) Vacuum Tubes and Plugboards}
After Babbage's unsuccessful efforts, little progress was made in constructing digital computers untill World War II.
Around the mid-1940s, Howard Aiken at Harvard University, John Von Neumann at the Institute for Advanced Study in Princeton, 
J. Presper Eckert and John Mauchley at the University of Pennsylvania, and Konrad Zuse in Germany, 
among others, all succeeded in building caculating engines.
The first ones used mechanical relays but were very slow, with cycle times measured in seconds.
Relays were later replaced by vacuum tubes.
These machines were enormous, filling up entire rooms with tens of thousands of vacuum tubes, 
but they were still millions of times slower than even the cheapest personal computers available today.

In these early days, a single group of people designed, built, programmed, operated, and maintained each machine.
All programming was done in absolute machine language, often by wiring up plugboards to control the machine's basic functions.
Programming languages were unknown (even assembly language was unknow).
Operating systems were unheard of.
The usual mode of operation was for the programmer to sign up for a block of time on the signup sheet on the wall, 
then come down to the machine room, insert his or her plugboard into the computer, 
and spend the next few hours hoping that none of the 20,000 or so vacuum tubes would burn out during the run.
Virtually all the problems were straitforward numerical calculations, such as grinding out tables of sines, cosines, and logarithms.

By the early 1950s, the routine had improved somewhat within the introduction of punched cards.
It was now possible to write programs on card and read them in instead of using plugboards; otherwise, the procedure was the same.

\subsection{The Second Generation(195565) Transistors and Batch Systems}
The introduction of the transistor in the mid-1950s changed the picture radically.
Computers became reliable enough that they could be manufactured and sold to paying customers with the expectation 
that they would continue to function long enough to get some useful work done.
For the first time, there was a clear separation between designers, builders, operators, programmers, and maintenance personnel.

These machines, now called \kw{mainframes}, were locked away in specially airconditioned computer rooms, 
with staffs of special-trained professional operators to run them.
Only big corporation or major government agencies or universities could afford their multimillion dollar price tags.
To run a \kw{job}(i.e., a program or set of programs), a programmer would first write the program on paper 
(in FORTRAN or possibly even in assembly language), then punch it on cards.
He would then bring the card deck down to the input room and hand it to one of the operators and go drink coffee untill the output was ready.

When the computer finished whatever job it was currently running, an operator would go over to the printer and tear off the output
and carry it over to the output-room, so that the programmer could collect it later. 
Then he would take one of the card decks that had been brought from the input room and read it in.
If the FORTRAN compiler was needed, the operator would have to get it from a file cabinet and read it in.
Much computer time was wasted while operators were walking around the machine room.

Given the high cost of the equipment, it is not surprising that people quickly looked for ways to reduce the wasted time.
The solution generally adopted was the \kw{batch system}.
The idea behind using a small (relatively) inexpensive computer, such as the IBM 1401, 
which was very good at reading cards, copying tapes, and printing output, but not at all good at numerical calculations.
Others, much more expensive machines, such as the IBM 7094, were used for the real computing.
This solution is show in Fig. 1-2.

After about an hour of collecting a batch of jobs, the tape was rewound and brought into the machine room, where it was mounted on a tape drive.
The operator then loaded a special program (the ancestor of today's operating system), which read the first job from tape and ran it.
The output was written onto a second tape, instead of being printed.
After each job finished, the operating system automatically read the next job from the tape and began running it.
When the whole batch was done, the operator removed the input and output tapes, replaced the input tape with the next batch, 
and brought the output tape to a 1401 for printing \kw{off line} (i.e., not connected to the main computer).

The structure of a typical input job is show in Fig. 1-3.
It started out with a \$JOB card, specifying the maximum run times in minutes, the account number to be charged, and the programmer's name.
Then came a \$FORTRAN card, telling the operating system to load FORTRAN compiler from the system tape.
It was followed by the program to be compiled, and then a \$LOAD card, directing the operating system to load the object program just compiled.
(Compiled programs were often written on scratch tapes and had to be loaded explicitly.)
Next came the \$RUN card, telling the operating system to run the program with the data following it.
Finally, the \$END card marked the end of the job.
These primitive control cards were the forerunners of modern job control language and command interpreters.

Large second-generation computers were used mostly for scientific and engineering calculations, 
such as solving the partial differential equations that often occur in physics and engineering.
They were largely programmed in FORTRAN and assembly labguage.
Typical operating systems were FMS (the Fortran Monitor System) and IBSYS, IBM'S operating system for the 7094.

\subsection{The Third Generation (19651980) ICs and Multiprogramming}
By the early 1960s, most computer manufactures had two distinct, and totally incompatible, product lines.
On the one hand there were the word-oriented, large-scale scientific computers, such as the 7094, 
which were used for numerical caculations in science and engineering.
On the other hand, there were the character-oriented, commercial computers, such as the 1401, 
which were widely used for tape sorting and printing by banks and insurance companies.

Developing, maintaining, and marketing two completely different product lines was expensive proposition for the computer manufactures.
In addition, many new computer customers initially needed a small machine but later outgrew it and wanted a bigger machine 
that had the same architectures as their current one so it could run all their old programs, but faster.

IBM attempted to solve both of these problems at a single stroke by introducing the System/360.
The 360 was a series of software-compatible machines ranging from 1401-size to much more powerful than the 7094.
The machines differed only in price and performance (maximum memory, processor speed, number of I/O devices permitted, and so forth).
Since all the machines had the same architecture and instruction set, programs written for one machine could run on all the others, at least in theory.
Furthermore, the 360 was designed to handle both scientific (i.e., numerical) and commertial computing.
Thus a single family of machines could satisfy the needs of all customers.
In subsequent years, IBM has come out with compatible successors to the 360 line, using more modern technology, 
known as the 370, 4300, 3080, 3090, and Z series.

The 360 was the first major computer line to use (small-scale) Integrated Circuits (ICs), 
thus providing a major price/performance advantage over the second-generation machines, which were built up from individual transistors.
It was an immediate success, and the idea of a family of compatible cpmputers was soon adopted by all the other major manufactures.
The descendants of these machines are still use at computer centers today.
Nowadays they are often used for managing huge databases (e/g., for airline reservation systems) 
or as servers for World Wide Web sites that must process thousands of requests per second.

The greatest strenth of the ``one family'' idea was simultaneously its greatest weakness.
The intention was that all software, including the operating system, \kw{OS/360}, had to work on all models.
It had to run on small system, which often just replaced 1401s for copying cards to tape, 
and on very large systems, which often replaced 7094s for doing weather forecasting and other heavy computing.
It had to be good on systems with few peripherals and on systems with many peripherals.
It had to work in commercial environments and in scientific environments.
Above all, it had to be efficient for all of these different uses.

There was no way that IBM(or anybody else) could write a piece of software to meet all those conflicting requirements.
The result was an enormous and extraordinarily complex operating system, probably two to three orders of magnitude larger than FMS.
It consisted of millions of lines of assembly language written by thousands of programmers, 
and contained thousands upon thousands of bugs, which necessitated a continuous stream of new releases in an attempt to correct them.
Each new release fixed some bugs and introduced new ones, so the number of bugs probably remained constant in time.

One of the designers of OS/360, Fred Brooks, subsequently wrote a witty and incisive book describing his experiences with OS/360 (Brooks, 1995).
While it would be impossible to summarize the book here, suffice it to say that the cover shows a herd of prehistoric beasts stuck in a tar pit.
The cover of Silberschatz et al.(2004) makes a similar point about operating systems being dinosaurs.

Despite its enormous size and problems, OS/360 and the similar third-generation operating systems produced by other computer manufacturers 
actually satisfied most of their customers reasonably well.
They also popularized several key techniques absent in second-generation operating systems.
Probably the most important of these was \kw{multiprogramming}.
On the 7094, when the current job paused to wait for a tape or other I/O operation to complete, the CPU simply sat idle untill the I/O finished.
With heavily CPU-bound scientific caculations, I/O is infrequent, so this wasted time is not significant.
With commercial data processing, the I/O wait time can often be 80 or 90 percent of the total time, 
so something had to be done to avoid having the (expensive) CPU be idle so much.

The solution that evolved was to partition memory into several pieces, with different job in each partition, as shown in Fig. 1-4.
While one job was waiting for I/O to complete, another job could be using the CPU.
If enough jobs could be held in main memory at once, the CPU could be kept busy nearly 100 percent of the time.
Having multiple jobs safely in memory at once requires special hardware to protect each job against snooping and mischief by the other ones,
but the 360 and other third-generation systems were equipped with this hardware.

Another major feature present in third-generation operating systems was the ability to read jobs from cards onto the disk 
as soon as they were brought to the computer room.
Then, whenever a running job finished, the operating system could load a new job from the disk into the now-empty partion and run it.
This technique is called \kw{spooling} (from Simultaneous Peripheral Operation On Line) and was used for output.
With spooling, the 1401s were no longer needed, and much carrying of tapes disappeared.

Although third-generation operating systems were well suited for big scientific caculations and massive commercial data processing runs, 
they were still basically batch systems.
Many programmers pined for the first-generation days when they had the machine all to themselves for a few hours, 
so they could debug their programs quickly.
With third-generation systems, the time between submitting a job and getting back the output was often hours, 
so a single misplaced comma could cause compilation to fail, and the programmer to waste half day.

The desire for quick response time paved the way for \kw{timesharing}, a variant of multiprogramming, in which each user has an online terminal.
In a timesharing system, if 20 users are logged in and 17 of them are thinking or talking or drinking coffee, 
the CPU can be allocated in turn to the three jobs that want service.
Since people debugging programs usually issue short commands (e.g., compile a five-page procedure) 
rather than long ones (e.g., sort a million-record file), the computer can provide fast, 
interactive service to a number of users and perhaps also work on big batch jobs in the backgroud when the CPU is otherwise idle.
The first serious timesharing system, \kw{CTSS} (Compatible Time Sharing System), was developed at M.I.T. 
on a special modified 7094 (Corbato et al., 1962). 
However, timesharing did not really become popular until the necessary protection hardware became widespread during the third generation. 

After the success of the CTSS system, MIT, Bell Labs, and General Electric (then a major computer manufacturer) decided to embark on 
the development of a ``computer utility'', a machine that would support hundreds of simultaneous timesharing users.
Their model was the electricity distribution system:
when you need electric power, you just stick a plug in the wall, and within reason, as much power as you need will be there.
The designer of this system, known as \kw{MULTICS} (MULTiplexed Information and Computing Service), 
envisioned one huge machine providing computing power for everyone in the Boston area.
The idea that machines far more powerful than their GE-645 mainframe would be sold for under a thousand dollars by the millions only 30 years later 
was pure science fiction, like the idea of supersonic trans-Atlantic underse a trains would be now.

MULTICS was a mixed success.
It was designed to support hundreds of users on a machine only slightly more powerful than an Intel 80386-base PC,
although it had much more I/O capacity.
This is not quite as crazy as it sounds, since people knew how to write small, efficent programs in those days, a skill that has subsequntly been lost.
There were many reasons that MULTICS did not take over the world, not the least of which is that it was written in PL/I, 
and the PL/I compiler was years late and barely worked at all when it finally arrived.
In addition, MULTICS was enormously ambitious for its time, much like Charles Babbage's analytical engine in the nineteenth century.

MULTICS introduced many seminal ideas into the computer literature, 
but turning it into a serious products and commercial success was a lot harder than anyone had expected.
Bell Labs dropped out of the project, and General Electric quit the computer business altogether.
However, M.I.T. persisted and eventually got MULTICS working.
It was ultimately sold as a commertial product by the company that bought GE's computer business (Honeywell) 
and installed by about 80 major companies and universities worldwide.
While their numbers were small, MULTICS users were fiercely loyal.
General Motors, Ford, and the U.S. National Security Agency, for example, only shut down their MULTICS systems in the late 1990s.
The last MULTICS running, at the Canadian Department of National Defence, shut down in October 2000.
Despite its lack of commertial success, MULTICS had huge influence on subsequent operating systems.
A great deal of information about it exists 
(Corbato et al., 1972; Corbato and Vyssotsky, 1965; Daley and Dennis, 1968; Organick, 1972; and Saltzerm 1974).
It also has a still active Web site, \www{www.multicians.org}, with a great deal of information about the system, its designers, and its users.

The phrase ``computer utility'' is no longer heard, but the idea has gained new life in recent years.
In its simplest form, PCs or workstation (high-end PCs) in a business or a classroom 
may be connected via a \kw{LAN (Local Area Network)} to a \kw{file server} on which all programs and data are stored.
An administrator then has to install an protect only one set of programs and data, 
and can easily reinstall local software on a malfunctioning PC or workstation without worrying about retrieving or preserving local data.
In more heterogeneous environments, a class software called \kw{middleware} has evolved 
to bridge the gap betwwen local users and the files, programs, and databases they use on remote servers.
Middleware makes networked computers look local to individual users' PCs or workstations 
and presents a consistent user interface even though there may be a wide variety of different servers, PCs, and workstations in use.
The World Wide Web is an example.
A web brower presents documents to a user in a uniform way, and a document as seen on a user's brower can consist of next from one server 
and graphics from another server, presented in a format determined by a style sheet on yet another sever.
Businesses and universities commonly use a web interface to access databases and run programs on a computer in another building or even another city.
Middleware appears to be the operating system of a \kw{distributed system}, 
but it is not really an operating system at all, and is beyond the scope of this book.
For more on distributed systems see Tanenbaum and Van Steen (2002).

Another major development during the third generation was the phenomental growth of minicompputers, 
starting with the Digital Equipment Company (DEC) PDP-1 in 1961.
The PDP-1 had only 4K of 18-bit words, but at \$120,000 per machine (less than 5 percent of the price of a 7094), it sold like hotcakes.
For certain kinds of nonnumerical work, it was almost as fast as the 7094 and gave birth to a whole new industry.
It was quickly followed by a series of other PDPs (unlike IBM's family all incompatible) culminating in the PDP-11.

One of the computer scientists at Bell Labs who had worked on the MULTICS project, Ken Thompson, 
subsequently found a small PDP-7 minicomputer that no one was using and set out to write a stripped-down, one-user version of MULTICS.
This work later developed into the \kw{UNIX} operating system, which became popular in the academic world, 
with government agencies, and with many companies.

The history of UNIX has been told elsewhere (e.g., Salus, 1994).
Because the source code was widely available, various organizations developed their own (incompatible) versions, which lead to chaos.
Two major versions developed, \kw{System V}, from AT\&T, and \kw{BSD}, (Berkeley Software Distribution) from the University of California at Berkeley.
These had minor variants as well, now including FreeBSD, OpenBSD, and NetBSD.
To make it possible to write programs that could run on any UNIX system, IEEE developed a standard for UNIX, called \kw{POSIX},
that most versions of UNIX now support.
In fact, some other operating system now also support the POSIX interface.
The information needed to write POSIX-compliant software is available in books (IEEE, 1990; Lewine, 1991),
and online as the Open Group's ``Single UNIX Specification'' at \www{www.unix.org}.
Later in this chapter, when we refer to UNIX, we mean all of these systems as well, unless stated otherwise.
While they differ internally, all of them support the POSIX X standard, so to the programmer they are quite similar.

\subsection{The Fourth Generation (1980Present) Personal Computers}
With the development of LSI (Large Scale Integration) circuits, chips containing thousands of transistors on a square centimeter of silicon,
the age of the \kw{microprocessor}-based personal computer dawned.
In terms of architecture, personal computers (initially called \kw{microcomputers}) were not all that different from minicomputers of the PDP-11 class, 
but in terms of price they certainly were different.
The minicomputer made it possible for a department in a cpmpany or university to have its own computer.
The microcomputer made it possible for an individual to have his or her own computer.

There were several families of microcomputers.
Intel came out with the 8080, the first general-purpose 8-bit microprocessor, in 1974.
A number of companies produced complete systems using the 8080 (or the compatible Zilog Z80) 
and the \kw{CP/M} (Control Program for Microcomputers) operating system from a company called Digital Research was widely used with these.
Many application programs were written to run on CP/M, and it dominated the personal computing world for about 5 years.

Motorola also produced an 8-bit microprocessor, the 6800.
A group of Motorola engineers left to form MOS Technology and manufacture the 6502 CPU after Motorola rejected their suggested improvements to the 6800.
The 6502 was the CPU of several early systems.
One of these, the Apple II, became a major competitor for CP/M systems in the home and educational markets.
But CP/M was so popular that many owners of Apple II computers purchased Z-80 coprocessor add-on cards to run CP/M, 
since the 6502 CPU was not compatible with CP/M.
The CP/M cards were sold by little company called Microsoft, which also had a market niche supplying BASIC interpreters 
used by a number of microcomputers running CP/M.

The next generation of microprocessors were 16-bit systems.
Intel came out with the 8086, and in the early 1980s, IBM designed the IBM PC around Intel's 8088 (an 8086 on the inside, with an 8bit external data path).
Microsoft offered IBM a package which included Microsoft's BASIC and an operating system, 
\kw{DOS} (Disk Operating System) originally developed by another company.
Microsoft bought the product and hired the original author to improve it.
The revised system was renamed \kw{MS-DOS} (MicroSoft Disk Operating System) and quickly came to dominate the IBM PC market.

CP/M, MS-DOS, and the Apple DOS were all command-line systems: user typed commands at the keyboard.
Years earlier, Doug Engelbart at Stanford Research Institute had invented the \kw{GUI (Graphical User Interface)}, pronounced ``gooey'', 
complete with windows, icons, menus, and mouse.
Apple's Steve Jobs saw the possibility of a truly \kw{user-friendly} personal computer 
(for users who knew nothing about computers and did not want to learn), and the Apple Macintosh was announced in early 1984.
It used Motorola's 16-bit 68000 CPU, and had 64KB of \kw{ROM (Read Only Memory)}, to support the GUI.
The Macintosh has envolved over the years.
Subsequent Motorola CPUs were true 32-bit systems, and later still Apple moved to IBM PowerPC CPUs, with RISC 32-bit (and later, 64-bit) architecture.
In 2001 Apple made a major operating system change, releasing \kw{Mac OS X}, with a new version of the Macintosh GUI on top of Berkeley UNIX.
And in 2005 Apple announced that it would be switching to Intel processors.

To compete with the Macintosh, Microsoft invented Windows.
Originally Windows was just a graphical environment on top of 16-bit MS-DOS (i.e., it was more like a shell than a true operating system).
However, current versions of Windows are descendant of Windows NT, a full 32-bit system, rewritten from scratch.

The other major contender in the personal computer world is UNIX (and its various derivatives).
UNIX is strongest on workstations and other high-end computers, such as network servers.
It is especially popular on machines powerd by high-performance RISC chips.
On Pentium-based computers, Linux is becoming a popular alternative to Windows for students and increasingly many corporate users.
(Throughout this book we will use the term ``Pentium'' to means the entire Pentium family, 
including the low-end Celeron, the high end Xeon, and compatible AMD microprocessors).

Although many UNIX users, especially experienced programmers, prefer a command-based interface to a GUI, 
nearly all UNIX systems support a windowing system called \kw{X Window} system developed at M.I.T.
This system handles the basic window management, allowing users to create, delete, move, and resize windows using a mouse.
Often a complete GUI, such as \kw{Motif}, is available to run on top of the X Window system 
giving UNIX a look and feel something like the Macintosh or Microsoft Windowns for those UNIX users who want such a thing.

An intresting development that began taking place during the mid-1980s is the growth of 
networks of personal computers running \kw{network operating systems} and \kw{distributed operating systems} (Tanenbauand Van Steen, 2002).
In a network operating system, the users are aware of the existence of multiple computers 
and can log in to remote machines and copy files from one machine to another.
Each machine runs its own local operating system and has its own local user (or users).
Basically, the machines are independent of one another.

Network operating systems are not fundamentally different from single-processor operating systems.
They obviously need a network interface controller and some low-level software to drive it, 
as well as programs to achieve remote login and remote file access, 
but these additions do not change the essential structure of the operating system.

A distributed operating system, in contrast, is one that appears to its users as a traditional uniprocessor system, 
even though it is composed of multiple processors.
The users should not be aware of where their programs are being run or where their files are located;
that should all be handled automatically and efficently by the operating system.

True distributed operating systems require more than just adding a little code to a uniprocessor operating system, 
because distributed and centralized systems differ in critical ways.
Distributed system, for example, often allow applications to run on several processors at the same time, 
thus requiring more complex processor scheduling algorithms in order to optimize the amount of parallelism.

Communication delays within the network often mean that these (and other) algorithms must run with incomplete, outdated, or even incorrect information.
This situation is radically different from a single-processor system in which the operating system has complete information about the system state.


\subsection{History of MINIX 3}
When UNIX was young (Version 6), the source code was widely available, under AT\&T license, and frequently studied.
John Lions, of the University of New South Wales in Australia, even wrote a little booklet describing its operation, line by line (Lions, 1996).
This booklet was used (with permission of AT\&T) as a text in many university operating system courses.

When AT\&T released Verion 7, it dimly began realize that UNIX was a valuable commercial product, 
so it issued Version 7 with a license that prohibited the source code from being studied in courses, 
in order to avoid endangering its status as a trade secret. 
Many universities complied by simply dropping the study of UNIX and teching only theory.

Unfortunately, teaching only theory leaves the student with a lopsided view of what an operating system is really like.
The theoretical topics that are usually covered in great detail in courses and books on operating systems, 
such as scheduling algorithms, are in practice not really that important. 
Subjects that really are important, such as I/O and file systems, are generally neglected because there is little about them.

To remedy this situation, one of the authors of this book (Tanenbaum) decided to write a new operating system from scratch 
that would be compatible with UNIX from the user's point of view,  but completely different on the inside.
By not using even one line of AT\&T code, this system avoided the licensing restrictions, so it could be used for class or individual study.
In this manner, readers could dissect a real operating system to see what is inside, just as biology students dissect frogs.
It was called \kw{MINIX} and was released in 1987 with its complete source code for anyone to study or modify.
The name MINIX stands for mini-UNIX because it is small enough that even a nonguru can understand how it works.

In addition to the advantage of eliminating the legal problems, MINIX had another advantage over UNIX.
It was written a decade after UNIX and was structured in a more modular way.
For instance, from the very first release of MINIX the file system and the memory manager 
were not part of the operating system at all but as user programs.
In the current release (MINIX 3) this modularization has been extended to the I/O device drivers, 
which (with the exception of the clock driver) all run as user programs.
Another difference is that UNIX was designed to be efficient; MINIX was designed to be readable 
(in as much as one can speak of any program hundreds of pages long as being readable).
The MINIX code, for example, has thousands of comments in it.

MINIX was originally designed for compatibility with Version 7 (V7) UNIX. Version 7 was used as the model because of its simplicity and elegance.
It is sometimes said that Version 7 was an improvement not only over all its predecessors, but also over all its successors.
With the advent of POSIX, MINIX began evolving toward the new standard, while maintaining backward compatibility with existing programs.
This kind of evolution is common in the computer industry, as no vendor wants to introduce a new system 
that none of its existing customers can use without great upheaval.
The version of MINIX described in this book, MINIX 3, is based on the POSIX standard.

Like UNIX, MINIX was written in the C programing language and intented to be easy to port to various computers.
The initial implementation was for the IBM PC.
MINIX was subsequently ported to several other platforms.
In keeping with the ``Small is Beautiful'' philosophy, MINIX originally did not even require a hard disk to run 
(in the mid-1980s hard disks were still an expensive novelty).
As MINIX grew in functionality and size, it eventually got the point that a hard disk was needed for PCs,
but in keeping with the MINIX philisophy, a 200-MB partion is sufficient (for embedded applications, no hard disk is required though).
In contrast, even small Linux systems require 500-MB of disk space, and several GB will needed to install common applications.

To the average user sitting at an IBM PC, running MINIX is similar to runing UNIX.
All of the basic programs, such as \sys{cat, grep, ls, make}, and the shell are present and perform the same functions as their UNIX counterparts. 
Like the operating system itself, all these utility programs have been rewritten completely from scratch by the author, 
his students, and some other dedicated people, with no AT\&T or other proprietary code.
Many other freely-distributable programs now exist, and in many cases these have been successfully ported (recompiled) on MINIX.

MINIX continued to develop for a decade and MINIX 2 was released in 1997, 
together with the second edition of this book, which described the new release.
The changes between Versions 1 and 2 were substantial (e.g., from 16-bit real mode on an 8088 using floppy disks 
to 32-bit protected mode on a 386 using a hard disk) but evolutionary.

Development continued slowly but systematically until 2004, when Tanenbaum became convinced the software was getting too bloated and unreliable
and decide to pick up the slightly-dormant MINIX thread again.
Together with his students and programmers at the Vrije University in Amsterdam, he produced MINIX 3,
a major redesign of the system, greatly restructuring the kernel, reducing its size, and emphasizing modularity and reliability.
The new version was intended both for PCs and embedded systems, where compactness, modularity, and reliability are crucial.
While some people in the group called for a completely new name, it was eventually decide to call it MINIX 3 
since the name MINIX was already well known.
By way of analogy, when Apple abandoned it own operating system, Mac OS 9 and replaced it with a variant of Berkeley UNIX, 
the name chosen was Mac OS X rather than APPLIX or something like that.
Similar fundamental changes have happened in the Windows family while retaining the Windows name.

The MINIX kernel is well under 4000 lines of executable code, compared to millions of executable lines of code for Windows, Linux, FreeBSD, and other operating systems.
Small kernel size is important because kernel bugs are far more devastating than bugs in user-mode programs and more code means more bugs.
One careful study has shown that the number of \sys{detected} bugs per 1000 executable lines of code varies from 6 to 16 (Basili and Perricone, 1984).
The actual number of bugs is probably much higher since the researchers could only count reported bugs, not unreported bugs.
Yet another study (Ostrand et al., 2004) showed that even after more than a dozen releases, on the average 6\% of all files contained bugs 
that were later reported and after a certain point the bug level tends to stabilize rather than go asymptotically to zero.
This result is supported by the fact that when a very simple, automated, model-checker was let loose on stable versions of Linux and Open BSD, 
it found hundreds of kernel bugs, overwhelmingly in device drivers (Chou et al., 2001; and Engler et al., 2001).
This is the reason the device drivers were moved out of the kernel in MINIX 3; they can do less damage in user mode.

Throughout this book MINIX 3 will be used as an example.
Most of the comments about the MINIX 3 system calls, however (as opposed to comments abount the actual code), also apply to other UNIX systems.
This remark should be kept in mind when reading the text.

A few words about Linux and its relationship to MINIX may possibly be of interest to some reader.
Shortly after MINIX released, a USENET newsgroup, \www{comp.os.minix}, was formed to discuss it.
Within weeks, it had 40,000 subscribers, most of whom wanted to add vast numbers of new features to MINIX 
to make it bigger and better (well, at least bigger).
Every day, several hundred of them offered suggestions, ideas, and frequently snippets of source code.
The author of MINIX was able to successfully resist this onslaught for several years, 
in order to keep MINIX clean enough for students to understand and small enough that it could run on computers that students could afford.
For people who thought little of MS-DOS, the existence of MINIX (with source code) as an alternative was even a reason fo finally go out and buy a PC.

One of these people was a Finnish student named Linus Torvalds.
Torvalds installed MINIX on his new PC and studied the source code carefully.
Torvalds wants to read USENET newsgroups (such as \www{comp.os.minix}) on his own PC rather than his university, 
but some features he needed were lacking in MINIX, so he wrote a program to do that, but soon discovered he needed a different terminal driver,
so he wrote that too.
Then he wanted to download and save postings, so he wrote a disk driver, and then a file system.
By Aug. 1991 he had produced a primitive kernel.
On Aug. 25, 1991, he announced it on \www{comp.os.minix}.
This announcement attracted other people to help him, and on March 13, 1994 Linux 1.0 was released.
Thus was Linux born.

Linux has become one of the notable successes of the \kw{open source} movement (which MINIX helped start).
Linux is challenging UNIX (and Windows) in many environments, partly because commodity PCs which support Linux are now available with performance that rivals the proprietary RISC systems required by some UNIX implementations.
Other open source software, notably the Apache Web server and the MySQL database, 
and the open source Perl and PHP programming labguages are often used together on Web servers and sometimes referred to by the acronym \kw{LAMP}.
For more on the history of Linux and open source software see DiBona et al. (1999), Moody (2001), and Naughton (2000).

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{Operating System Concepts}
The interface between the operating system and the user programs is defined by the set of ``extended instructions'' that the operating system provides.
These extended instructions have been traditionally known as \kw{system call}, although they can be implemented in several ways.
To really understand what operating system do, we must examine this interface closely.
The calls available in the interface vary from operating system to operating system (although the underlying concepts tend to be similar).

We are thus forced to make a choice between (1) vague generalities (``operating systems have system calls for reading files'')
and (2) some specific system (``MINIX 3 has a \cmd{read} system call with three parameters: 
one to specify the file, one to tell where the data are to be put, and one to tell how many bytes to read'').

We have chosen the latter approach.
It's more work that way, but it gives more insight into what operating systems really do.
In Sec. 1.4 we will look closely at the basic system calls present in UNIX (including the various version of BSD), Linux, and MINIX 3.
For simplicity's sake, we will refer only to MINIX 3, but the corresponding UNIX and Linux system calls are based on POSIX in most cases.
Before we look at the actual system calls, however, it is worth taking a bird's-eye view of MINIX 3, 
to get a general feel for what an operating system is all about.
this overview applies equally well to UNIX and Linux, as mentioned above.

The MINIX 3 system calls fall roughly in two broad categories: those dealing with processes and those dealing with the file system.
We will now examine each of these in turn.

\subsection{Processes}
A key concept in MINIX 3, and in all operating systems, is the \kw{process}.
A process is basically a program in execution.
Associated with each process is its \kw{address space}, a list of memory locations from some minimum (usually 0) to some maximum,
which the process can read and write.
The address space contains the executable program, the program's data, and its stack.
Also associated with each process is some set of registers, including the program counter, stack pointer, and other hardware registers, 
and all the other information needed to run the program.
 
We will come back to the process concept in much more detail in Chap. 2, but for the time being, 
the easiest way to get a good intuitive feel for a process is to think about multiprogramming systems.
Periodically, the operating system decides to stop running one process and start running another, for example, 
because the first one has had more than its share of CPU time in the past second.

When a process is suspended temporarily like this, it must later be restarted in exactly the same state it had when it was stopped.
This means that all information about the process must be explicitly saved somewhere during the suspension.
For example, the process may have several files open for reading at once.
Associated with each of these files is a pointer giving the current position (i.e., the number of the byte or record to be read next).
When a process is temporarily suspended, all these pointers must be saved so that 
a \cmd{read} call executed after the process is restarted will read the proper data.
In many operating systems, all the information about each process, other than the contents of its own address space, 
is stored in an operating system table called \kw{process table}, which is an array (or linked list) of structures, 
one for each process currently in existence.

Thus, a (suspended) process consists of its address space, usually called the \kw{core image} 
(in honor of the magnetic core memories used in days of yore),
and its process table entry, which contains its registers, among other things. 

The key process management system calls are those dealing with the creation and termination of processes.
Consider a typical example.
A process called the \kw{command interpreter} or \kw{shell} reads commands from a terminal.
The user has just typed a command requesting that a program be compiled.
The shell must now create a nre process that will run the compiler.
When that process has finished the compilation, it executes a system call to terminate itself.

On Windows and other operating systems that have a GUI, (double) clicking on a desktop icon launches a program in much the same way 
as typing its name at the command prompt.
Although we will not discuss GUIs much, they are really simple command interpreters.

If a process can create one or more other processes (usually referred to as \kw{child process}) and these processes in turn can create child processes, 
we quickly arrive at the process tree structure of Fig. 1-5.
Related processes that are cooperating to get some job done often need to communicate with one another and synchronize their activities.
This communication is called \kw{interprocess communication}, and will be addressed in detail in Chap. 2.

Other process system calls are available to request more memory (or release unused memory),
wait for a child process to terminate, and overlay its program with a different one.

Occasionally, there is a need to convey information to a running process that is not sitting around waiting for it.
For example, a process that is communicating with another process on a different computer does so 
by sending messages to the remote process over a network.
To guard against the possibility that a message or its reply is lost, the sender may request that its own operating system notify it 
after a specified number of seconds, so that it can retransmit the message if no acknowledgement has been received yet.
After setting this timer, the program may continue doing other work.

When the specified number of seconds has elapsed, the operating system sends an \kw{alarm signal} to the process.
The signal causes the process to temporarily suspend whatever it was doing, save its registers on the stack, 
and start running a special signal handling procedure, for example, to retransmit a presumably lost message.
When the signal handler is done, the running process is restarted in the state it was in just before the signal.
Signals are the software analog of hardware interrupts.
They are generated by a variety of causes in addition to timers expiring.
Many traps detected by hardware, such as executing an illegal instruction or using a invalid address, 
are also converted into signals to the guilty process.

Each person authorized to use a MINIX 3 system is assigned a \kw{UID} (User IDentification) by the system administrator.
Every process started has the UID of the person who started it.
The child process has the same UID as its parent.
Users can be members of groups, each of which has a \kw{GID} (Group IDentification).

One UID, called the \kw{superuser} (in UNIX), has special power and may violate many of the protection rules.
In large installations, only the system administrator knowns the password needed to become superuser, 
but many of the ordinary users (especially students) devote considerable effort to trying to find flaws in the system 
that allow them to become superuser without the password.

We will study processes, interprocess communication, and related issues in Chap. 2.

\subsection{Files}
The other broad category of system calls relates to the file system.
As noted before, a major function of the operating system is to hide the peculiarities of the disks and other I/O devices 
and present the programmer with a nice, clean abstract model of device-independent files.
System calls are obviously needed to create files, remove files, read files, and write files.
Before a file can be read, it must be opened, and after it has been read it should be closed, so calls are provided to do these things.

To provide a place to keep files, MINIX 3 has the concept of a \kw{directory} as a way of grouping files together.
A student, for example, might have one directory for each course he is taking (for the programs needed for that course),
another directory for his electronic mail, and still another directories for his World Wide Web home page.
System calls are then needed to create and remove directories.
Calls are also provided to put an existing file into a directory, and to remove a file from a directory.
Directory entries may be either file or other directories.
This model also gives rise to a hierarchy, the file systems shown in Fig. 1-6.

The process and file hierarchies both are organized as trees, but the similarity stops there.
Process hierarchies usually are not very deep (more than three levels is unusual), 
whereas file hierarchies are commonly four, five, or even more levels deep.
Process hierarchies are typically short-lived, generally a few minutes at most, 
whereas the directory hierarchy may exist fo years.
Ownership and protection also differ to processes and files.
Typically, only a parent process may control or even access a child process, 
but mechanisms nearly always exist to allow files and directories to be read by a wider group than just the owner.

Every file within the directory hierarchy can be specified by giving its \kw{path name} from the top of the directory hierarchy, the \kw{root directory}.
Such absolute path names consist of the list of directories that must be traversed from the root directory to get to the file, 
with slashes separating the components.
In Fig. 1-6, the path for file CS101 is \sys{/Faculty/Prof.Brown/Courses/CS101}.
The leading slash indicates that the path is absolute, that is, starting at the root directory.
As an aside, in Windows, the backslash(\textbackslash) character is used as the seperator instead of the slash (/) character, 
so the file path given above would be written as $\backslash$Faculty$\backslash$Prof.Brown$\backslash$Courses$\backslash$CS101.
Throughout this book we will use the UNIX convention for paths.

At every instant, each process has a current \kw{working directory}, in which path names not beginning with a slash are looked for.
As an example, in Fig. 1-6, if /Faculty/Prof.Brown were the working directory, 
then use of the path name Courses/CS101 would yield the same file as the absolute path name given above. 
Processes can change their working directory by issuing a system call specifying the new working directory.

Files and directories in MINIX 3 are protected by assigning each one an 11-bit binary protection code.
The protection code consists of three 3-bit fields: one for the ower, one for other members of the owner's group 
(users are divided into groups by the system administrator), one for everyone else, and 2 bits we will discuss later.
Each field has a bit for read access, a bit for write access, and a bit for execute access.
These 3 bits are known as the \kw{rwx bits}.
For example, the protection code \sys{rwxr-x--x} means that the ower can read, write, or execute the file, 
other group members can read or execute (but no write) the file, and everyone else can execute (but not read or write) the file.
For a directory (as opposed to a file), \sys{x} indicates search permission.
A dash means that the corresponding permission is absent (the bit is zero).

Before a file can be read or written, it must be opened, at which time the permissions are checked.
If access is permitted, the system returns a small integer called a \kw{file descriptor} to use in subsequent operations.
If the access is prohibited, an error code (1) is returned.

Another important concept in MINIX 3 is mounted file system.
Nearly all personal computers have one or more CD-ROM drives into which CD-ROMs can be inserted and removed.
To provide a clean way to deal with removable media (CD-ROMs, DVDs, floppies, Zip drives, etc.), 
MINIX 3 allows the file system on a CD-ROM to be attached to the main tree.
Consider the situation of Fig. 1-7(a).
Before the \cmd{mount} call, the \kw{root file system}, on the hard disk, and a second file system, on a CD-ROM, are separate and unrelated.
 
Hoever, the file system on the CD-ROM cannot be used, because there is no way to specify path names on it.
MINIX 3 does not allow path names to be prefixed by a drive name or number;
That is precisely the kind of device dependence that operating systems ought to eliminate.
Instead, the \cmd{mount} system call allows the file system on the CD-ROM to be attached to the root file system wherever the program wants it to be.
In Fig. 1-7(b) the file system on drive 0 has been mounted on directory b, thus allowing access to file \sys{/b/x} and \sys{/b/y}.
If directory \sys{/b} had originally contained any files they would not be accessible while the CD-ROM was mounted, 
since \sys{/b} would refer to the root directory of drive 0.
(Not being able to access these file is not as serious as it at first seems: file systems are nearly always mounted on empty directories.)
If a system contains multiple hard disks, they can all be mounted into a single tree as well.

Another important concept in MINIX 3 is the \kw{special file}.
Special files are provided in order to make I/O devices look like files.
That way, they can be read and written using the same system calls as are used for reading and writing files.
Two kinds of special files exist: \kw{block special files} and \kw{character special files}.
Block special files are normally used to model devices that consist of a collection of randomly addressable blocks, such as disks.
By opening a block special file and reading, say, block 4, a program can directly access the fourth block on the device, 
without regard to the structure of the file system contained on it.
Similarly, character special files are used to model printers, modems, and other devices that accept or output a character stream.
By convention, the special files are kept in the \sys{/dev} directory.
For example, \sys{/dev/lp} might be the line printer.

The last feature we discuss in this overview is one that relates to both processes and files: pipes.
A \kw{pipe} is a sort of pseudofile that can be used to connect two processes, as shown in Fig. 1-8.
If processes A and B wish to talk using a pipe, they must set it up in advance.
When process A wants to send data to process B, it writes on the pipe as though it were an output file.
Process B can read the data by reading from the pipe as though it were an input file.
Thus, communication between process in MINIX 3 looks very much like ordinary file reads and writes.
Stronger yet, the only way a process can discover that the output file it is writing on is not really a file, 
but a pipe, is by making a special system call.

\subsection{The Shell}
The operating system is the code that carries out the system calls.
Editors, compilers, assemblers, linkers, and command interpreters definitely are not part of the operating system, 
even though they are important and useful.
At the risk of confusing things somewhat, in this section we will look briefly at the MINIX 3 command interpreter, called the \kw{shell}.
Although it is not part of the operating system, it makes heavy use of many operating system features 
and thus serves as a good example of how the system calls can be used.
It is also the primary interface between a user sitting at his terminal and the operating system, 
unless the user is using a graphical user interface.
Many shell exist, including \sys{csh, zsh} and \kw{bash}.
All of them support the functionality described below, which derives from the original shell (\sys{sh}).

When any user logs in, a shell is started up.
The shell has terminal as standard input and standard output.
It starts out by typing the \kw{prompt}, a character such as a dollar sign, 
which tell the user that the shell is waiting to accept a command.
If the user types\\
\cmd{data}\\
for example, the shell creates a child process and runs the \sys{data} program as the child.
While the child process is running, the shell waits for it to terminate.
When the child finishes, the shell types the prompt again and tries to read the next input line.

The user can specify that standard output be redirected to a file, for example\\
\cmd{data >file}\\
Similarly, standard input can be redirected, as in\\
\cmd{sort <file1 >file2}\\
which invokes the sort program with input taken from \sys{file1} and output sent to \sys{file2}.

The output of one program can be used as the input for another program by connecting them with a pipe. Thus\\
\cmd{cat file1 file2 file3 | sort >/dev/lp}\\
invokes the \sys{cat} program to concatenate three files and send the output to \sys{sort} to arrange all the lines in alphabetical order.
The output of \sys{sort} is redirected to the file \sys{/dev/lp}, typically the printer.

If a user puts an ampersand after a command, the shell does not wait for it to complete.
Instead it just gives a prompt immediately. Consequently,\\
\cmd{cat file1 file2 file3 | sort >/dev/lp \&}\\
starts up the sort as a backgroud job, allowing the user to continue working normally while the sort is going on.
The shell has a number of other interesting features, which we do not have space to discuss here.
Most books for UNIX beginners are useful for MINIX 3 users who want to learn more about using the system.
Examples are Ray and Ray (2003) and Herborth (2005).

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{System Calls}
Armed with our general knowledge of how MINIX 3 deals with processes and files, 
we can now begin to look at the interface between the operating system and its application programs, that is, the set of system calls.
Although this discussion specially refers to POSIX (International Standard 9945-1), hence also to MINIX 3, UNIX, and Linux, 
most other modern operating systems have system calls that perform the same functions, even if the details differ.
Since the actual mechanics of issuing a system call are highly machine dependent, and often must be expressed in assembly code, 
a procedure library provided to make it possible to make system calls from C programs.

It is useful to keep the following in mind: any single-CPU computer can execute only one instruction at a time.
If a process is running a user program in user mode and needs asystem service, such as reading data from a file, 
it has to execute a trap or system call instruction to transfer control to the operating system.
The operating system then figures out what the calling process wants by inspecting the parameters.
Then it carries out the system call and returns control to the instruction following the system call.
In a sense, making a system call is like making a special kind of procedure call, 
only system calls enter the kernel or other privileged operating system components and procedure calls do not.

To make the system call machanism clearer, let us take a quick look at \cmd{read}.
It has three parameters: 
the first one specifying the file, the second one specifying the buffer, and the third one specifying the number of bytes to read.
A call to \cmd{read} from a C program might look like this:\\
\cmd{count = read(fd, buffer, nbytes);}\\
The system call (and the library procedure) return the number of bytes actually read in \sys{count}.
This value is normally the same as \sys{nbytes}, but may be smaller, if, for example, end-of-file is encountered while reading.

If the system call cannot be carried out, either due to an invalid parameter or a disk error, \sys{count} is set to 1, 
and the error number is put in a global variable, \sys{errno}.
Programs should always check the results of a system call to see if an error occurred.

MINIX 3 has a total of 53 main system calls.
These are listed in Fig. 1-9, grouped for convenience in six categories.
A few other calls exist, but they have very specialized uses so we will omit them here.
In the folloing sections we will briefly examine each of the calls of Fig. 1-9 to see what it does.
To a large extent, the services offered by these calls determine most of what the operating system has to do, 
since the resource management on personal computers is minimal (at least compared to big machines with many users).
\\
\\
\kw{Process management}\\
\cmd{pid = fork}()\\
Create a child process identical to the parent
\\
\cmd{pid = waitpid(pid, \$statloc, opts)}\\
Wait for a child to terminate
\\
\cmd{S = wait(\&status)}\\
Old version of waitpid
\\
\cmd{S = execve(name, argv, envp)}\\
Replace a process core image
\\
\cmd{exit(status)}\\
Terminate process execution and return status
\\
\cmd{size = brk(addr)}\\
Set the size of the data segment
\\
\cmd{pid = getpid()}\\
Return the caller's process id
\\
\cmd{pid = getpgrp()}\\
Return the id of the caller's process group
\\
\cmd{pid = setsid()}\\
Create a new session and return its proc. group id
\\
\cmd{| = ptrace(req, pid, addr, data)}\\
Used for debugging
\\
\\
\kw{Signals}\\
\cmd{S = sigaction(sig, \&act, \&oldact)}\\
Define action to take on signals
\\
\cmd{S = sigreturn(\&contex)}\\
Return from a signal
\\
\cmd{S = sigprocmask(how, \&set, \&old)}\\
Examine or change the signal mask
\\
\cmd{S = sigsuspend(sigmask)}\\
Replace the signal mask and suspend the process
\\
\cmd{S = kill(pid, sig)}\\
Send a signal to a process
\\
\cmd{residual = alarm(seconds)}\\
Set the alarm clock
\\
\cmd{S = pause()}\\
Suspend the caller until the next signal
\\
\\
\kw{File Mnagement}\\
\cmd{fd = creat(name, mode)}\\
Obsolete way to creat a new file
\\
\cmd{fd = mknod(name, mode, addr)}\\
Create a regular, special, or directory i-node
\\
\cmd{fd = open (file, how, ...)}\\
OPen a file for reading, writing, or both
\\
\cmd{S = close (fd)}\\
Close an open file
\\
\cmd{n = read (fd, buffer, nbytes)}\\
Read data from a file into a buffer
\\
\cmd{n = write (fd, buffer, nbytes)}\\
Write data from a buffer into a file
\\
\cmd{pos = lseek (fd, offset, whence)}\\
MOve the file pointer
\\
\cmd{S = stat (name, \&buf)}\\
Get a file's status information
\\
\cmd{S = fstat (fd, \&buf)}\\
Get a file's status information
\\
\cmd{fd = dup (fd)}\\
Allocate a new file descriptor for an open file
\\
\cmd{S = pipe (\&fd[0])}\\
Create a pipe
\\
\cmd{S = ioctl (fd, request, argp)}\\
Performance special operations on a file
\\
\cmd{S = rename (old, new)}\\
Give a file new name
\\
\cmd{S = fcntl(fd, cmd, ...)}\\
File locking and other operations
\\
\\
\kw{Dir. \& File System Mgt.}\\
\cmd{S = mkdir (name, mode)}\\
Create a new directory
\\
\cmd{S = rmdir (name)}\\
Remove an empty directory
\\
\cmd{S = link (name1, name2)}\\
Create a new entry, name2, pointing to name1
\\
\cmd{S = unlink (name)}\\
Remove a directory entry
\\
\cmd{S = mount (special, name, flag)}\\
Mount a file system
\\
\cmd{S = unmount (special)}
Unmount a file system
\\
\cmd{S = sync()}\\
Flush all cached blocks to the disk
\\
\cmd{S = chdir(dirname)}\\
Change the working directory
\\
\cmd{S = chroot (dirname)}\\
Change the root directory
\\
\\
\kw{Protection}\\
\cmd{S = chmod (name, mode)}\\
Change a file's protection bits
\\
\cmd{uid = getuid()}\\
Get the caller's uid
\\
\cmd{gid = getgid ()}\\
Get the caller's gid
\\
\cmd{S = setuid(uid)}\\
Set the caller's uid
\\
\cmd{S = setgid(gid)}\\
Set the caller's gid
\\
\cmd{S = chown(name, owner, group)}\\
Change a file's owner and group
\\
\cmd{oldmask = umask(complmode)}\\
Change the mode mask
\\
\\
\kw{Time Management}\\
\cmd{seconds = time (\&seconds)}\\
Get the elapsed time since Jan. 1, 1970
\\
\cmd{S = stime(tp)}\\
Set the elapsed time since Jan.1, 1970
\\
\cmd{S = utime(file, timep)}\\
Set a file's ``last access'' time
\\
\cmd{S = times (buffer)}\\
Get the user and system times used so far
\\

This is a good place to point out the mapping of POSIX procedure calls onto system calls is not necessarily one-to-one.
The POSIX standard specifies a number of procedures that a conformant system must supply, 
but it does not specify wether they are system calls, library calls, or something else.
In some cases, the POSIX procedures are supported as library routines in MINIX 3.
In others, several required procedures are only minor variations of one other, and one system call handles all of them.

\subsection{System Calls for Process Management}
The first group of calls in Fig. 1-9 deals with process management.
\cmd{Fork} is a good place to start the discussion.
\cmd{Fork} is the only way to create a new process in MINIX 3.
It creats an exact duplicate of the original process, including all the file descriptors, registers, everything.
After the \cmd{Fork}, the original process and the copy (the parent and child) go their seperate ways.
All the variables have identical values at the time of the \cmd{fork}, but since the parent's data are copied to create the child, 
subsequent changes in one of them do not affect the other one.
(The program text, which is unchangeable, is shared between parent and child.)
The \cmd{Fork} call returns a value, which is zero in the child and equal to the child's process identifier or \kw{PID} in the parent.
Using the returned PID, the two processes can see which one is the parent process and which one is the child process.

In most cases, after a \cmd{fork}, the child will need to execute different code from the parent.
Consider the shell.
It reads a command from the terminal, forks off a child process, waits for the child to execute the command, 
and then reads the next command when the child terminates.
To wait for the child finish, the parent executes a \cmd{waitpis} system call, 
which just waits until the child terminates (any child of more than one exists).
\cmd{Waitpid} can wait for a specific child, or for any old child by setting the first parameter to 1.
When \cmd{waitpid} completes, the address pointed by the second parameter, \sys{statioc}, 
will be set to the child's exit status (normal or abnormal termination and exit value).
Various options are provided, specified by the third parameter.
The \cmd{waitpid} call replaces the previous \cmd{wait} call, which is now obsolete but is provided for reasons of backward compatibility.

Now consider how \cmd{fork} is used by the shell.
When a command is typed, the shell forks off a new process.
This child process must execute the user command.
It does this by using the \cmd{execve} system call, which causes its entire core image to be replaced by the file named in its first parameter.
(Actually, the system call itself is \cmd{exec}, 
but several different library procedures call it with different parameters and slightly different names. 
We will treat these as system calls here.)
A highly simplified shell illustrating the use of \cmd{fork}, \cmd{waitpid}, and \cmd{execve} is shown in Fig. 1-10.

In the most general case, \cmd{execve} has three parameters: the name of the file to be executed, 
a pointer to the argument array, and a pointer to the environment array.
These will be described shortly.
Various library rountines, including \cmd{execl, execv, execle}, and \cmd{execve}, 
are provided to allow the parameters to be ommitted or specified in various ways.
Through this book we will use the name \cmd{exec} to represent the system call invoked by all of these.

Let us consider the case of a command such as\\
\cmd{cp file1 file2}\\
used to copy \sys{file1} to \sys{file2}.
After the shell has forked, the child process locates and executes the file \sys{cp} and passes to it the names of the source and target files.

The main program of \sys{cp} (and main program of most other C programs) contains the declaration\\
\cmd{main (argc, argv, envp)}\\
where \sys{argc} is a count of the number of items on the command line, including the program name.
For example above, \sys{argc} is 3.

The second parameter, \sys{argv}, is a pointer to an array.
Element \sys{i} of that array is a pointer to the \sys{i-th} string on the command line.
In our example, \sys{argv[0]} would point to the string ``cp'', \sys{argv[1]} would point to the string ``file1'', 
and \sys{argv[2]} would point to the string ``file2''.

The third parameter of \sys{main}, \sys{envp}, is a pointer to the environment, and array of strings containing assignments 
of the form \sys{name = value} used to pass information such as the terminal type and home directory name to a program.
In Fig. 1-10, no environment is passed to the child, so the third parameter of \sys{execve} is a zero.

If \cmd{exec} seems complicated, do not dispair; it is (semantically) the most complex of all the POSIX system calls.
All the other ones are much simpler.
As an example of a simple one, consider \cmd{exit}, which processes should use when they are finished executing.
It has one parameter, the exit status (0 to 255), which is returned to the parent via \sys{statloc} in the \cmd{waitpid} system call.
The low-order byte of status contains the termination status, with 0 being normal termination and the other values being various error conditions.
The high-order byte contains the child's exit status (0 to 255).
For example, if a parent process executes the statement\\
\cmd{n = waitpid(1, \&statloc, options);}\\
it will be suspended until some child process terminates.
If the child exits with, say, 4 as the parameter to \sys{exit}, the parent will be awakened with \sys{n} set to the child's PID 
and \sys{statloc} set to 0x0400 (the C convention of prefixing hexadecimal constants with 0x will be used throughout this book).

Processes in MINIX 3 have their memory divided up into three segments: the \kw{text segment} (i.e., the program code),
the \kw{data segment} (i.e., the variables), and the \kw{stack segment}.
The data segment grows upward and the stack grows downward, as shown in Fig. 1-11.
Between them is a gap of unused address space.
The stack grows into the gap automatically, as needed, but expansion of the data segment is done explicitly by using a system call, 
\cmd{brk}, which specifies the new address where the data segment is to end.
This address may be more than the current value (data segment is growing) or less than the current value (data segment is shringking).
The parameter must, of course, be less than the stack pointer or the data and stack segments would overlap, which is forbidden.

As a convenience for programmers, a library routine \sys{sbrk} is provided that also changes the size of the data segment, 
only its parameter is the number of bytes to add to the data segment (negtive parameters make the data segment smaller).
It works by keeping track of the current size of the data segment, which is value returned by \cmd{brk}, 
computing the new size, and making a call asking for that number of bytes. 
The \cmd{brk} and \cmd{sbrk} calls, however, are not defined by the POSIX standard.
Programmers are encouraged to use the \sys{malloc} library procedure for dynamiclly allocating storage, 
and the underlying implementation of \sys{malloc} was not thought to be a suitable subject for standadization 
since few programmers use it directly.

The next process system call is also the simplest, \cmd{getpid}.
It just returns the caller's PID.
Remember that in \cmd{fork}, only the parent was given the child's PID.
If a child wants to find out its own PID, it must use \cmd{getpid}.
The \cmd{getpgrp} call returns the PID of the caller's process group.
\cmd{setsid} creates a new session and sets the process group's PID to the caller's.
Sessions are related to an optional feature of POSIX, \kw{job control}, which is not supported by MINIX 3 and which will not concern us further.

The last process management system call, \cmd{ptrace}, is used by debugging programs to control the program being debugged.
It allows the debugger to read and write the controlled process' memory and manage it other ways.

\subsection{System Calls for Signaling}
Although most forms of interprocess communication are planned, 
situation exist in which unexpected communications is needed.
For example, if a user accidently tells a text editor to list the entire contents of a very long file,
and then realizes the error, some way is needed to interrupt the editor.
In MINIX 3, the user can hit the CTRL-C key on the keyboard, which sends a \kw{signal} to the editor.
The editor catches the signal and stops the print-out.
Signals can also be used to report certain traps detected by the hardware, such as illegal instruction or floating point overflow.
Timeouts are also implemented as signals.

When a signal is sent to a process that has not announced its willingness to accept that signal,
the process is simply killed without further ado.
To avoid this fate, a process can use the \cmd{sigaction} system call to announce that it is prepared to accept some signal type,
and to provide the address of the signal handling procedure and a place to store the address of the current one.
After a \cmd{sigaction} call, if a signal of the relevant type is generated (e.g., by pressing CTRL-C), 
the state of the process is pushed onto its own stack, and then the signal handler is called.
It may run for as long as it wants to and perform any system calls it wants to.
In practice, though, signal handlers are usually fairly short.
When the signal handling procedure is done, it calls \cmd{sigreturn} to continue where it left off before the signal.
The \cmd{sigaction} call replaces the older \cmd{signal} call, which is now provided as a library procedure, 
however, for backward compatibility.

Signals can be blocked in MINIX 3.
A blocked signal is held pending until it is unblocked.
It is not delivered, but also not lost.
The \cmd{sigprocmask} call allows a process to define the set of blocked signals by presenting the kernel with a bitmap.
It is also possible for a process to ask for the set of signals currently pending but not allowed to be delivered due to their being blocked.
The \cmd{sigpending} call returns this set as a bitmap.
Finally, the \cmd{sigsuspend} call allows a process to atomically set the bitmap of blocked signals and suspend itself.

Instead of providing a function to catch a signal, the program may also specify the constant SIG\_IGN 
to have all subsequent signals of the specified type ignored, or SIG\_DFL to restore the default action of the signal when it occurs.
The default action is either to kill the process or ignore the signal, depending upon the signal.
As an example of how SIG\_IGN is used, consider what happens when the shell forks off a backgroud process as a result of\\
\cmd{command \&}\\
It would be undesirable for a SIGINT signal (generated by pressing CTRL-C) to affect the background process,
so after the \cmd{fork} but before the \cmd{exec}, the shell does\\
\cmd{sigaction (SIGINT, SIG\_IGN, NULL);}\\
and\\
\cmd{sigaction (SIGQUIT, SIG\_IGN, NULL);}\\
to disable the SIGINT amd GIGQUIT signals.
(SIGQUIT is generated by CTRL-\textbackslash; it is the same as SIGINT generated by CTRL-C 
except that if it is not caught or ignored it makes a core dump of the process killed.)
For foreground process (no ampersand), these signals are not ignored.

Hitting CTRL-C is not the only way to send a signal.
The \cmd{kill} system call allows a process to signal another process 
(provided they have the same UID, unrelated processes cannot signal each other).
Getting back to the example of backgroud process used above, suppose a backgroud process is started up, 
but later it is decided that the process should be terminated.
SIGINT and GIGQUIT have been disabled, so something else is needed.
The solution is to use the \sys{sys} program, which uses the \cmd{kill} system call to send a signal to any process.
By sending signal 9 (SIGKILL), to a backgroud process, that process can be killed.
SIGKILL cannot be caught or ignored.

For many real-time applications, a process needs to be interrupted after a specific time interval to do something, 
such as retransmit a potentially lost packet over an unreliable communication line.
To handle this situation, the \cmd{alarm} system call has been provided.
The parameter specifies an interval, in seconds, after which a SIGALARM signal is sent to the process.
A process may only have one alarm outstanding at any instant.
If an \cmd{alarm} call is made with a parameter of 10 seconds, 
and then 3 seconds later another \cmd{alarm} call is made with a parameter of 20 seconds,
only one signal will be generated, 20 seconds after the second call.
The first signal is canceled by the second call to \cmd{alarm}.
If the parameter to \cmd{alarm} is zero, any pending alarm signal is canceled.
If an alarm signal is not caught, the default action is taken and the signaled process is killed.

It sometimes occurs that the process has nothing to do until a signal arrives.
For example, consider a computer-aided-instruction program that is testing reading speed and comprehension.
It displays some text on the screen and then calls \cmd{alarm} to signal it after 30 seconds.
While the student is reading the text, the program has nothing to do.
It could sit in a tight loop doing nothing, but would waste CPU time that another process or user might need.
A better idea is to use \cmd{pause}, which tells MINIX 3 to suspend the process untill the next signal.

\subsection{System Calls for File Management}
Many sytem calls relate to the file system.
In this section we will look at calls that operate on individual files; 
in the next one we will examine those that involve directories or the file system as a whole.
To create a new file, the \cmd{creat} call is used (why the call is \cmd{creat} and not \cmd{create} has been lost in the mists of time).
Its parameters provide the name of the file and the protection mode.
Thus\\
\cmd{fd = creat ("abc", 0751);}\\
creates a file called \sys{abc} with mode 0751 octal (in C, a leading zero means that a constant is in octal).
The low-order 9 bits of 0751 specify the \sys{rwx} bits for the owner (7 means read-write-execute permission),
his group (5 means read-execute), and others (1 means execute only).

\cmd{creat} not only creates a new file but also opens it for writing, regardless of the file's mode.
The file descriptor returnd, \sys{fd}, can be used to write the file.
If a \cmd{creat} is done on an existing file, that file is truncated to lenghth 0, provided, of course, that the permissions are all right.
The \cmd{creat} call is obsolete, as \cmd{open} can now create new files, but it has been included for backward compatibility.

Special files are created using \cmd{mknod} rather than \cmd{creat}.
A typical call is\\
\cmd{fd = mknod ("/dev/ttyc2", 020744, 0x0402);}\\
which creates a file named \sys{/dev/ttyc2} (the usual name for console 2) 
and gives it mode 020744 octal (a character special file with protection bits rwxr--r--).
The third parameter contains the major device (4) in the high-order byte and the minor device (2) in the low-order byte.
The major device could have been anything, but a file named \sys{/dev/ttyc2} ought to be minor device 2.
Calls to \cmd{mknod} fail unless the caller is the superuser.

To read or write an existing file, the file must first be opened using \cmd{open}.
This call specifies the file name to be opened, either as an absolute path name or relative to the working directory, 
and a code of \sys{O\_RDONLY}, \sys{O\_WRONLY}, or \sys{O\_RDWR}, meaning open for reading, writing, or both.
The file descriptor returned can then be used for reading or writing.
Afterward, the file can be closed by \cmd{close}, which makes the file descriptor available for reuse on a subsequent \cmd{creat} or \cmd{open}.

The most heavily used calls are undoubtedly \cmd{read} and \cmd{write}.
We saw \cmd{read} earlier; \cmd{write} has the same parameters.

Although most programs read and write files sequentially, 
for some applications programs need to be able to access any part of a file at random.
Associated with each file is a pointer that indicates the current position in the file.
When reading (writing) sequentially, it normally points to the next byte to be read (written).
The \cmd{lseek} call changes the value of the position pointer, 
so that subsequent calls to \cmd{read} or \cmd{write} can begin anywhere in the file, or even beyond the end.

\cmd{lseek} has three parameters: the first is the file descriptor for the file, the second is a file position, 
and the third tells whether the file position is relative to the beginning of the file, the current position, or the end of the file.
The value returned by \cmd{lseek} is the absolute position in the file after changing the pointer.

For each file, MINIX 3 keeps track of the file mode (regular file, special file, directory, and so on),
size, time of last modification, and other information.
Programs can ask to see this information via the \cmd{stat} and \cmd{fstat} system calls.
These differ only in that the former specifies the file by name, whereas the latter takes a file descriptor, 
making it useful for open files, especially standard input and standard output, whose names may not be known.
Both calls provide as the second parameter a pointer to a structure where the information is to be put.
The structure is shown in Fig. 1-12.

When manipulating file descriptors, the \cmd{dup} call is occasionally helpful.
Consider, for example, a program that needs to close standard output (file descriptor 1), substitute another file as standard output, 
call a function that writes some output onto standard output, and then restore the original situation.
Just closing file descriptor 1 and opening a new file will make the new file standard output 
(assuming standard input, file descriptor 0, is in use),
but it will be impossible to restore the original situation later.

The solution is first to execute the statement\\
\cmd{fd = dup(1);}\\
which uses the \cmd{dup} system call to allocate a new file descriptor, \sys{fd}, and arrange for it to correspond to the same file as standard output.
Then standard output can be closed and a new file opened and used.
When it is time to restore the original situation, file descriptor 1 can be closed, and the\\
\cmd{n = dup(fd)}\\
executed to assign the lowest file descriptor, namely, 1 to the same file as \sys{fd}.
Finally, \sys{fd} can be closed and we are back where we started.

The \cmd{dup} call has a variant that allows an arbitrary unassigned file descriptor to be made to refer to a given open file.
It is called by\\
\cmd{dups(fd, fd2);}\\
where \sys{fd} refers to an open file and \sys{fd2} is the unassigned file descriptor that is to be made refer to the same file as \sys{fd}.
Thus if \cmd{fd} refers to standard input (file descriptor 0) and \sys{fd2} is 4, after the call, 
file descriptors 0 and 4 will both refer to standard input.

Interprocess communication in MINIX 3 uses pipes, as described earlier.
When a user types\\
\cmd{cat file1 file 2 | sort}\\
the shell creates a pipe and arranges for standard output of the first process to write to the pipe,
so standard input of the second process can read from it.
The \cmd{pipe} system call creates a pipe and returns two file descriptors, one for writing and one for reading.
The call is\\
\cmd{pipe (\&fd[0]);}\\
where \sys{fd} is an array of two integer and \sys{fd[0]} is the file descriptor for reading and \sys{fd[1]} is the one for writing.
Typically, a \cmd{fork} comes next, and the parent closes the file descriptor for reading 
and the child close the file descriptor for writing (or vice versa),
so when they are done, one process can read the pipe and the other can write on it.

Fig. 1-13 depicts a skeleton procedure that creates two processes, with the output of the first one piped into the second one.
(A more realistic example would do error checking and handle arguments.)
First a pipe is created, and then the procedure forks, with the parent eventually becoming the first process in the pipeline 
and the child process becoming the second one.
Since the files to be executed, \sys{prcess1} and \sys{process2}, do not known  that they are part of a pipeline, 
it is essential that the file descriptors be manipulated so that the first process' standard output be the pipe 
and the second one's standard input be the pipe.
The parent first closes off the file descriptor for reading from the pipe.
Then it closes standard output and does a \cmd{dup} call that allows file descriptor 1 to write on the pipe.
It is important to realize that \cmd{dup} always returns the lowest available file descriptor, in this case, 1.
Then the program closes the other pipe file descriptor.

After the \cmd{exec} call, the process started will have file descriptors 0 and 2 be unchanged, 
and file descriptor 1 for writing on the pipe.
The child code is analogous.
The parameter to \sys{execl} is repeated because the first one is the file to be executed and the second one is the first parameter, 
which most programs expect to be the file name.

The next system call, \cmd{ioctl}, is potentially applicable to all special files.
It is, for instance, used by block device drivers like the SCSI driver to control tape and CD-ROM devices.
Its main use, however, is with special character files, primarily terminals.
POSIX defines a number of functions which the library translates into \cmd{ioctl} calls.
The \sys{tcgetattr} and \sys{tcsetattr} library functions use \cmd{ioctl} to change the characters used for 
correcting typing errors on the terminal, changing the \kw{terminal mode}, and so forth.

Traditionally, there are three terminal modes, cooked, raw, and cbreak.
\kw{Cooked mode} is the normal terminal mode, in which the erase and kill characters work normally, 
CTRL-S and CTRL-Q can be used for stopping and starting terminal output, 
CTRL-D means end of file, 
CTRL-C generates an interrupt signal, and 
CTRL-\textbackslash generates a quit signal to force a core dump.
 
In \kw{raw mode}, all of these functions are disabled; consequently, every character is passed directly to the program with no special processing.
Furthermore, in raw mode, a read from the terminal will give the program any characters that have been typed, 
even a partial line, rather than waiting for a complete line to be typed, as in cooked mode.
Screen editors often use this mode.

\kw{Cbreak mode} is in between.
The erase and kill characters for editing are disabled, as is CTRL-D, but CTRL-S, CTRL-Q, CTRL-C, and CTRL-\textbackslash are enabled.
Like raw code, partial lines can be returned to programs (if intraline editing is turn off there is no need 
to wait until a whole line has been received, the user cannot change his mind and detete it, as he can in cooked mode). 

POSIX does not use the term cooked, raw, and cbreak.
In POSIX terminology \kw{canonical mode} corresonds to cooked mode.
In this mode there are eleven special characters defined, and input is by lines.
In \kw{noncanonical mode} a minimum number of characters to accept and a time, specified in units of 1/10th of second, 
determine how a read will be satisfied.
Under POSIX there is a great deal of flexibility, and various flags can be set to make noncanonical mode behave like either cbreak or raw mode.
The older terms are more descriptive, and we continue to use them informally.

\cmd{Ioctl} has three parameters, for example a call to \sys{tcsetattr} to set terminal parameters will result in\\
\cmd{ioctl (fd, TCSETS, \&termios);}\\
The first parameter specifies a file, the second one specifies an operation, 
and the third one is the address of the POSIX structure that contains flags and the array of control characters.
Other operation codes instruct the system to postpone the changes until all output has been sent,
cause unread input to be discarded, and return the current values.

The \cmd{access} system call is used to determine whether a certain file access is permitted by the protection system.
It is needed because some programs can run using a differnt user's UID.
This SETUID mechanism will be described later.

The \cmd{rename} system call is used to give a file a new name.
The parameters specify the old and new names.

Finally, the \cmd{fcntl} call is used to control files, somewhat analogous to \cmd{ioctl} (i.e., both of them are horrible hacks).
It has several options, the most important of which is for advisory file locking.
Using \cmd{fcntl}, it is possible for a process to lock and unlock parts of files and test part of a file to see if it is locked.
The call does not enforce any lock semantics.
Programs must do this themselves.

\subsection{System Calls for Directory Management}
In this section, we will look at some system calls that relate more to directories or the file system as a whole,
rather than just to one specific file as in the previous section.
The first two calls, \cmd{mkdir} and \cmd{rmdir}, create and remove empty directories, respectively.
The next call is \cmd{link}.
Its purpose is to allow the same file to appear under two or more names, often in different directories.
A typical use is to allow several members of the same programming team to share a common file, 
with each of them having the file appear in his own directory, possibly under different names.
Sharing a file is not the same as giving every team member a private copy, 
because having a shared file means that changes that any member of the team makes are instantly visible to the other members,
there is only one file.
When copies are made of a file, subsequent changes made to one copy do not affect the other ones.
 
To see how \cmd{link} works, consider the situation of Fig. 1-14(a).
Here are two users, \sys{ast} and \sys{jim}, each having their own directories with some files.
If \sys{ast} now executes a program containing the system call\\
\cmd{link ("/usr/jim/memo", "usr/ast/note");}\\
the file \sys{memo} in \sys{jim}'s directory is now entered into \sys{ast}'s directory under the name \sys{note}.
Thereafter, \sys{/usr/jim/memo} and \sys{/usr/ast/note} refer to the same file.
 
Understanding how \cmd{link} works will probably make it clearer what it does.
Every file in UNIX has a unique number its i-number, that identifies it.
This number is an index into a table of \kw{i-nodes}, one per file, telling who owns the file, 
where its disk blocks are, and so on.
A directory is simply a file containing a set of (i-number, ASCII name) pairs.
In the first versions of UNIX, each directory entry was 16 bytes: 2 bytes for the i-number and 14-bytes for the name.
A more complicated structure is needed to support long file names, but conceptually a directory is still a set of (i-number, ASCII name) pairs.
In Fig. 1-14, \sys{mail} has i-number 16, and so on.
What \cmd{link} does is simply create a new directory entry with a (possibly new) name, using the i-number of an existing file.
In Fig. 1-14(b), two entries have the same i-number (70) and thus refer to the same file.
If either one is later removed, using the \cmd{unlink} system call, the other one remains.
If both are removed, UNIX sees that no entries to the file exist 
(a field in the i-node keeps track of the number of directory entries pointing to the file), so the file is removed from the disk.

As we have mentioned early, the \cmd{mount} system call allows two file systems to be merge into one.
A common situation is to have the root system containing the binary (executable) versions of the common commands 
and other heavily used files, on a hard disk.
The user can then insert a CD-ROM with files to be read into the CD-ROM drive.

By executing the \cmd{mount} system call, the CD-ROM file system can be attached to the root file system, as shown in Fig. 1-15.
A typical statement in C to perform the mount is\\
\cmd{mount ("/dev/cdrom0", "/mnt", 0);}\\
where the first parameter is the name of a block special file for CD-ROM drive 0, 
the second parameter is the place in the tree where it is to be mounted,
and the third one tells whether the file system is to be mounted read-write or read-only.

After the \cmd{mount} call, file on CD-ROM drive 0 can be accessed by just using its path from the root directory or the working directory,
without regard to which drive it is on.
In fact, second, third and fourth drives can also be mounted anywhere in the tree.
The \cmd{mount} call makes it possible to integrate removable media into a single integrated file hierarchy,
without having to worry about which device a file is on.
Although this example involves CD-ROMs, hard disks or portions of hard disks
(often called \kw{partitions} or \kw{minor devices}) can also be mounted this way.
When a file system is no longer needed, it can be unmounted with the \cmd{unmount} system call.

MINIX 3 maintains a \kw{block cache} cache of recently used blocks in main memory to avoid having to read them from the disk
if they are used again quickly.
If a block in the cache is modified (by a \cmd{write} on a file) and the system crashes before the modified block is written out to disk, 
the file system will be damaged.
To limit the potential damage, it is important to flush the cache periodically,
so that the amount of data lost by a crash will be small.
The system call \cmd{sync} tells MINIX 3 to write out all the cache blocks that have been modified since being read in.
When MINIX 3 is started up, a program called \sys{update} is started as a background process 
to do a \cmd{sync} every 30 seconds, to keep flushing the cache.

Two other calls that relate to directories are \cmd{chdir} and \cmd{chroot}.
The former changes the working directory and the latter changes the root directory.
After the call\\
\cmd{chdir ("/usr/ast/test");}\\
an open on the file \sys{xyz} will open \sys{/usr/ast/test/xyz}.
\cmd{chroot} works in an analogous way.
Once a process has told the system to change its root directory, 
all absolute path names (path names beginning with a ``/'') will start at the new root.
Why would you want to do that?
For security server programs for protocols such as \kw{FTP} (File Transfer Protocol) and \kw{HTTP} (HyperText Transfer Protocol) 
do this so remote users of these services can access only the portions of a file system below the new root.
Only superusers may execute \cmd{chroot}, and even superusers do not do it very often.

\subsection{System Calls for Protection}
In MINIX 3 every file has an 11-bit mode used for protection.
Nine of these bits are the read-write-execute bits for the owner, group, and others.
The \cmd{chmod} system call makes it possible to change the mode of a file.
For example, to make a file read-only by everyone except the owner, one could execute\\
\cmd{chmod ("file", 0644);}\\
The other two protection bits, 02000 and 04000, are the SETGID (set-group-id) and SETUID (set-user-id) bits, respectively.
When any user executes a program with the SETUID bit on, 
for the duration of that process the user's effective UID is changed to that of the file's owner.
This feature is heavily used to allow users to execute programs that perform superuser only functions, such as creating directories.
Creating a directory uses \cmd{mknod}, which is for the superuser only.
By arranging for the \sys{mkdir} program to be owned by the superuser and have mode 04755, 
ordinary users can be given the power to execute \cmd{mknod} but in a highly restricted way.

When a process executes a file that has the SETUID or SETGID bit on in its mode,
it acquires an effective UID or GID different from its real UID or GID.
It is sometimes important for a process to find out what its real and effective UID or GID is.
The system calls \cmd{getuid} and \cmd{getgid} have been provided to supply this information.
Each call returns both the real and effective UID or GID, so four library routines were needed to extract the proper information:
\sys{getuid}, \sys{getgid}, \sys{geteuid}, and \sys{getegid}.
The first two get the real UID/GID, and the last two the effective ones.

Ordinary users cannot change their UID, except by executing programs with the SETUID bit on,
but the superuser has another possibility: the \cmd{setuid} system call, which sets both the effective and real UIDs. 
\cmd{setgid} sets both GIDs.
The superuser has plenty of opportunity for violating all the protection rules,
which explains why so many students devote so much of their time to trying to become superuser.

The last two system calls in this category can be executed by ordinary user processes.
The first one, \cmd{umask}, sets an internal bit mask within the system, which is used to mask off mode bits when a file is created.
After the call\\
\cmd{umask (022);}\\
the mode supplied by \cmd{creat} and \cmd{mknod} will have the 022 bits masked off before being used.
Thus the call\\
\cmd{creat ("file", 0777);}\\
will set the mode to 0755 rather than 0777.
Since the bit mask is inherited by child processes, if the shell does a \cmd{umask} just after login, 
none of the user's processes in that session will accidently create files that other people can write on.
 
When a program owned by the root has the SETUID bit on, it can access any file, because its effective UID is the superuser.
Frequently it is useful for the program to know if the person who called the program has permission to access a given file.
If the program just tries the access, it will always succeed, and thus learn nothing.

What is needed is a way to see if the access is permitted for the real UID.
The \cmd{access} system call provides a way to find out.
The \sys{mode} parameter is 4 to check for read access, 2 for write access, and 1 for execute access.
Combinations of these values are also allowed.
For example, with \sys{mode} equal to 6, the call returns 0 if both read and write access are allowed for the real ID;
otherwise 1 is returned.
With \sys{mode} equal to 0, a check is made to see if the file exists and the directories leading up to it can be searched.

Although the protection mechanisms of all UNIX-like operating systems are generally similar, 
there are some differences and inconsistencies that lead to security vulnerabilities.
See Chen et al.(2002) for a discussion.

\subsection{System Calls for Time Management}
MINIX 3 has four system calls that involve the time-of-day clock.
\cmd{Time} just returns the current time in seconds, with 0 corresponding to Jan. 1, 1970 at midnight (just as the day was starting, not ending).
Of course, the system clock must be set at some point in order to allow it to be read later,
so \cmd{stime} has been provided to let the clock be set (by the superuser).
The third time call is \cmd{utime}, which allows the owner of a file (or the superuser) to change the time stored in a file's i-node.
Application of this system call is fairly limited, but a few programs need it, 
for example, \sys{touch}, which sets the file's time to the current time.

Finally, we have \cmd{times}, which returns the accounting information to a process,
so it can see how much CPU time it has used directly, 
and how much CPU time the system itself has expended on its behalf (handling its system calls).
The total user and system times used by all its children combined are also returned.

%---------------------------------------------------------------------------------------------------------------------------------------------------%
\section{Operating System Structure}
Now that we have seen what operating systems look like on the outside (i.e., the programmer's interface),
it is a time to take a look inside.
In the following sections, we will examine five different structures that have been tried,
in order to get some idea of the spectrum of possibilities.
These are by no means exhaustive, but they give an idea of some designs that have been tried in practice.
The five designs are monolithic systems, layered systems, virtual machines, exokernels, and client-server systems.

\subsection{Monolithic Systems}
By far the most common organization, this approach might well be subtitled ``The Big Mess''.
The structure is that there is no structure.
The operating system is written as a collection of procedure, each of which can call any of the other ones whenever it needs to.
When this technique is used, each procedure in the system has a well-defined interface in terms of parameters and results,
and each one is free to call any other one, if the latter provides some useful computation that the former needs.

To construct the actual object program of the operating system when this approach is used, 
one first compiles all the individual procedures, or files containing the procedures, 
and then binds them all together into a single object file using the system linker.
In terms of information hiding, there is essentially none every procedure is visible to every other procedure
(as opposed to a structure containing modules or packages, in which much of the information is hidden away inside modules,
and only the officially designated entry points can be called from outside the module).  

Even in monolithic systems, however, it is possible to have at least a little structure.
The services (system calls) provided by the operating system are requested by 
putting the parameters in well-defined places, such as in registers or on the stack,
and then executing a special trap instruction known as a \kw{kernel call} or \kw{supervisor call}.

This instruction switches the machine from user mode to kernel mode and transfers control to the operating system.
(Most CPUs have two modes: kernel mode, for the operating system, in which all instructions are allowed;
and user mode, for user programs, in which I/O and certain other instructions are not allowed.)

This is a good time to look at how system calls are performed.
Recall that the \cmd{read} call is used like this:\\
\cmd{count = read(fd, buffer, nbytes);}

In preparation for calling the \sys{read} library procedure, which actually makes the \cmd{read} system call,
the calling program first pushes the parameters onto the stack, as shown in steps 13 in Fig. 1-16.
C and C++ compilers push the parameters onto the stack in reverse order for historical reasons
(having to do with making the first parameters to \sys{printf}, the format string, appear on top of the stack).
The first and third parameters are called by value, but the second parameter is passed by reference,
meaning that the address of the buffer (indicated by \&) is passed, not the contents of the buffer.
Then comes the actual call to the library procedure (step 4).
This instruction is the normal procedure call instruction used to call all procedures.

The library procedure, possibly written in assembly language, 
typically puts the system call number in place where the operating system expects it, such as register (step 5).
Then it executes a \cmd{trap} instruction to switch from user mode to kernel mode 
and start execution at a fixed address within the kernel (step 6).
The kernel code that starts examines the system call number and then dispatches to the correct system call handler,
usually via a table of pointers to system call handlers indexed on system call number (step 7).
At that point the system call handler runs (step 8).
Once the system call handler has completed its work, 
control may be returned to the user-pace library procedure at the instruction following the \cmd{trap} instruction (step 9).
This procedure then returns to the user program in the usual way procedure calls return (step 10).

To finish the job, the user program has to clean up the stack, as it does after any procedure call (step 11).
Assuming the stack grows downward, as it often does, 
the compiled code increments the stack pointer exactly enough to remove the parameters pushed before the call to \sys{read}.
The program is now free to do whatever it wants to do next.

In step 9 above, we said ``may be returned to the user-space library procedure'' for good reason.
The system call may block the caller, preventing it from continuing.
For example, if it is trying to read from the keyboard and nothing has been typed yet, the caller has to be blocked.
In this case, the operating system will look around to see if some other process can be run in next.
Later, when the desired input is available, this process will get the attention of the system and step 9-11 will occur.

This organization suggests a basic structure of the operating system:
\begin{enumerate}
  \item A main program that invokes the requested service procedure.
  \item A set of service procedures that carry out the system calls.
  \item A set of utility procedures that help the service procedures.
\end{enumerate}

In this model, for each system call there is one service procedure that takes care of it.
The utility procedures do things are needed by several service procedures, such as fetching data from user programs.
This division of the procedures into three layers is shown in Fig. 1-17.

\subsection{Layered Systems}
A generalization of the approach of Fig. 1-17 is to organize the operating system as a hierarchy of layers,
each one constructed upon the one below it.
The first system constructed in this way was THE system 
built at the Technische Hogeschool Eindhoven in the Netherlands by E.W. Dijkstra (1968) and his students.
The THE system was a simple batch system for a Dutch computer, the Electrologica X8,
which had 32K of 27-bit words (bits were expensive back then).

The system had 6 layers, as shown in Fig. 1-18.
Layer 0 dealt with allocation of the processor, switching between processes when interrupts occurred or timers expired.
Above layer 0, the system consisted of sequential processes, each of which could be programmed without having to worry about the fact 
that multiple process are running on a single processor.
In other words, layer 0 provided the basic multiprogramming of the CPU.

Layer 1 did the memory management.
It allocated space for processes in main memory and on a 512K word drum used for holding parts of processes (pages) 
for which there was no room in main memory.
Above layer 1, processes did not have to worry about wether they were in memory or on the drum;
the layer 1 software took care of making sure pages were brought into memory whenever they were needed.

Layer 2 handled communication between each process and the operator console.
Above this layer each process effectively had its own operator console.
Layer 3 took care of managing the I/O devices and buffering the information streams to and from them.
Above layer 3 each process could deal with abstract I/O devices with nice properties, 
instead of real devices with many peculiarities.
Layer 4 was where the user  programs were found.
They did not have to worry about process, memory, console, or I/O management.
The system operator process was located in layer 5.

A further generalization of the layering concept was present in the MULTICS system.
Instead of layers, MULTICS was organized as a series of concentric rings, with the inner ones being more privileged than the outer ones.
When a procedure in an outer ring wanted to call a procedure in an inner ring,
it has to make the equivalent of a system call, that is, a TRAP instruction
whose parameters were carefully checked for validity before allowing the call to proceed.
Although the entire operating system was part of the address space of each user process process in MULTICS,
the hardware made it possible to designate individual procedures (memory segments, actually)
as protected against reading, writing, or executing.

Whereas the THE layering scheme was really only a design aid, 
because all the parts of the system were ultimately linked together into a single object program, in MULTICS,
the ring mechanism was very much present at run time and enforced by the hardware.
The advantege of the ring mechanism is that it can easily be extended to structure user subsystems.
For example, a professor could write a program to test and grade student programs and run this program in ring \sys{n},
with the student programs running in ring \sys{n} + 1 so that they could not change their grades.
The Pentium hardware supports the MULTICS ring structure, but no major operating system uses it present.

\subsection{Virtual Machines}
The initial releases of OS/360 were strictly batch systems.
Neverthless, many 360 users wanted to have timesharing, so various groups, 
both inside and outside IBM decided to write timesharing system for it.
The official IBM timesharing system, TSS/360, was delivered late, 
and when it finally arrived it was so big and slow that few sites converted to it.
It was eventually abandoned after its development had consumed some \$50 million (Graham, 1970).
But a group at IBM'S Scientific Center in Cambridge, Massachusetts, 
produced a radically different system that IBM eventually accepted as a product,
and which is now used on its mainframes.

This system, originally called CP/CMS and later renamed VM/370 (Seawright and MacKinnon, 1979),
was based on a very astute observation: a timesharing system provides
(1) multiprogramming and
(2) an extended machine with a more convenient interface than the bare hardware.
The essence of VM/370 is to completely seperate these two functions.
 
The heart of the system, known as the \kw{virtual machine monitor}, runs on the bare hardware and does the multiprogramming,
providing not one, but several virtual machines to the next layer up, as shown in Fig. 1-19.
However, unlike all other operating systems, these virtual machines are not extended machines, with files and other nice features.
Instead, they are \sys{exact} copies of the bare hardware, 
including kernel/user mode, I/O, interrupts, and everything else real machine has.

Because each virtual machine is identical to the true hardware, 
each one can run any operating system that will run directly on the bare hardware.
Different virtual machines can, and frequently do, run different operating systems.
Some run one of the descendants of OS/360 for batch or transaction processing, 
while others run a single-user, interactive system called \kw{CMS} (Conversational Monitor System) for timingsharing users.

When a CMS program executes a system call, the call is trapped to operating-system in its own virtual machine,
not to VM/370, just as it would if it were running on a real machine instead of a virtual one.
CMS then issues the normal hardware I/O instructions for reading its virtual disk or whatever is needed to carry out the call.
These I/O instructions are trapped by VM/370, which then performs them as part of its simulation of the real hardware.
By making a complete separation of the functions of multiprogramming and providing an extended machine, 
each of the pieces can be much simpler, more flexible, and easier to maintain.

The idea of a virtual machine is used nowadays in a different contex: runing old MS-DOS programs on a Pentium.
When designing the Pentium and its software, both Intel and Microsoft realized that 
there would be a big demand for running old software on new hardware.
For this reason, Intel provided a virtual 8086 mode on the Pentium.
In this mode, the machine acts like an 8086 (which is identical to an 8088 from a software point of view),
including 16-bit addressing with a 1-MB limit.

This mode is used by Windows, and other operating systems for running old MS-DOS programs.
These programs are started up in virtual 8086 mode.
As long as they execute normal instructions, they run on the bare hardware.
However, when a program tries to trap to the operating system to make a system call,
or tries to do protected I/O directly, a trap to the virtual machine monitor occurs.

Two variants on this design are possible.
In the first one, MS-DOS itself is loaded into the virtual 8086's address space, 
so the virtual machine monitor just reflects the trap back to MS-DOS, just as would happen on a real 8086.
When MS-DOS later tries to do the I/O itself, that operation is caught and carried out by the virtual machine monitor.

In the other variant , the virtual nachine monitor just catches the first trap and does I/O itself,
since it knowns what all the MS-DOS system calls are and thus known what each trap is supposed to do.
This variant is less pure than the first one, since it emulates only MS-DOS correctly, and not other operating systems, as the first one does.
On the other hand, it is much faster, since it saves the trouble of starting up MS-DOS to do the I/O.
A further disadvantage of actually running MS-DOS in virtual 8086 mode is that MS-OS fiddles around with the interrupt enable/disable bit quite a lot, 
all of which must be emulated at considerable cost.

It is worth nothing that neither of these approaches are really the same as VM/370, 
since the machine being emulated is not a full Pentium, but only an 8086.
With the VM/370, it is possible to run VM/370, itself, in the virtual machine.
Even the earliest vertion of Windows require at least a 286 and cannot be run on a virtual 8086. 

Several virtual machine implementations are marked commercally.
For companies that provide web-hosting services, it can be more ecnomical to run multiple virtual machines 
on a single fast server (perhaps one with multiple CPUs) than to run many small computers, each hosting a single Web site.
VMWare and Microsoft's Virtual PC are marked for such installations.
These programms use large files on a host system as simulated disks for their guest systems.
To achive efficiency they analyze guest system program binaries and allow safe code to run directly on the host hardware,
trapping instructions that make operating system calls.
Such systems are also useful in education.
For instance, students working on MINIX 3 lab assignments can work using MINIX 3 as a guest operating system 
on VMWare on a Windows, Linux or UNIX host with no risk of damaging other software installed on the same PC.
Most professors teaching other subjects would be very nervous about sharing laboratory computers with an operating systems course 
where student mistakes could corrupt or erase disk data.

Another are a where virtual machines are used, but in a somewhat different way, is for running Java programs.
When Sun Microsystems invented the Java programming language, 
it also invented a virtual machine (i.e., a computer architecture) called \kw{JVM (Java Virtual Machine)}.
The Java compiler produces code for JVM, which then typically executed by a software JVM interpreter.
The advantage of this approach is that the JVM code can be shipped over the Internet to any computer 
that has a JVM interpreter and run there.
If the compiler had produced SPARC or Pentium binary programs, for example, they could not have been shipped and run anywhere as easily.
(Of course, Sun could have produced a compiler that produced SPARC binaries and then distributed a SPARC interpreter, 
but JVM is a much simpler architecture to interpret.)
Another advantage of using JVM is that if the interpreter is implemented properly, which is not completely trivial, 
incoming JVM programs can be checked for safety and then executed in a protected environment so they cannot steal data or do any damage.

\subsection{Exokernels}
With VM/370, each user process gets an exact copy of the actual computer.
With virtual 8086 mode on the Pentium, each user process gets an exact copy of a different computer.
Going one step further, researchers at M.I.T. built a system that gives each user a clone of the actual computer,
but with a subset of the resources (Engler et al., 1995; and Leschke, 2004).
Thus one virtual machine might get disk blocks 0 to 1023, 
the next one might get blocks 1024 to 2047, and so on.

At the bottom layer, running in kernel mode, is a program called \kw{exokernel}.
Its job is to allocate resources to virtual machines and then check attempts to use them 
to make sure no machine is trying to use somebody else's resources.
Each user-level virtual machine can run its own operating system, as on VM/370 and the Pentium virtual 8086s,
except that each one is restricted to using only the resources it has asked for and been allocated.

The advantage of the exokernel scheme is that it saves a layer of mapping.
In the other designs, each virtual machine thinks it has its own disk, with blocks running from 0 to some maximum,
so the virtual machine monitor must maintain tables to remap disk addresses (and all other resources).
With the exokernel, this remapping is not needed.
The exokernel need only keep track of which virtual machine has been assigned with resource.
This method still has the advantage of separating the multiprogramming (in the exokernel) from 
the user operating system code (in user space), but with less overhead,
since all the exokernel has to do is keep the virtual machines out of each other's hair.
 
\subsection{Client-Server Model}
VM/370 gains much in simplicity by moving a large part of the traditional operating system code 
(implementing the extended machine) into a higher layer, CMS.
Nevertheless, VM/370 itself is still a complex program because simulating a number of virtual 370s is not that simple
(especially if you want to do it reasonably efficiently).

A trend in modern operating systems is to take this idea of moving code up into higher layers even further 
and remove as much as possible from the operating system, leaving a minimal \kw{kernel}.
The usual approach is to implement most of the operating system functions in user processes.
To request a service, such as reading a block of a file, 
a user process (now known as the \kw{client process}) sends the request to a \kw{server process},
which then does the work and sends back the answer.

In this model, shown in Fig. 1-20, all the kernel does is handle the communication between clients and servers.
By splitting the operating system up into parts, each of which only handles one facet of the system,
such as file service, process service, terminal service, or memory service, each part becomes small and manageable.
Furthermore, because all the servers run as user-mode processes, and not in kernel mode, 
they do not have direct access to the hardware.
As a consequence, if a bug in the file server is triggered, the file service may crash, 
but this will not usually bring the whole machine down.

Another advantage of the client-server model is its adaptability to use in distributed systems (see Fig. 1-21).
If a client communicates with a server by sending it messages, 
the client need not know whether the message is handled locally in its own machine,
or whether it was sent across a network to a server on a remote machine.
As far as the client is concerned, the same thing happens in both cases: 
a request was sent and a reply came back.

The picture painted above of a kernel that handles only the transport of messages from clients to servers 
and back is not completely realistic.
Some operating system functions (such as loading commands into the physical I/O device registers) are difficult, 
if not impossible, to do from user space programs.
There are two ways of dealing with this problem.
One way is to have some critical server processes (e.g., I/O device drivers) actually run in kernel mode, 
with complete access to all the hardware, but still communicate with other processes using the normal message mechanism.
A variant of this mechanism was used in earlier version of MINIX where drivers were compiled into the kernel but ran as separate processes.

The other way is to build a minimal amount of \kw{mechanism} into the kernel but leave the \kw{policy} decisions up to servers in user space.
For example, the kernel might recognize that a message sent to a certain special address means to take the contents of that message
and load it into the I/O device registers for some disk, to start a disk read.
In this example, the kernel would not even inspect the bytes in the message to see if they were valid or meaningful;
it would just blindly copy them into the disk's device registers.
(Obviously, some scheme for limiting such message to authorized processes only must be used.)
This is how MINIX 3 works, drivers are in user space and use special kernel calls to request reads and writes of I/O registers or to access kernel information.
The split between mechanism and policy is an important concept; it occurs...

\section{Outline of the Rest of This Book}
Operating systems typically have four major components: 
process management, I/O device management, memory management, and file management.
MINIX 3 is also divided into these four parts.
The next four chapters deal with these four topics, one topic per chapter.
Chapter 6 is a list of suggested reading and a bibliography.

The chapters on processes, I/O, memory management, and file systems have the same general structure.
First the general principles of the subject are laid out.
Then comes an overview of the corresponding area of MINIX 3 (which also applied to UNIX).
Finally, the MINIX 3 implementation is discussed in detail.
The implementation section may be skimmed or skipped without loss of continuity by readers 
just interested in the principles of operating systems and not interested in the MINIX 3 code.
Readers who are interested in finding out how a real operating system (MINIX 3) works should read all the sections.

\section{Summary}
Operating systems can be viewed from two viewpoints: resource manager and extended machines.
In the resource manager view, the operating system's job is to efficently manage the different parts of the system.
In the extended machine view, the job of the system is to provide the users with a virtual machine 
that is more convenient to use than the actual machine.
 
Operating systems have a long history, starting from the days when they replaced the operator,
to modern multiprogramming systems.

The heart of any operating system is the set of system calls that it can handle.
These tell what the operating system really does.
For MINIX 3, these calls can be divided into six groups.
The first group of system calls relates to process creation and termination.
The second group handles signals.
The third group is for reading and writing files.
A fourth group is for directory management.
The fifth group protects information, and the sixth group is about keeping track of time.

Operating systems can be structured in several ways.
The most common ones are as a monolithic system, as a hierarchy of layers, as a virtual machine system,
using an exokernel, and using the client-server model.

\section{Problems}
\begin{enumerate}
\item What are the two main functions of an operating system?
\item What is the difference between kernel mode and user mode? Why is the difference important to an operating system?
\item What is multiprogramming?
\item What is spooling? Do you think that advanced personal computers will have spooling as a standard feature in the future?
\item One early computers, every byte of data read or written was directly handled by the CPU (i.e., there was no DMA Directed Memory Access).
      What implications does this organization have for multiprogramming?
\item Why was timesharing not widespread on second-generation computers?
\item Which of the following instructions should be allowed only in kernel mode?\\
      (a) Disable all interrupts.\\
      (b) Read the time-of-day clock.\\
      (c) Set the time-of-day clock.\\
      (d) Change the memory map.
\item List some differences between personal computer operating systems and mainframe operating systems.
\item Give one reason why a closed-source proprietary operating system like Windows should have better quality than 
      an open source operating system like Linux.
      Now give one reason why an open-source operating system like Linux should have better quality than 
      a closed-source proprietary operating system like Windows.
\item A MINIX file whose owner has UID = 12 and GID = 1 has mode \sys{rwxr-x---}.
      Another user with UID = 6, GID = 1 tries to execute the file. What will happen?
\item In view of the fact that the mere existence of a superuser can lead to all kinds of security problems, why does such a concept exist?
\item All versions of UNIX support file naming using both absolute paths (relative to the root) and 
      relative paths (relative to the working directory). 
      Would it be possible to dispose of one of these and just use the other?
      If so, which would you suggest keeping?
\item Why is the process table needed in a timesharing system?
      Is it also needed in personal computer systems in which only one process exists,
      that process taking over the entire machine until it is finished?
\item What is the essential difference between a block special file and a character special file?
\item In MINIX 3 if user 2 links to a file owned by user 1, then user 1 removes the file, what happens when user 2 tries to read the file?
\item Are pipes an essential facility? Would major functionality be lost if they were not available?
\item Modern consumer appliances such as stereos and digital cameras often have a display 
      where commands can be enterned and the results of entering those commands can be viewed.
      These devices often have a primitive operating system inside.
      To what part of a personal computer software is the command processing via the stereo or camera's display similar to?
\item Windows does not have a \cmd{fork} system call, yet it is able to create new processes.
      Make an educated guess about the semantics of the system call Windows uses to create new processes.
\item Why is the \cmd{chroot} system call limited to the superuser? (Hint: Think about protection problems.)
\item Examine the list of system calls in Fig. 1-9.
      Which call do you think is likely to execute most quickly.
      Explain your answer.
\item Suppose that a computer can execute 1 billion instructions/sec and that a system call takes 1000 instructions,
      including the trap and all the context switching.
      How many system calls can the computer execute per second and still have half the CPU  capacity for running application code?
\item There is a \cmd{mknod} system call in Fig. 1-16 but there is no \cmd{rmnod} call.
      Does this mean that you have to be very, very careful about making nodes this way because there is no way to every remove them?
\item Why does MINIX 3 have the program \sys{update} running in the background all the time?
\item Does it ever make any sense to ignore the SIGALARM signal?
\item The client-server model is popular in distributed systems.
      Can it also be used in a single-computer system?
\item The initial version of the Pentium could not sopport a virtual machine monitor.
      What essential characteristics is needed to allow a machine to be virtualizable?
\item Write a program (or series of programs) to test all the MINIX 3 system calls.
      For each call, try various sets of parameters, including some incorrect ones, to see if they are detected.
\item Write a shell that is similar to Fig. 1-10 but contains enough code that it actually works so you can test it.
      You might add some features such as redirection of input and output, pipes, and background jobs.
\end{enumerate}


\chapter{Processes}
We are now about to embark on a detailed study of how operating systems, in general, and MINIX, in particular, are designed and constructed.
The most central concept in any operating system is the \sys{process}: an abstraction of a running program.
Everything else hinges on this concept, and it is important that the operating system designer (and student) understand this concept well.

\section{Introduction to Processes}
All modern computers can do several things at the same time.
While running a user program, a computer can also be reading from a disk and outputting text to a screen or printer.
In a multiprogramming system, the CPU also swithches from program to program, 
running each for tens or hundreds of milliseconds.
While, strictly speaking, at any instant of time, the CPU is running only one program, 
in the course of 1 second, it may work on several programs, thus giving the users the illusion of parallelism.
Sometimes people speak of \kw{pseudoparallelism} in this context, 
to constrast it with the true hardware parallelism of \kw{multiprocessor} systems (which have two or more CPUs sharing the same physical memory).
Keeping track of multiple, parallel activities is hard for people to do.
Therefore, operating system designers over the years have evolved a conceptual model (sequential process) 
that makes parallelism easier to deal with.
That model, its uses, and some of its consequences form the subject of this chapter.

\subsection{The Process Model}
In this model, all the runnable software on the computer, sometimes including the operating system, 
is organized into a number of \kw{sequential processes}, or just \kw{processes} for short.
A process is just an executing program, including the current values of the program counter, registers, and variables.
Conceptually, each process has its own virtual CPU.
In reality, of course, the real CPU switches back and forth from process to process,
but to understand the system, it is much easier to think about a collection of processes running in (pseudo) parallel,
than to try to keep track of how the CPU switches from program to program.
This rapid switching back and forth is called \kw{multiprogramming}, as we saw in Chap. 1.

In Fig. 2-1(a) we see a computer multiprogramming four programs in memory.
In Fig. 2-1(b) we see four processes, each with its own flow of control (i.e., its own program counter), 
and each one running independently of the other ones.
Of course, there is only one physical program counter, so when each process runs, 
its logical program counter is loaded in to the real program counter. 
When it is finished for the time being, the physical program counter is saved in the process' logical program counter in memory.
In Fig. 2-1(c) we see that viewed over a long enough time interval, all the processes have made progress,
but at any given instant only one process is actually running.

With the CPU switching back and forth among the process, the rate at which a process performs its computation will not be uniform, 
and probably not even reproducible if the same processes are run again.
Thus, processes must not be programmed with built-in assumptions about timing.
Consider, for example, an I/O process that starts a streamer tape to restore backed up files,
executes an idle loop 10,000 times to let it get up to speed, and then issues a command to read the first record.
If the CPU decides to switch to another process during the idle loop,
the tape process might not run again untill after the first record was already past the read head.
When a process has critical real-time requirements like this, that is, 
particular events must occur within a specified number of milliseconds, special measures must be taken to ensure that they do occur.
Normally, however, most processes are not affected by the underlying multiprogramming of the CPU or the relative speeds of different processes.

The difference between a process and a program is subtle, but crucial.
An analogy may help make this pointer cleaner.
Consider a culinary-mind computer scientist who is backing birthday cake for his daughter.
He has a birthday cake recipe and a kitchen well stocked with the necessary input:
flour, eggs, sugar, extract of vanilla, and so on.
In this analogy, the recipe is the program (i.e., an algorithm expressed in some suitable notation),
the computer scientist is the processor (CPU), and the cake ingredients are the input data.
The process is the activity consisting of our baker reading the recipe, fetching the ingredients, and baking the cake.
 
Now imagine that the computer scientist's son comes running in crying, saying that he has been stung by a bee.
The computer scientist records where he was in the recipe (the state of the current process is saved),
gets out a first aid book, and begins following the directions in it.
Here we see the processor being switched from one process (baking) to a higher priority process (administering medical care),
each having a different program (recipe vs. first aid book).
When the bee sting has been taken care of, the computer scientist goes back to his cake,
continuing the point where he left off.

The key idea here is that a process is an activity of some kind.
It has a program, input, output and a state.
A single processor may be shared among several processes, with some scheduling algorithm being used to determine
when to stop work on one process and service a different one.

\subsection{Process Creation}
Operating systems need some way to make sure all the necessary processes exist.
In very simple systems, or in systems designed for running only a single application (e.g., controlling a device in real time),
it may be possible to have all the processes that will ever be needed be present when the system comes up.
In general-purpose systems, however, some way is needed to create and terminate processes as needed during operation.
We will now look at some of the issues.

There are four principal events that cause processes to be created:
\begin{enumerate}
  \item System initialization.
  \item Execution of a process creation system call by running process.
  \item A user request to create a new process.
  \item Initiation of a batch job.
\end{enumerate}

When an operating system is booted, often several processes are created.
Some of these are foregroud process, that is, processes that interact with (human) user and perform work for them.
Others are backgroud processes, which are not associated with particular users, but instead have some special function.
For example, a backgroud process may be designed to accept incoming requests for web pages hosted on that machine,
waking up when a request arrives to service the request.
Processes that say in the backgroud to handle some activity such as web pages, printing, and so on are called \kw{daemons}.
Large systems commonly have dozens of them.
In MINIX 3, the \sys{ps} program can be used to list the running processes.

In addition to the processes created at boot time, new processes can be created afterwards as well.
Often a running process will issue system calls to create one or more new processes to help it do its job.
Creating new processes is particularly useful when the work to be done can easily be formulated in terms of several related,
but otherwise independent interacting processes.
For example, when compiling a large program, the \sys{make} program invokes the C compiler to convert source file to object code,
and then it invokes the \kw{install} program to copy the program to its destination, 
set ownership and permissions, etc.
In MINIX 3, the C compiler itself is actually several different programs, which work together.
These include a preprocessor, a C language parser, an assembly language code generator, an assembler, and a linker.

In interactive systems, users can start a program by typing a command.
In MINIX 3, virtual consoles allow a user to start a program, say a compiler, 
and then switch to an alternate console and start another program,
perhaps to edit documentation while the compiler is running.

The last situation in which processes are created applies only to the batch systems found on large mainframes.
Here users can submit batch jobs to the system (possibly remotely).
When the operating system decides that it has the resources to run another job,
it create a new process and runs the next job from the input queue in it.

Technically, in all these cases, a new process is created by having an existing process execute a process creation system call.
That process may be a running user process, 
a system process invoked from the keyboard or mouse,
or a batch manager process.
What that process does is execute a system call to create the new process.
This system call tells the operating system to create a new process and indicates, directly or indirectly,
which program to run in it.

In MINIX 3, there is only one system call to create a new process: \cmd{fork}.
This call creates an exact clone of the calling process.
After the \cmd{fork}, the two processes, the parent the child, have the same memory image, the same environment strings, and the same open files.
That is all there is.
Usually, the child process then executes \cmd{execve} or a similar system call to change its memory image and run a new program.
For example, when a user types a command, say, \sys{sort}, to the shell,
the shell forks off a child process and the child executes \sys{sort}.
The reason for this two-step process is to allow the child to manipulate its file descriptors after the \cmd{fork} 
but before the \cmd{execve} to accomplish redirection of standard input, standard output, and standard error.

In both MINIX 3 and UNIX, after a process is created both the parent and child have their own distinct address spaces.
If either process changes a word in its address space, the change is not visible to the other process.
The child's initial address space is a \sys{copy} of the parent's,
but there are two distinct address space involved; no writable memory is shared (like some UNIX implementations, 
MINIX 3 can share the program text between the two since that cannot be modified).
It is, however, possible for a newly created process to share some of its creator's other resources, such as open files.

\subsection{Process Termination}
After a process has been created, it starts running and does whatever its job is.
However, nothing lasts forever, not even processes.
Sooner or later the new process will terminate, usually due to one of the following conditions:
\begin{enumerate}
  \item Normal exit (voluntary).
  \item Error exit (voluntary).
  \item Fatal error (voluntary).
  \item Killed by another process (involuntary).
\end{enumerate}

Most processes terminate because they have done their work.
When a compiler has compiled the program given to it, 
the compiler executes a system call to tell the operating system that it is finished.
This call is \cmd{exit} in MINIX 3.
Screen-oriented programs also support voluntary termination.
For instance, editors always have a key combination that the user can invoke to tell the process to save the working file, 
remove any temporary files that are open and terminate.

The second reason for termination is that the process discovers a fatal error.
For example, if a user types the command\\
\cmd{cc foo.c}\\
to compile the program \sys{foo.c} and no such file exists, the compiler simply exits.

The third reason for termination is an error caused by the process, perhaps due to a program bug.
Examples include executing an illegal instruction, referencing nonexistent memory, or dividing by zero.
In MINIX 3, a process can tell the operating system that it wishes to handle certain errors itself,
in which case the process is signaled (interrupted) instead of terminated when one of the errors occurs.

The fourth reason a process might terminate is that one process executes a system call telling the operating system to kill some other process.
In MINIX 3, this call is \cmd{kill}.
Of course, the killer must have the necessary authorization to do in the killee.
In some system, when a process terminates, either voluntarily or otherwise,
all processes it created are immediately killed as well.
MINIX 3 does not work this way, however.

\subsection{Process Hierarchies}
In some systems, when a process creates another pprocess,
the parent and child continue to be associated in certain ways.
The child can itself create more process, forming a process hierarchy.
Unlike plants and animals that use sexual reproduction,
a process has only one parent (but zero, one, two, or more children).

In MINIX 3, a process, its children, and further descendants together may form a process group.
When a user sends a signal from the keyboard, the signal may be delivered to all members of the process group
associated with the keyboard (usaully all process that were created in the current window).
This is signal-dependent.
If a signal is sent to a group, each process can catch the signal, ignore the signal, or take the degault action,
which is to be killed by the signal.

As a simple example of how process trees are used, let us look at how MINIX initializes itself.
Two special processes, the \kw{reincarnation server} and \kw{init} are present in the boot image.
The reincarnation server's job is to (re)start drivers and servers.
It begins by blocking, waiting for a message telling it what to create.

In contrast, \sys{init} executes the \sys{/etc/rc} script that causes it to issue commands to the reincarnation server
to start the drivers and servers not present in the boot image.
This procedure make the drivers and servers so started children of the reincarnation server,
so if any of them ever terminate, the reincarnation server will be informed and can restart (i.e., reincarnation) them again.
This mechanism is intended to allow MINIX 3 to tolerate a driver or server crash because a new one will be started automatically.
In practice, replacing a driver is much easier than replacing a server, however,
since there fewer repercussions elsewhere in the system.
(And, we do not say this always work perfectly; it is still work in progress.)

When \sys{init} has finished this, it reads a configuration file \sys{/etc/ttytab} to see which terminals and virtual terminal exist.
\sys{Init} \cmd{fork}s a \sys{getty} process for each one, displays a login prompt on it, and then wait for input.
When a name is typed, \sys{getty} \cmd{exec}s a \sys{login} process with the name as its argument.
If the user succeeds in logging in, \sys{login} will \cmd{exec} the user's shell.
So the shell is a child of \sys{init}.
User commands create children of the shell, which are granchildren of \sys{init}.
This sequence of events is an example of how process trees are used.
As an aside, the code for the reincarnation server and \sys{init} is not listed in this book; neither is the shell.
The line had to be drawn somewhere.
But now you have the basic idea.

\subsection{Process Status}
Although each process is an independent entity, 
with its own program counter registers, stack, open files, alarms, and other internal state,
processes often need to interact, communicate, and synchronize with other processes.
One process may generate some output that another process uses as input, for example.
In the case, the data needs to be moved between processes.
In the shell command\\
\cmd{cat chapter1 chapter2 chapter3 | grep tree}\\
the first process, running \sys{cat}, concatenates and output three files.
The second process, running \sys{grep}, selects all lines containing the word ``tree''.
Depending on the relative speeds of the two processes (which depends on both 
the relative complexity of the programers and how much CPU time each one has had),
it may happen that \sys{grep} is ready to run, but there is no input waiting for it.
It must then \kw{block} until some input available.

When a process blocks, it does so because logically it cannot continue, 
typically because it is waiting for input that is not yet available.
It is also possible for a process that is conceptually ready and able to run to be stopped 
because the operating system has decided to allocate the CPU to another process for a while.
These two conditions are completely different.
In the first case, the suspension is inherent in the problem 
(you cannot process the user's command line until it has been typed).
In the second case, it is technicality of the system (not enough CPUs to give each process its own private processor).
In Fig. 2-2 we see a state digram showing the three states a process may be in:
\begin{enumerate}
  \item Running (actually using the CPU at that instant).
  \item Ready (runnable; temporarily stopped to let another process run).
  \item Blocked (unable to run until some external event happens).
\end{enumerate}

Logically, the first two states are similar.
In both cases the process is willing to run, only in the second one, there is temporarily no CPU available for it.
The third state is different from the first two in that the process cannot run, even if the CPU has nothing else to do.

Four transitions are possible among these three states, as shown.
Transition 1 occurs when a process discovers that it cannot continue.
In some systems the process must execute a system call, \cmd{block} or \cmd{pause} to get into blocked state.
In other systems, including MINIX 3, when a process reads from a pipe or special file (e.g., a terminal) and there is no input available,
the process is automatically moved from the running state to the block state.

Transition 2 and 3 are caused by the process schedular, a part of the operating-system,
without the process even knowing about them.
Transition 2 occurs when the scheduler decides that the running process has run long enough,
and it is time to let another process have some CPU time.
Transition 3 occurs when all the other processes have had their fair share 
and it is time for the first process to get the CPU to run again.
The subject of scheduling deciding which process should run when and for how long is an important one.
Many algorithms have been devised to try to 
balance the competing demands of efficiency for the system as a whole and fairness individual processes.
We will look at sheduling and study some of these algorithms later in this chapter.

Transition 4 occurs when the external event for which a process was waiting (e.g, the arrival of some input) happens.
If no other process is running then, transition 3 will be triggered immediately,
and the process will start running.
Otherwise it may have to wait in \sys{ready} state for a little while untill the CPU is available.

Using the process model, it becomes much easier to think about what is going on inside the system.
Some of the process run programs that carry out commands typed by a user.
Other processes are part of the system and handle tasks such as carrying out requests for file services 
or managing the details of running a disk or a tape drive.
When a disk interrupt occurs, the system may make a decision to stop running the current process and run the disk process,
which was blocked waiting for the interrupt.
We say ``may'' because it depends upon relative priorities of the running process and the disk driver process.
But the point is that instead of thinking about interrupts, we can think about user processes, disk processes, terminal processes, and so on,
which block when they are waiting for something to happen.
When the disk block has been read or the character typed, the process waiting for it is unblocked
and is eligible to run again.

This view gives rise to the model shown in Fig. 2-3.
Here the lowest level of the operating system is the scheduler, with a variety of processes on top of it.
All the interrupt handling and details of actually starting and stopping processes are hidden away in the scheduler,
which is actually quite small.
The rest of the operating system is nicely structured in process form.
The model of Fig. 2-3 is used in MINIX 3.
Of course, the ``scheduler'' is not the only thing in the lowest layer, 
there also support for interrupt handling and interprocess communication.
Neverthless, to a first approximation, it does show the basic structure.

\subsection{Implementation of Processes}
To implement the process model, the operating system maintains a table (an array of structures),
called the \kw{process table}, with one entry per process.
(Some authors call these entries \kw{process control blocks}.)
This entry contains information about the process' state, its program counter, stack pointer, memory allocation,
the state of its open files, its accounting and scheduling information, alarms and other signals,
and everything else about the process that must be saved when the process is switched from \sys{running} to \sys{ready} state 
so that it can be restarted later as if it had never been stopped.

In MINIX 3, interprocess communication, memory management, and file management are each handled by seperate modules within the system,
so the process table is partitioned, with each module maintaining the fields that it needs.
Fig. 2-4 shows some of the more important fields.
The fields in the first column are the only ones relevant to this chapter.
The other two columns are provided just to give an idea of what information is needed elsewhere in the system.

Now that we have looked at the process table,
it is possible to explain a little more about how the illusion of multiple sequential process is maintained 
on a machine with one CPU and many I/O devices.
What follows is technically a description of how the ``scheduler'' of Fig. 2-3 works in MINIX 3 
but most modern operating systems work essentially the same way.
Associated with each I/O device class (e.g., floppy disks, hard disks, timers, terminals) is a data structure in a table 
called the \kw{interrupt descriptor table}.
The most important part of each entry in this table is called the \kw{interrupt vector}.
It contains the address of the interrupt service procedure.
Suppose that user process 23 is running when a disk interrupt occurs.
The program counter, program status word, and possibly one or more registers are pushed onto the (current) stack by the interrupt hardware.
The computer then jumps to the address specified in the disk interrupt vector.
That is all the hardware does.
From here on, it is up to the software.

The interrupt service procedure starts out by saving all the registers in the process table entry for the current process.
The current process number and a pointer to its entry are kept in global variables so they can be found quickly.
Then the information deposited by the interrupt is removed from the stack, 
and the stack pointer is set to a temporary stack used by the process handler. 
Actions such as saving the registers and setting the stack pointer cannot even be expressed in high-level languages such as C,
so they are performed by a small assembly language routine.
When this routine is finished, it calls a C procedure to do the rest of the work for this specific interrupt type.

Interprocess communication in MINIX 3 is via message,
so the next step is to built a message to be sent to the disk process,
which will be blocked waiting for it.
The message says that an interrupt occured,
to distinguish it from messages from user processes requesting disk blocks to be read and things like that.
The state of the disk process is now changed from \sys{blocked} to \sys{ready} and scheduler is called.
In MINIX 3, different processes have different priorities, 
to give better service to I/O device handlers than to user processes, for example.
If the disk process is now the highest priority runnable process, it will be scheduled to run.
If the process that was interrupted is just as important or more so, 
then it will be scheduled to run again, and the disk process will have to wait a little while.

Either way, the C procedure called by the assembly language interrupt code now returns,
and the assembly language code loads up the registers and memory map for the now-current process and starts it running.
Interrupt handling and scheduling are summarized in Fig. 2-5.
It is worth nothing that the details vary slightly from system to system.

\subsection{Threads}
In traditional operating systems, each process has an address space and a single thread of control.
In fact, that almost the definition of a process.
Nevertheless, there are often situations in which it is desirable to 
have multiple threads of control in the same address space running in quasi-parallel,
as though they were seperate processes (except for the shared address space).
These threads of control are usually just called \kw{threads},
although some people call them \kw{lightweight processes}.

One way of looking at a process is that it is a way to group related resources together.
A process has an address space containing program text and data, as well as other resources.
These resources may include open files, child processes, pending alarms, signal handlers, accounting information, and more.
By putting them together in the form of a process, they can be managed more easily.

The other concept a process has is a thread of execution, usually shortened to just \kw{thread}.
The thread has a program counter that keeps track of which instruction to execute next.
It has registers, which hold its current working variables.
It has a stack, which contains the execution history, with one frame for each procedure called but not yet returned from.
Although a thread must execute in some process, the thread and its process are different concepts and can be treated seperately.
Processes are used to group resources together; threads are the entities scheduled for execution on the CPU.

What threads add to the process model is to allow multiple executions to take place in the same process environment,
to a large degree independent of one another.
In Fig. 2-6(a) we see three traditional processes.
Each process has its own address space and a single thread of control.
In contrast, in Fig. 2-6(b) we see a single process with three threads of control.
Although in both cases we have three threads, in Fig. 2-6(a) each of them operates in a different address space, 
whereas in Fig. 2-6(b) all three of them share the same address space.

As an example of where multiple threads might be used, consider a web browser process.
Many web pages contain multiple small images.
For each image on a web page, the browser must set up a separate connection to the pages's home site and request the image.
A great deal of time is spent establishng and releasing all these connections.
By having multiple threads within the browser, many images can be requested at the same time, 
greatly speeding up performance in most cases since with small images, 
the set-up time is the limiting factor, not the speed of the transmission line.

When multiple threads are present in the same address space, a few of the fields of Fig. 2-4 are not per process, but per thread,
so a separate thread table is needed, with one entry per thread.
Among the per-thread items are the program counter, registers, and state.
The program counter is needed because threads, like process, can be suspended and resumed.
The registers are needed because when threads are suspended, their registers must be saved.
Finally, threads, like processes, can be in \sys{running}, \sys{ready}, or \sys{blocked} state.
Fig. 2-7 lists some per-process and per-thread items.

In some systems, the operating system is not aware of the threads.
In other words, they are managed entirely in user space.
When a thread is about to block, for example, it chooses and starts its successor before stopping.
Several userlevel threads packages are in common use, including the POSIX \kw{P-threads} and Mach \kw{C-threads} packages.

In other operating systems, the operating system is aware of the existence of multiple threads per process,
so when a thread blocks, the operating system chooses the next one to run, either from the same process or a different one.
To do scheduling, the kernel must have a thread table that lists all the threads in the system,
anologous to the process table.

Although these two alternatives may seem equivalent, they differ considerably in performance.
Switching threads is much faster when thread management is done in user space than when a system call is needed.
This fact argues strongly doing thread management in user space.
On the other hand, when thread are managed entirely in user space and one thread blocks (e.g., waiting for I/O or a page fault to be handled),
the kernel blockes the entire process, since it is not even aware that other thread exist.
This fact as well as others argue for doing thread management in the kernel (Boehm, 2005).
As a consequence, both systems are in use, and various hybrid schemes have been proposed as well (Anderson et al., 1992).

No matter whether threads are managed by the kernel or in user space, they introduce a raft of problems
that must be solved and which change the programming model appreciably.
To start with, consider the effects of the \cmd{fork} system call.
If the parent process has multiple threads, should the child also have them?
If not, the process may not function properly, since all of them may be essential.

However, if the child process gets as many threads as the parent, 
what happens if thread was blocked on a \cmd{read} call, say, from the keyboard?
Are two threads now blocked on the keyboard?
When a line is typed, do both threads get a copy of it?
Only the parent?
Only the child?
The same problem exists with open network connections.

Another class of problems is related to the fact that threads share many data structures.
What happens if one thread closes a file while another one is still reading from it?
Suppose that one thread notices that there is too little memory and starts allocating more memory.
Then, part way through, a thread switch occurs, 
and the new thread also notices that there is too little memory and starts allocating more momery.
Does the allocation happen once or twice?
In nearly all systems that were not designed with threads in mind,
the libraries (such as the memory allocation procedure) are not reentrant,
and will crash if a second call is made while the first one still active.

Another problem relates to error reporting.
In UNIX, after a system call, the status of the call is put into a global variable, \sys{errno}.
What happens if a thread makes a system call, and before it is able to read \sys{errno},
another thread makes a system call, wiping out the original value?

Next, consider signals.
Some signals are logically thread specific; others are not.
For example, if a thread calls \sys{alarm}, it makes sense for the resulting signal to go to the thread that made the call.
When the kernel is aware of threads, it can usually make sure the right thread gets the signal.
When the kernel is not aware of threads, the threads package must keep track of alarms by itself.
An additional complication for user-level threads exists when (as in UNIX) a process may only have one alarm at a time pending
and several threads call \cmd{alarm} independently.

Other signals, such as a keyboard-initiated SIGINT, are not thread specific.
Who should catch them?
One designated thread?
All the threads?
A newly created thread?
Each of these solutions has problems.
Furthermore, what happens if one thread changes the signal handlers without telling other threads?

One last problem introduced by thread is stack management.
In many systems, when stack overflow occurs, the kernel just provides more stack, automatically.
When a process has multiple threads, it must also have multiple stacks.
If the kernel is not aware of all these stacks, it cannot grow them automatically upon stack fault.
In fact, it may not even realize that a memory fault is related to stack growth.
 
\section{Interprocess Communication}
Process frequently need to communicate with other processes.
For example, in a shell pipeline, the output of the first process must be passed to the second process, and so on down the line.
Thus there is a need for communication between processes, 
preferably in a well-structured way not using interrupts.
In the following sections we will look at some of the issues related to this \kw{InterProcess Communication} or \kw{IPC}.

There are three issues here.
The first was alluded to above:how one process can pass information to another.
The second has to do with making sure two or more processes do not get each other's way 
when engaging in critical activities (suppose two processes each try to grab the last 1 MB of memory).
The third concerns proper sequencing when dependencies are present: if process A produces data and process B print it, 
B has to wait until A has produced some data before starting to print.
We will examine all three of these of these issues in this section.

It is also important to mention that two of these issues apply equally well to threads.
The first one passing informations easy for threads since they share a common address space 
(threads in different address space that need to communication fall under the heading of communicating processes).
However, the other two keeping out of each other's hair and proper sequencing apply as well to threads.
The same problems exist and the same solutions apply.
Below we will discuss the problem in the context of processes,
but please keep in mind that the same problems and solutions also apply to threads.

\subsection{Race Conditions}
In some operating systems, processes that we are working together may share some common storage
that each one can read and write.
The shared storage may be in main memory (possibly in a kernel data structure) or it may be a shared file;
the location of the shared memory does not change the nature of the communication or the problems that arise.
To see how interprocess communication works in practice, let us consider a simple but common example, a print spooler.
When a process wants to print a file, it enters the file name in a special \kw{spooler directory}.
Another process, the \kw{printer daemon}, periodically checks to see if so are any files to be printed,
and if so removes their name from the directory.

Imagine that our spooler directory has a large number of slots, numberd 0, 1, 2, ..., 
each one capable of holding a file name.
Also imagine that there are two shared variables, 
\sys{out}, which points to the next file to be printed,
and \sys{in}, which points to the next free slot in the directory.
These two variables might well be kept in a two-word file available to all processes.
At a certain instant, slots 0 to 3 are empty (the files have already been printed) and slots 4 to 6 are full (with the names of files to be printed).
More or less simultaneously, process A and B decide they want to queue a file for printing.
This situation is shown in Fig. 2-8.

In jurisdictions where Murphy's law is applicable, the following might well happen.
Process A reads \sys{in} and store the value, 7, in a local variable called \sys{next\_free\_slot}.
Just then a clock interrupt occurs and the CPU decides that process A has run long enough, 
so it switches to process B.
Process B also reads \sys{in}, and also gets a 7, so it stores the name of its file in slot 7 and update \sys{in} to be an 8.
Then it goes off and does other things.

Eventually, process A runs again, starting from the place it left off last time.
It looks at \sys{next\_free\_slot}, find a 7 there, and write its file name in slot 7, erasing the name that process B just put there.
Then it computes \sys{next\_free\_slot} + 1, which is 8, and set \sys{in} to 8.
The spooler directory is now internally consistent, so the printer daemon will not notice anything wrong,
but process B will never receive any output.
User B will hang around the printer room for years, wistfully hoping for output that never comes.
Situations like this, where two or more processes are reading or writing some shared data 
and the final result depends on who runs precisely when, called \kw{race conditions}.
Debugging programs containning race conditions is no fun at all.
The results of most test runs are fine, but once in a blue moon something weird and unexplained happens.

\subsection{Critical Sections}
How do we avoid race conditions?
The key to preventing trouble here and in many other situations involving shared memory, shared files, and shared everything else 
is to find some way to prohibit more than one process from reading and writing the shared data at the same time.
Put in other words, what we need is \kw{mutual exclusion} some way of making sure that
if one process is using a shared variable or file, the other processes will be excluded from doing the same thing.
The difficulty above occurred because process B started using one of the shared variables before process A was finished with it.
The choice of approprite primitive operations for achieving mutual exclusion is a major design issue in any operating system,
and a subject that we will now examine in great detail.

The problem of avoiding race conditions can also be formulated in an abstract way.
Part of the time, a process is busy doing internal computations and other things that do not lead to race conditions.
However, sometimes a process may be accessing shared memory or files.
That part of the program where the shared memory is accessed is called the \kw{critical region} or \kw{critical section}.
If we could arrange matters such that no two processes were ever in their critical regions at the same time, we could avoid race conditions.

Although this requirement avoids race conditions, 
this is not sufficient for having parallel processes cooperate correctly and efficiently using shared data.
We need four conditions to hold to have a good solution:
\begin{enumerate}
  \item No two processes may be simultaneously inside their critical regions.
  \item No assumptions may be made about speeds or the number of CPUs.
  \item No process running outside its critical region may block other process.
  \item No process should have to wait forever to enter its critical region.
\end{enumerate}

The behavior that we wants is shown in Fig. 2-9.
Here process A enters its critical region at time \sys{T1}.
A little later, at time \sys{T2} process B attempts to enter its critical region but fails 
because another process is already in its critical region and we allow only one at a time.
Consequently, B is temporarily suspended until time \sys{T3} when A leaves its critical region, allowing B to enter immediately.
Eventually B leaves (at \sys{T4}) and we are back to the original situation with no processes in their critical regions.

\subsection{Mutual Exclusion with Busy Waiting}
In this section we will examine various proposals for achiving mutual exclusion,
so that while one process is busy updating shared memory in its critical region,
no other process will enter its critical region and cause trouble.
\subsubsection*{Disabling Interrupt}
The simplest solution is to have each process disable all interrupts just after entering its critical region 
reenable them just before leaving it.
With interrupts disabled, no clock interrupts can occur.
The CPU is only switched from process to process as a result of clock or other interrupts, after all,
and with interrupts turned off the CPU will not be switched to another process.
Thus, once a process has disabled interrupts, it can examine and update the shared memory without fear that any other process will intervence.

This approach is generally unattractive because it is unwise to give user processes the power to turn off interrupts.
Suppose that one of them did, and then never turned them on again?
That could be the end of the system.
Furthermore, if the system is a multiprocessor, with two or more CPUs, 
disabling interrupts affects only CPU that executed the disable instruction.
The other one will continue running and can access the shared memory.

On the other hand, it is frequently convenient for the kernel itself to disable interrupts 
for a few instructions while it is updating variables or lists.
If an interrupt occurred while the list of ready processes, for example, was in an inconsistent state, race conditions could occur.
The conclusion is: disabling interrupts is often a useful technique within the operating system itself
but is not appropriate as a general mutual exclusion mechanism for user processes.

\subsubsection*{Lock Variables}
As a second attempt, let us look for a software solution.
Consider having a single, shared, (lock) variable, initially 0.
When a process wants to enter its critical region, it first tests the lock.
If the lock is 0, the process sets it to 1 and enters the critical region.
If the lock is already 1, the process just waits until it becomes 0.
Thus, a 0 means that no process is in its critical region, and a 1 means that some process is in its critical region.

Unfortunately, this idea contains exactly the same fatal flaw that we saw in the spooler directory.
Suppose that one process reads the lock and sees that it is 0.
Before it can set the lock to 1, another process is scheduled, runs, and sets the lock to 1.
When the first process runs again, it will also set the lock to 1, and two processes will be in their critical regions at the same time.

Now you might think that we could get around this problem by first reading out the lock value,
then checking it again just before storing into it, but that really does not help.
The race now occurs if the second process modifies the lock just after the first process has finished its second check.

\subsubsection*{Strict Alternation}
A third approach to the mutual exclusion problem is shown in Fig. 2-10.
This program fragment, like most others in this book, is written in C.
C was chosen here because real operating systems are commonly written in C (or occasionally C++),
but hardly ever in languagees like Java.
C is powerful, efficient, and predictable, characteristics critical for writing operating systems.
Java, for example, is not predictable because it might run out of storage at a critical moment 
and need to invoke the garbage collector at a most inopportune time.
This cannot happen in C because there is no garbage collection in C.
A quantitative comparison of C, C++, Java, and four other languages is given by Prechelt (2000).

In fig. 2-10, the integer variable \sys{turn}, initially 0, keeps track of whose turn it is to enter the critical region
and examine or update the shared memory.
Initially, process 0 inspects \sys{turn}, finds it to be 0, and enters its critical region.
Process 1 also find it to be 0 and therefore sits in a tight loop continually testing \sys{turn} to see when it becomes 1.
Continuously testing a variable until some value appears is called \kw{busy waiting}.
It should usually be avoided, since it wastes CPU time.
Only when there is a reasonable expectation that the wait will be short is busy waiting used.
A lock that uses busy waiting is called a \kw{spin lock}.

When process 0 leaves the critical region, it sets \sys{turn} to 1, to allow process 1 to enter its critical region.
Suppose that process 1 finishes its critical region quickly, so both processes are in their noncritical regions,
with \sys{turn} set to 0.
Now process 0 executes its whole loop quickly, exiting its critical region and setting \sys{turn} to 1.
At this point \sys{turn} is 1 and both processes are executing in their noncritical regions.

Suddenly, process 0 finishes its noncritical region and goes back to the top of its loop.
Unfortunately, it is not permitted to enter its critical region now, 
because \sys{turn} is 1 and process 1 is busy with its noncritical region.
It hangs in its \cmd{while} loop until process 1 sets \sys{turn} to 0.
Put differently, taking turns is not a good idea when one of the processes is much slower than the other.

This situation violates condition 3 set about above: 
process 0 is being blocked by a process not in its critical region.
Going back to the spooler directory discussed above,
if we now associate the critical region with reading and writing the spooler directory, 
process 0 would not be allowed to print another file because process 1 was doing something else.

In fact, this solution requires that the two processes strictly alternate in entering their critical regions,
for example, in spooling files.
Neither one would be permitted to spool two in a row.
While this algorithm does avoid all races, it is not really a serious candidate as a solution 
because it violates condition 3.

\subsubsection*{Peterson's Solution}
By combining the idea of taking turns with the idea of lock variables and warning variables,
a Dutch mathematician, T. Dekker, was the first one to devise a software solution to the mutual exclusion problem
that does not require strict alternation.
In 1981, G.l. Peterson discovered a much simpler way to achieve mutual exclusion, 
thus rendering Dekker's solution obsolete.
Peterson's algorithm is shown in Fig. 2-11.
This algorithm consists of two procedure written in ANSI C, 
which means that function prototypes should be supplied for all the functions defined and used.
However, to save space, we will not show the prototype in this or subsequent example.

Before using the shared variables (i.e., before entering its critical region),
each process calls \sys{enter\_region} with its own process number, 0 or 1, as the parameter.
This call will cause it to wait, if need be, until it is safe to enter.
After it has finished with the shared variables, the process calls \sys{leave\_region} to indicate that it is done 
and to allow the other process to enter, if so desires.

Let us see how this solution works.
Initially, neither process is in its critical region.
Now process 0 calls \sys{enter\_region}.
It indicates its interest by setting its array element and set \sys{turn} to 0.
Since 1 is not interested, \sys{enter\_region} returns immediately.
If process 1 now calls \sys{enter\_region}, it will hang there until \sys{intersted[0]} goes to FALSE, 
and event that only happens when process 0 calls \sys{leave\_region} to exit the critical region.

Now consider the case that both processes call \sys{enter\_region} almost simuteneously.
Both will store their process number in \sys{turn}.
Whichever store is done last is the one that counts; the first one is lost.
Suppose that process 1 stores last, so \sys{turn} is 1.
When both processes come to the \cmd{while} statement, process 0 executes it zero times and enters its critical region.
Process 1 loops and does not enter its critical region.

\subsubsection*{The TSL Instruction}
Now that let us look at a proposal that requires a little help from the hardware.
many computers, especially those designed with multiple processors in mind, have an instruction\\
\cmd{TSL RX, LOCK}\\
(Test and Set Lock) that works as follows: 
it reads the contents of the memory word \sys{LOCK} into register \cmd{RX} 
and then stores a nonzero value at the memory address \sys{LOCK}.
The operations of reading the word and storing into it are guaranteed to be indivisible
no other processor can access the memory word until the instruction is finished.
The CPU executing the \cmd{TSL} instruction locks the memory bus to prohibit other CPUs from accessing memory until it is done.
 
To use the \cmd{TSL} instruction, we will use a shared variable, \sys{lock}, to coordinate access to shared memory.
When \sys{LOCK} is 0, any process may set it to 1 using the \cmd{TSL} instruction and then read or write the shared memory.
When it is done, the process sets \sys{LOCK} back to 0 using an ordinary \cmd{move} instruction.

How can this instruction be used to prevent two process from simultaneously entering their critical region?
The solution is given in Fig. 2-12.
There a four-instruction subroutine in a fictitious (but typical) assembly language is shown.
The first instruction copies the old value of \sys{LOCK} to the register and then sets \sys{lock} to 1.
Then the old value is compared with 0.
If it is nonzero, the lock was already set, so the program just goes back to the beginning and tests it again.
Sooner or later it will become 0 (when the process currently in its critical region is done with its critical region),
and the subroutine returns, with the lock set.
Clearning the lock is simple.
The program just stores a 0 in \sys{LOCK}.
No special instruction are needed.

One solution to the critical region problem is now straitforward.
Before entering its critical region, a process calls \sys{enter\_region}, which does busy waiting until the lock is free;
then it acquires the lock and returns.
After the critical region the process calls \sys{leave\_region}, which stores a 0 in \sys{LOCK}.
As with all solutions based on critical regions, the processes must call \sys{enter\_region} and \sys{leave\_region} 
at the correct times for the method to work.
If a process cheats, the mutual exclusion will fail.

\subsection{Sleep and Wakeup}
Both Peterson's solution and the solution using \cmd{TSL} are correct, but both have the defect of requiring busy waiting.
In essence, what these solutions do is this: when a process wants to enter its critical region, 
it checks to see if the entry is allowed.
If it is not, the process just sits in a tight loop waiting until it is.

Not only does this approach waste CPU time, but it can also have unexpected effects.
Consider a computer with two processes, H, with high priority and L, with low priority, which share a critical region.
The scheduling rules are such that H is run whenever it is in ready state.
At a certain moment, with L in its critical region, H becomes ready to run (e.g., an I/O operation completes).
H now begins busy waiting, but since L is never scheduled while H is running, 
L never gets the chance to leave its critical region, so H loops forever.
This situation is sometimes referred to as the \kw{priority inversion problem}.

Now let us look at some interprocess communication primitives that lock instead of wasting CPU time 
when they are not allowed to enter their critical region.
One of the simplest is the pair \cmd{sleep} and \cmd{wakeup}.
\cmd{sleep} is a system call that cause the caller to block, that is, be suspended until another process wakes it up.
The \cmd{wakeup} call has one parameter, the process to be awakened.
Alternatively, both \cmd{sleep} and \cmd{wakeup} each have one parameter, 
a memory address used to match up \cmd{sleep}s with \cmd{wakeup}s.

\subsubsection*{The Producer-Consumer Problem}
As an example of how these primitives can be used in practice,
let us consider the \kw{producer-consumer} problem (also known as the \kw{bounded buffer} problem).
Two processes share a common, fixed-size buffer.
One of them, the producer, puts information into the buffer, and the other one, the consumer, takes it out.
(It is also possible to generalize the problem to have \sys{m} producers and \sys{n} consumers, 
but we will only consider the case of one producer and one consumer because this assumption simplifies the solutions.)

Trouble arises when the producer wants to put a new item in the buffer, but it is already full.
The solution is for the producer to go to sleep, to be awakened when the consumer has removed one or more items.
Similarly, if the consumer wants to remove an item from the buffer and sees that the buffer is empty,
it goes sleep until the producer puts something in the buffer and wakes it up.

This approach sounds simple enough, but it leads to the same kinds of race conditions we saw earlier with the spooler directory.
To keep track of the number of items in the buffer, we will need a variable, \sys{count}.
If the maximum number of items the buffer can hold is N, the producer's code will first test to see if \sys{count} is N. 
If it is, the producer will go to sleep; if it is not, the producer will add an item and increment \sys{count}.

The consumer's code is similar: first test \sys{count} to see if it is 0.
If it is, go to sleep; if it is nonzero, remove an item and decrement the counter.
Each of the processes also tests to see if the other should be sleeping, and if not, wakes it up.
The code for both producer and consumer is shown in Fig. 2-13.

To express system calls such as \cmd{sleep} and \cmd{wakeup} in C, we will show them as calls to library routines.
They are not part of the standard C library but presumably would be available on any system that actually had these system calls.
The procedures \sys{enter\_item} and \sys{remove\_item}, which are not shown,
handle the bookkeeping of putting items into the buffer and taking items out of the buffer.

Now let us get back to the trace condition.
It can occur because access to \sys{count} is unconstrained.
The following situation could possibly occur.
The buffer is empty and the consumer has just read \sys{count} to see if it is 0.
At that instant, the scheduler decides to stop running the consumer temporarily and start running the producer.
The producer enters an item in the buffer, increments \sys{count}, and notice that it is now 1.
Reasoning that \sys{count} was just 0, and thus the consumer must be sleeping, 
the producer calls \sys{wakeup} to wake the consumer up.

Unfortunately, the consumer is not yet logically asleep, so the wakeup signal is lost.
When the consumer next runs, it will test the value of \sys{count} it previously read, find it to be 0, and go to sleep forever.

The essence of the problem here is that a wakeup sent to a process that not (yet) sleeping is lost.
If it were not lost, everything would work.
A quick fix is to modify the rules to add a \kw{wakeup waiting bit} to the picture.
When a wakeup is sent to a process that is still awake, this bit is set.
Later, when the process tries to go to sleep, if the wakeup waiting bit is on, it will be turned off,
but the process will stay awake.
The wakeup waiting bit is a piggy bank for wakeup signals.


While the wakeup waiting bit saves the day in this simple example, 
it is easy to construct examples with three or more processes in which one wakeup waiting bit is insufficient.
We could make another patch, and add a second wakeup waiting bit, or maybe 8 or 32 of them, but in principle the problem is still there.

\subsection{Semaphores}
This was the situation until E. W. Dijkstra (1965) suggested using an integer variable to count the number of wakeups saved for future use.
In his proposal, a new variable type, called a \kw{semaphore}, was introduced.
A semaphore could have the value 0, indicating that no wakeups were saves, 
or some positive value if one or more wakeups were pending.

Dijkstra proposed having two operations, \cmd{down} and \cmd{up} 
(which are generalization of \cmd{sleep} and \cmd{wakeup}, respectively).
The \cmd{down} operation on a semaphore checks to see if the value is greater than 0.
If so, it decrements the value (i.e., uses up one stored wakeup) and just continues.
If the value is 0, the process is put to sleep without completing the \cmd{down} for the moment.
Checking the value, changing it, and possibly going  to sleep is all done as a single, indivisible, \kw{atomic action}.
It is guaranteed that once a semaphore operation has started, 
no other process can access the semaphore untill the operation has completed or blocked.
This atomicity is absolutely essential to solving synchronization problems and avoiding race condition.

The \cmd{up} operation increments the value of the semaphore addresses.
If one or more processes were sleeping on that semaphore, unable to complete an earlier \cmd{down} operation,
one of them is chosen by the system (e.g., at random) and is allowed to complete its \cmd{down}.
Thus, after an \cmd{up} on a semaphore with processes sleeping on it, the semaphore will still be 0,
but there will be one fewer process sleeping on it.
The operation of incrementing the semaphore and waking up one process is also indivisible.
No process ever blocks doing an \cmd{up}, just as no process ever blocks doing a \cmd{wakeup} in the earlier model.

As an aside, in Dijkstra's original paper, he used the names \cmd{p} and \cmd{v} instead of \cmd{down} and \cmd{up},
respectively, but since these have no mnemonic significance to people who do not speak Dutch (and only marginal significance to those who do),
we will use the terms \cmd{down} and \cmd{up} instead.

\subsubsection*{Solving the Producer-Consumer Problem using Semaphores}
Semaphores solve the lost-wakeup problem, as shown in Fig. 2-14.
It is essential that they be implemented in an indivisible way.
The normal way is to implement \cmd{up} and \cmd{down} as system calls,
with the operating system briefly disbling all interrupts while it is testing the semaphore,
updating it, and putting the process to sleep, if necessary.
As all of these actions take only a few instructions, no harm is done in disabling interrupts.
If multiple CPUs are being used, each semaphore should be protected by a lock variable, 
with the \cmd{TSL} instruction used to make sure that only one CPU at a time examines the semaphore.
But sure you understand that using \cmd{TSL} to prevent several CPUs from accessing the semaphore at the same time 
is quite different from busy waiting by the producer or consumer waiting for the other to empty or fill the buffer.
The semaphore operation will only take a few microseconds, whereas the producer or consumer might take arbitrarily long.

This solution uses three semaphores: 
one called \sys{full} for counting the number of slots that are full,
one called \sys{empty} for counting the number of slots that are empty,
and one called \sys{mutex} to make sure the producer and consumer do not access the buffer at the same time.
\sys{Full} is initially 0, \sys{empty} is initially equal to the number of slots in the buffer,
and \sys{mutex} is initially 1.
Semaphores that are initialized to 1 and used by two or more processes to ensure that 
only one of them can enter its critical region at the same time are called \kw{binary semaphores}.
If each process does a \cmd{down} just before entering its critical region and an \cmd{up} just after leaving it, mutual exlusion is guaranteed.

Now that we have a good interprocess communication primitive at our disposal, 
let us go back and look at the interrupt sequence of Fig. 2-5 again. 
In a system-using semaphores, the natural way to hide interrupts is to have a semaphore, 
initially set to 0, associated with each I/O device.
Just starting an I/O device, the managing process does a \cmd{down} on the associated semaphore, thus blocking immediately.
When the interrupt comes in, the interrupt handler then does an \cmd{up} on the associated semaphore,
which makes the relevant process ready to run again.
In this model, step 6 in Fig. 2-5 consists of doing an \cmd{up} on the device's semaphore,
so that in step 7 the scheduler will be able to run the device manager.
Of course, if several processes are now ready, the scheduler may choose to run an even more important process next.
We will look at how scheduling is done later in this chapter.

In the example of Fig. 2-14, we have actually used semaphores in two different ways.
This difference is important enough to make explicit.
The \sys{mutex} semaphore is used for mutual exlusion.
It is designed to guarantee that only one process at a time will be reading or writing the buffer and the associated variables.
This mutual exlusion is required to prevent chaos.
We will study mutual exclusion and how to achive it more in the next section.

The other use of semaphore is for \kw{synchronization}.
The \sys{full} and \sys{empty} semaphores are needed to guarantee that certain event sequences do or do not occur.
In this case, they ensure that the producer stops running when the buffer is full, and the consumer stops running when it is empty.
This use is differnt from mutual exclusion.

\subsection{Mutexes}
When the semaphore's ability to count is not needed, a simplified version of the semaphore, called mutex, is sometimes used.
Mutexes are good only for managing mutual exclusion to some shared resources or piece of code.
They are easy and efficient to implement, which makes them especially useful in thread packages that are implemented entirely in user space.

A \kw{mutex} is a variable that can be in one of two states: unlocked or locked.
Consequently, only 1 bit is required to represent it, but in practice an integer often is used, 
with 0 meaning unlocked and all other values meaning locked.
Two procedures are used with mutexes.
When a process (or thread) needs access to a critical region, it calls \sys{mutex\_lock}.
if the mutex is currently unlocked (meaning that the critical region is available),
the call succeeds and the calling thread is free to enter the critical region.

On the other hand, if the mutex is already locked, the caller is blocked until the process in the critical region is finished 
and calls \sys{mutex\_unclock}.
If multiple processes are blocked on the mutex, one of them is chosen at random and allowed to acquire the lock.

\subsection{Monitors}
With semaphores interprocess communication looks easy, right? Forget it.
Look closely at the order of the \cmd{down}s before entering or removing items from the buffer in Fig. 2-14.
Suppose that the two \cmd{down}s in the producer's code were reversed in order, 
so \sys{mutex} was decremented before \sys{empty} instead after it.
If the buffer were completely full, the producer would block, with \sys{mutex} set to 0.
Consequently, the next time the consumer tried to access the buffer, it would do a \cmd{down} on \sys{mutex}, and block too.
Both processes would stay blocked forever and no more work would ever be done.
This unfortunate situation is called a \kw{deadlock}.
we will study deadlocks in detail in Chap. 3.

This problem is pointed out to show how careful you must be when using semaphores.
One subtle error and everything comes to a gringding halt.
It is like programming in assembly language, only worse, 
because the errors are race conditions, deadlocks, and other forms of unpredictable and irreproducible behavior.

To make it easier to write correct programs, Brinch Hansen (1973) and Hoare (1974) 
proposed a higher level synchronization primitive called a \kw{monitor}.
Their proposals differed slightly, as described below.
A monitor is a collection of procedures, variables, and data structures 
that are all grouped together in a special kind of module or package.
Processes may call the procedures in a monitor whenever they want to,
but they cannot directly access the monitor's internal data structures from procedures declared outside the monitor.
This rule, which is common in modern object-oriented languages such as Java, was relatively unusual for its time,
although objects can be tracked back to Simula 67.
Fig. 2-15 illustrates a monitor written in an imaginary language, Pidgin Pascal.

Monitors have a key property that makes them useful for achieving mutual exclusion: 
only one process can be active in a monitor at any instant.
Monitors are a programming labguage construct, so the compiler knows they are special 
and can handle calls to monitor procedures differently from other procedure calls.
Typically, when a process calls a monitor procedure, 
the first few instructions of the procedure will check to see if any other process has left the monitor.
If no other process is using the monitor, the calling process may enter.

It is up to the compiler to implement the mutual exlusion on monitor entries,
but a common way is to use a mutex or binary semaphore.
Because the compiler, not the programmer, arranges for the mutual exclusion, it is much less likely that something will go wrong.
In any event, the person writing the monitor does not have to be aware of how the compiler aranges for mutual exclusion.
It is sufficient to know that by turning all the critical regions into monitor procedures, 
no two processes will ever execute their critical regions at the same time.

Although monitors provide an easy way to achieve mutual exlusion, as we have seen above, that is not enough.
We also need a way for processes to block when they cannot proceed.
In the producer-consumer problem, it is easy enough to put all the tests for buffer-full and buffer-empty in monitor procedures,
but how should the procedure block when it finds the buffer full?

The solution lies in the introduction of \kw{condition variables}, among with two operations on them, \cmd{wait} and \cmd{signal}.
When a monitor procedure discovers that it cannot continue (e.g., the procedure find the buffer full),
it does a \cmd{wait} on some condition variablle, say, \sys{full}.
This action causes the calling process to block.
It also allows another process that had been previously prohibited from entering the monitor to enter now.

The other process, for example, the consumer, can wake up its sleeping partner - 
by doing a \cmd{signal} on the condition variable that its patner is waiting on.
To avoid having two active processes in the monitor at the same time, we need a rule telling what happens after a \cmd{signal}.
Hoare proposed letting the newly awakened process run, suspending the other one.
Brinch Hansen proposed finessing the problem by requiring that a process doing a \cmd{signal} must exit the monitor immediately.
In other words, a \cmd{signal} statement may appear only as the final statement in a monitor procedure.
We will use Brinch Hansen's proposal because it is conceptually simpler and also easier to implement.
If a \cmd{signal} is done on a condition variable on which several processes are waiting, 
only one of them, determined by the system scheduler, is revived.

There is also a third solution, not proposed by either Hoare or Brinch Hansen.
This is to let the signaler continue to run and allow the waiting process to start running only after the signaler has exited the monitor.

Condition variables are not counters.
They do not accumulate signals for later use the way semaphores do.
Thus if a condition variable is signaled with no one waiting on it, the signal is lost.
In other words, the \cmd{wait} must come before the \cmd{signal}.
This rule makes the implementation much simpler.
In practice it is not a problem because it is easy to keep track of the state of each process with variables, if need be.
A process that might otherwise do a \cmd{signal} can see that this operation is not necessary by looking at the variables.

A skeleton of the producer-consumer problem with monitors is given in Fig. 2-16 in Pidgin Pascal.
The advantage of using Pidgin Pascal here is that it is pure and simple 
and follow Hoare/Brinch Hansen model exactly.

You may be thinking that the operations \cmd{wait} and \cmd{signal} look similar to \cmd{sleep} and \cmd{wakeup},
which we saw earlier had fatal race conditions.
They are very similar, but with one crucial difference:
\cmd{sleep} and \cmd{wakeup} failed because while one process was trying to go sleep, the other one was trying to wake it up.
With monitors, that cannot happen.
The automatic mutual exclusion on monitor procedures guarantee that if, say, 
the producer inside a monitor procedure discovers that the buffer is full, 
it will be able to complete the \cmd{wait} operation without having to worry about the possibility 
that the scheduler may switch to the consumer just before the \cmd{wait} completes.
The consumer will not even be let into the monitor at all untill the \cmd{wait} is finished 
and the producer is marked as no longer runnable.

Although Pidgin Pascal is an imaginary language, some real programming languages also support monitors,
although not always in the form designed by Hoare and Brinch Hansen.
One such language is Java.
Java is an object-oriented language that supports user-level threads and also allows methods (procedures) to be grouped together into classes.
By adding the keyword \cmd{synchronized} to a method declaration,
Java guarantees that once any thread has started executing that method,
no other thread will be allowd to start executing any other \cmd{synchronized} method in that class.

Synchronized methods in Java differ from classical monitors in an essential way:
Java does not have condition variables.
Instead, it offers two procedures, \sys{wait} and \sys{notify} that are the equivalent of \sys{sleep} and \sys{wakeup} except
that when are used inside synchronized methods, they are not subject to race condition.

By making the mutual exlusion of critical regions automatic,
monitors make parallel programming much less error-prone than with semaphores.
Still, they too have some drawbacks.
It is not for nothing that Fig. 2-16 is written in Pidgin Pascal rather than in C,
as are the other examples in this book.
As we said earlier, monitors are a programming language concept.
The compiler must recognize them and arrange for the mutual exclusion somehow.
C, Pascal, and most other languages do not have monitors,
so it is unreasonable to expect their compilers to enforece any mutual exclusion rules.
In fact, how could the compiler even known which procedures were in monitors and which were not?

These same languages do not have semaphores either, but adding semaphores is easy:
all you need to do is add two short assembly code routines to the library to issue the \cmd{up} and \cmd{down} system calls.
The compiler do not even have to know that they exist.
Of course, the operating systems have to know about the semaphores, 
but at least if you have a semaphore-based operating system,
you can still write the user programs for it in C or C++ (or even FORTRAN if you are masochistic enough).
With monitors, you need a language that has them built in.

Another problem with monitors, and also with semaphores, 
is that they were designed for solving the mutual exclusion problem on one or more CPUs that all have access to a common memory.
By putting the semaphores in the shared memory and protecting them with \cmd{TSL} instructions,
we can avoid races.
When we go to a distributed system consisting of mutiple CPUs, 
each with its own private memory, connected by a local area network, these primitives become inapplicable.
The conclusion is that semaphores are too low level and monitors are not usable except in a few programming languages.
Also, none of the primitives provide for information exchange between machines.
Something else is needed.

\subsection{Message Passing}
That something else is \kw{message passing}.
This method of interprocess communication uses two primitives, \cmd{send} and \cmd{receive},
which, like semaphores and unlike monitors, are system calls rather than language constructs.
As such, they can easily be put into library procedures, such as\\
\cmd{send (destination, \&message);}\\
and\\
\cmd{receive(source, \&message);}

The former call sends a message to a given destination and the latter one receives a message from a given source
(or from \sys{ANY}, if the receiver does not care.)
If no message is available, the receiver could block until one arrives.
Alternatively, it could return immediately with an error code.

\subsubsection*{Design Issues for Message Passing System}
Message passing system have many challenging problems and design issues that do not arise with semaphores or monitors,
especially if the communicating processes are on different machines connected by anetwork.
For example, message can be lost by the network.
To guard against lost messages, the sender and receiver can agree that as soon as message has been received, 
the receiver will send back a special \kw{acknowledgement} message.
If the sender has not received the acknowledgement within a certain time interval, it retransmits the message.

Now consider what happens if the message itself is received correctly, but the acknowledgement is lost.
The sender will retransmit the message, so the receiver will get it twice.
It is essential that the receiver can distinguish a new message from the retransmission of an old one.
Usually, this problem is solved by putting consecutive sequence numbers in each original message.
If the receiver gets a message bearing the same sequence number as the previous message,
it knows that the message is a duplicate that can be ignored.

Message systems also have to deal with the question of how processes are named,
so that the process specified in a \cmd{send} or \cmd{receive} call is unambiguous.
\kw{Authentication} is also an issue in message systems:
how can the client tell that he is communicating with the real file sever, and not with an imposter?

As the other end of the spectrum, there are also design issues that are important when the sender and receiver are on the same machine.
One of these is performance.
Copying messages from one process to another is always slower than doing a semaphore operation or entering a monitor.
Much work has gone into making message passing efficient.
Cheriton (1984), for example, has suggested limiting message size to what will fit in the machine's registers,
and then doing message passing using the registers.

\subsubsection*{The Producer-Consumer Problem with Message Passing}
Now let us see how the producer-consumer problem can be solved with message passing and no shared memory.
A solution is given in Fig. 2-17.
We assume that all messages are the same size and that messages sent but not yet received are buffered automatically by the operating system.
In this solution, a total of N message is used, analogous to the N slots in a shared memory buffer.
The consumer starts out by sending N empty messages to the producer.
Whenever the producer has an item to give to the consumer, it takes an empty message and sends back a full one.
In this way, the total number of messages in the system remains constant in time, 
so they can be stored in a given amount of memory known in advance.

If the producer works faster than the consumer, all the messages will end up full, waiting for the consumer;
the producer will be blocked, waiting for an empty to come back.
If the consumer works faster, then the reverse happens;
all the messages will be empties waiting for the producer to fill them up; the consumer will be blocked, waiting for a full message.

Many variants are possible with message passing.
For starters, let us look at how messages are addresses.
One way is to assign each process a unique address and have messages be addressed to processes.
A different way is to invent a new structure, called a \cmd{mailbox}.
A mailbox is a place to buffer a certain number of messages, typically specified when the mailbox is created.
When the mailboxes are used, the address parameters in the \cmd{send} and \cmd{receive} calls are mailboxes, not processes.
When a process tries to send to a mailbox that is full, 
it is suspended until a message is removed from that mailbox, making room for a new one.

For the producer-consumer problem, both the producer and consumer would create mailboxes large enough to hold N messages.
The producer would send messages containing data to the consumer's mailbox, 
and the consumer would send empty messages containing data to the consumer's mailbox.
When mailboxes are used, the buffering mechanism is clear:
the destination mailbox holds messages that have sent to the destination process but have not yet been accepted.

The other extreme from having mailboxes is to eliminate a buffering.
When this approach is followed, 
if the \cmd{send} is done before the \cmd{receive}, the sending process is blocked until the \cmd{receive} happens,
at which time the message can be copied directly from the sender to the receiver, with no intermediate buffering.
Similarly, if the \cmd{receive} is done first, the receiver is blocked until a \cmd{send} happens.
This strategy is often known as \kw{rendezvous}.
It is easy to implement than a buffered message scheme but is less flexible since the sender and receiver are forced to run in lockstep.

The processes that make up the MINIX 3 operating system itself use the rendezvous methods 
with fixed size messages for communication among themselves.
User processes also use this method to communicate with operating system components,
although a programmer does not see this, since library routine mediate systems calls.
Interprocess communication between user processes in MINIX 3 (and UNIX) is via pipes, which are effectively mailboxes.
The only real difference between a message system with mailboxes and the pipe mechanism is that
pipes do not preserve message boundaries.
In other words, if one process write 10 messages of 100 bytes to a pipe and another process reads 1000 bytes from the pipe,
the reader will get all 10 messages at once.
With a true message system, each \cmd{read} should return only one message.
Of course, if the processes agree always to read and write fixed-size messages from the pipe, 
or to end each message with a special character (e.g., linefeed), no problems arise.

Message passing is commonly used in parallel programming systems.
One well-known message-passing system, for example, is \kw{MPI(Message-Passing Interface)}.
It is widely used for scientific computing.
For more information about it, see for example Gropp et al. (1994) and Snir et al. (1996). 

\section{Classical IPC Problems}
The operating systems literature is full of interprocess communication problems 
that have been widely discussed using a variety of synchronization methods.
In the following sections we will examine two of the better-known problems.

\subsection{The Dining Philosophers Problem}
In 1965, Dijkstra posed and solved a synchronization problem he called the \kw{dining philosophers problem}.
Since that time, everyone inventing yet another synchronization primitive has felt obligated to 
demonstrate how wonderful the new primitive is by showing how elegantly it solves the dining philosophers problem.
The problem can be stated quite simply as follows.
Five philosophers are seated around a circular table.
Each philosopher has a plate of spaghetti.
The spaghetti is so slippery that a philosopher needs two forks to eat it.
Between each pair of plates is one fork.
The layout of the table is illustrated in Fig. 2-18.

The life of a philosopher consists of alternate periods of eating and thinking.
(This is something of an abstraction, even for philosophers, but the other activities are irrelevant here.)
When a philosopher gets hungry, she tries to acquire her left and right fork, one at a time, in either order.
If successful in acquiring two forks, she eats for a while, then puts down the forks and continues to think.
The key question is: can you write a program for each philosopher that does what it is supposed to do and never gets stuck?
(It has been pointed out that the two-fork requirement is somewhat artificial; 
perhaps we should switch from Italian to Chinese food, substituting rice for spaghetti and chopsticks for forks.)

Fig. 2-19 shows the obvious solution.
The procedure \sys{take\_fork} waits until the specified fork is available and then seizes it.
Unfortunately, the obvious solution is wrong.
Suppose that all five philosophers take their left forks simutaneously.
None will be able to take their right forks, and there will be a deadlock.

We could modify the program so that after taking the left fork, the program checks to see if the right fork is available.
If it is not, the philosopher puts down the left one, waits for some time, and then repeats the whole process.
This proposal too, fails, although for a different reason.
With a little bit of bad luck, all the philosophers could start the algorithm simultaneously, 
picking up their left forks, seeing that their right forks were not available, putting down their left forks, waiting, 
picking up their left forks again simultaneously, and so on, forever.
A situation like this, in which all the programs continue to run indefinitely but fail to make any process is called \kw{starvation}.
(It is called starvation even when the problem does not occur in an Italian or a Chinese restaurant.)

Now you might think,``if the philosophers would just wait a random time instead of the same time after failing to acquire the right-hand fork,
the chance that everything would continue in lockstep for even an hour is very small."
This observation is true, and in nearly all applications trying again later is not a problem.
For example, in a local area network using Ethernet, a computer sends a packet only when it detects no other computer is sending one.
However, because of transmission delays, two computers separated by a length of cable may send packets overlap a collision. 
When a collision of packets is detected each computer waits a random time and tries again;
in practice this solution works fine.
However, in some applications one would prefer a solution that always works and cannot fail due to an unlikely series of random numbers.
Think about safety control in a nuclear power plant.

One improvement to Fig. 2-19 that has no deadlock and no starvation is to 
protect the five statements following the call to \sys{think} by a binary semaphore.
Before starting to acquire forks, a philosopher would do a \cmd{down} on \sys{mutex}.
After replacing the forks, she would do an \cmd{up} on \sys{mutex}.
From a theoretical viewpoint, this solution is adequate.
From a practical one, it has a performance bug: only one philosopher can be eating at any instant.
With five forks available, we should be able to allow two philosophers to eat at the same time.

The solution presented in Fig. 2-20 is deadlock-free and allows the maximum parallelism for an arbitrary nuber of philosophers.
It uses an array, \sys{state}, to keep track of whether a philosopher is eating, thinking, or hungry (trying to acquire forks).
A philosopher may move into eating state only if neither neighbor is eating.
Philosopher \sys{i}'s neighbors are defined by the macros \sys{LEFT} and \sys{RIGHT}.
In other words, if \sys{i} is 2, \sys{LEFT} is 1 and \sys{RIGHT} is 3.

The program uses an array of semaphores, one per philosopher, so hungry philosophers can block if the needed forks are busy.
Note that each process runs the procedure \sys{phylosopher} as its main code, 
but the other procedures, \sys{take\_forks}, \sys{put\_forks}, and \sys{test} are ordinary procedures and not separate processes.

\subsection{The Readers and Writers Problem}
The dining philosophers problem is useful for modeling processes that are competing for exclusive access to a limited number of resources,
such as I/O devices.
Another famous problem is the readers and writers problem which models access to a database (Courtois et al., 1971).
Imagine, for example, an airline reservation system, with many competing processes wishing to read and write it.
It is acceptable to have multiple process reading the database at the same time, but if one process is updating (writing) the database,
no other process may have access to the database, not even a reader.
The question is how do you program the readers and the writers?
One solution is shown in Fig. 2-21.

In this solution, the first reader to get access to the database does a \cmd{down} on the semaphore \sys{db}.
Subsequent readers merely have to increment a counter, \sys{rc}.
As readers leave, they decrement the counter and the last one out does an \cmd{up} on the semaphore, allowing a blocked writer,
if there is one, to get in.

The solution presented here implicitly contains a subtle decision that is worth commenting on.
Suppose that while a reader is using the database, another reader comes along.
Since having two readers at the same time is not a problem, the second reader is admitted.
A third and subsequent readers can also be admitted if they come along.

Now suppose that a writer comes along.
The writer cannot admitted to the database, since writers must have exlusive access, so the writer is suspended.
Later, additional readers show up.
As long as at least one reader is still active, subsequent readers are admitted.
As a consequence of this strategy, as long as there is a steady supply of readers, they will all get in as soon as they arrive.
The writer will be kept suspended until no reader is present.
If a new reader arrives, say, every 2 seconds, and each reader takes 5 seconds to do its work, the writer will never get in.

To prevent this situation, the program could be written slightly differently:
When a reader arrives and a writer is waiting, the reader is suspended behind the writer instead of being admitted immediately.
In this way, a writer has to wait for readers that were active when it arrived to finish 
but does not have to wait for readers that came along after it. 
The disadvantage of this solution is that it achives less concurrency and thus lower performance.
Courtois et al. present a solution that gives priority to writers.
For details, we refer you to the paper.

\section{Scheduling}
In the examples of the previous sections, we have often had situations in which 
two or more processes (e.g., producer and consumer) were logically runnable.
When a computer is mutiprogrammed, it frequently has multiple processes competing for the CPU at the same time.
When more than one process is in the ready state and there is only one CPU available,
the operating system must decide which process to run first.
The part of the operating system that makes the choice is called the \kw{scheduler};
the algorithm it uses called the \kw{scheduling algorithm}.

Many scheduling issues apply both to processes and threads.
Initially, we will focus on process scheduling, but later we will take a brief look at some issues specific to thread scheduling.

\subsection{Introduction to Scheduling}
Back in the old days of batch systems with input in the form of card images on a magnetic tape,
the scheduling algorithm was simple: just run the next job on the tape.
With timesharing systems, the scheduling algorithm became more complex, because there were generally multiple users waiting for service.
There may be one or more batch systems as well (e.g., at an insurance company, for processing clainms).
On a personal computer you might think there would be only one active process.
After all, a user entering a document on a word processor is unlikely to be simutaneously compiling a program in the backgroud.
However, there are often backgroud jobs, such as electronic mail daemons sending or receiving e-mail.
You might also think that computers have gotten so much faster over the years that the CPU is rarely a scare resource any more.
However, new applications tend to demand more resources.
Processing digital photographs or watching real time video are examples.

\subsubsection*{Process Behavior}
Nearly all processes alternate bursts of computing with (disk) I/O requests, as shown in Fig. 2-22.
Typically the CPU runs for a while without stopping, then a system call is made to read from a file or write to a file.
When the system call completes, the CPU computes again until it needs more data or has to write more data, and so on.
Note that some I/O activities count as computing.
For example, when the CPU copies bits to a video RAM to update the screen, it is computing, not doing I/O, because the CPU is in use.
I/O in this sense is when a process enters the blocked state waiting for an external device to complete its work.

The important thing to notice about Fig. 2-22 is that s
ome processes, such as the one in Fig. 2-22(a), spend most of their time computing, 
while others, such as the one in Fig. 2-22(b), spend most of their time waiting for I/O.
The former are called \kw{compute-bound}; the latter are called \kw{I/O-bound}.
Compute-bound processes typically have long CPU bursts and thus infrequent I/O waits,
whereas I/O-bound processes have short CPU bursts and thus frequent I/O waits.
Note that the key factor is the length of the CPU burst, not the length of the I/O burst.
I/O-bound processes are I/O bound because they do not compute much between I/O requests, 
not because they have especially long I/O requests.
It takes the same time to read a disk block no matter how much or how little time it takes to process the data after they arrive.

It is worth nothing that as CPU s get faster, processes tends to get more I/O bound.
This effect occurs because CPUs are improving much faster than disks.
As a consequence, the scheduling of I/O-bound processes is likely to become more inportant subject in the future.
The basic idea here is that if an I/O-bound process wants to run, 
it should get a chance quickly so it can issue its disk request and keep the disk busy.

\subsubsection*{When to Schedule}
There are a variaty of situation in which scheduling may occur.
First, scheduling is absolutely required on two occasions:
\begin{enumerate}
  \item When a process exits.
  \item When a process blocks on I/O , or a semaphore.
\end{enumerate}
 
In each of these cases the process that had most recently been running becomes unready, so another must be chosen to run next.

There are three other occasions when scheduling is usaully done, although logically it is not absolutely necessary at these times:
\begin{enumerate}
  \item When a new process is created.
  \item When an I/O interrupt occurs.
  \item When a clock interrupt occurs.
\end{enumerate}

In the case of a new process, it makes sense to reevaluate priorities at this time.
In some cases the parent may able to request a different priority for its child.

In some case of an I/O interrupt, this usually means that an I/O devices has now completed its work.
So some process that was blocked waiting for I/O may now be ready ro run.

In the case of a clock interrupt, this is an opportunity to decide whether the currently running process has run too long.
Scheduling algorithms can be divided into two categories with respect to how they deal with clock interrupts.
A \kw{non-preemptive} scheduling algorithm picks a process to run and 
then just lets it run until it blocks (either on I/O or waiting for another process)
or until it voluntarily release the CPU.
In contrast, a \kw{preemptive} scheduling algorithm picks a process and let it run for a maximum of some fixed time.
If it is still running at the end of the time interval, it is suspended and the scheduler picks another process to run (if one is available).
Doing preemptive scheduling requires having a clock interrupt occur at the end of the time interval to 
give control of the CPU back to the scheduler.
If no clock is available, non-preemptive scheduling is the only option.

\subsubsection*{Categories of Scheduling Algorithms}
Not surpringly, in different environments different scheduling algorithms are needed.
THis situation arises because different application areas (and different kinds of operating systems) have different goals.
In other words, what the scheduler should optimize for is not the same in all systems.
Three environments worth distinguishing are
\begin{enumerate}
  \item Batch.
  \item Interactive.
  \item Real time.
\end{enumerate}

In batch systems, there are no users impatiently waiting at their terminals for a quick response.
Consequently, nonpreemptive algorithms, or preemptive algorithms with long time periods for each process are often acceptable.
This approach reduces process switches and thus improves performance.

In an environment with interactive users, preemption is essential to 
keep one process from hogging the CPU and denying service to the others.
Even if no process intentionally ran forever, due to a program bug, one process might shut out all the others indefinitely.
Preemption is needed to prevent this behavior.

In systems with real-time constraints, preemption is, oddly enough sometines not needed because the processes know that
they may not run for long periods of time and usually do their work and block quickly.
The difference with interactive systems is that real-time systems run only programs that are intended to further the application at hand.
Interactive systems are general purpose and msy run arbitrary programs that are not cooperative or even malicious.

\subsubsection*{Scheduling Algorithm Goals}
In order to design a scheduling algorithm, it is necessary to have some idea of what a good algorithm should do.
Some goals depend on the environment (batch, interactivem or real time),
but there are also some that are desirable in all cases.
Some goals are listed in Fig. 2-23.
We will discuss these in turn below.

Under all circumstances, fairness is important.
Comparable processes should get comparable service.
Giving one process much more CPU time than an equivalent one is not fair.
Of course, different categories of processes may be treated differently.
Think of safety control and doing the payroll at a nuclear reactor's computer center.

Somewhat related to fairness is enforcing the system's policies.
If the local policy is that safety control processes get to run whenever they want to,
even if it means the payroll is 30 sec late, the scheduler has to make sure this policy is enforeced.

Another general goal is keeping all parts of the system busy when possible.
If the CPU and all the I/O devices can be kept running all the time, more work gets done per second if some of the components are idle.
In a batch system, for example, the scheduler has control of which jobs are brought into memory to run.
Having some CPU-bound processes and some I/O-bound processes in memory together is a better idea than 
first loading and running all the CPU-bound jobs and 
then, when they are finished, loading an running all the I/O-bound jobs.
If the later strategy is used, when the CPU-bound processes are running, 
they will fight for the CPU and the disk will be idle.
Later, when the I/O-bound jobs come in, they will fight for the disk and the CPU will be idle.
Better to keep the whole system running at once by careful mix of processes.

The managers of corporate computer centers that run many batch jobs (e.g., processing insurance claims) typically 
look at three metrics to see how well their systems are performing:
\kw{throughput}, \kw{turnaround time}, and \kw{CPU utilization}.
Throughput is the number of jobs per second that the system completes.
All things considered, finishing 50 jobs per second is better than finishing 40 jobs per second.
Turnaround time is the average time from the moment that a batch job is submitted until the moment it is completed.
It measures how long the average user has to wait for the output.
Here the rule is: Small is Beautiful.

A scheduling algorithm that maximizes throughput may not necessarily minimize turnaround time.
For example, given a mix of short jobs and long jobs, 
a scheduler that always ran short jobs and never ran long jobs might achieve an excelent throughput (many short jobs per second) 
but at the expense of a terrible turnaround time for the long jobs.
If short jobs kept arriving at a steady rate, the long jobs might never run, 
making the mean turnaround time infinite while achieving a high throughput.

CPU utilization is also an issue with batch systems because on the big mainfremes where batch systems run,
the CPU is still a major expense.
Thus computer center managers feel guilty when it is not running all the time.
Actually though, this is not such a good metric.
What really matters is how many jobs per second come out of the system (throughput) and how long it takes to get a job back (turnaround time).
Using CPU utilization as ametric is like rating cars based on how many times per second the engine turns over.

For interactive systems, especially timesharing systems and servers, different goals apply.
The most important one is to minimize \kw{response time}, that is the time between issuing a command an getting the result. 
On a personal computer where a backgroud process is running (for example, reading and storing email from the network),
a user request to start a program or open a file should take precedence over the backgroud work.
Having all interactive requests go first will be perceived as good service.

A somewhat related issue is what might be called \kw{proportionality}.
Users have an inherent (but often incorrect) idea of how long things should take.
When a request that is perceived as complex takes a long time, users accept that,
but when a request that is perceived as simple takes a long time, users get irritated.
For example, if clicking on a icon that calls up an Internet provider using an analog modem takes 45 seconds to establish a connection, 
the user will probably accept that as a fact of life.
On the other hand, if clicking on an icon that breaks the connection takes 45 seconds, 
the user will probably be swearing a blue streak by the 30-sec mark and frothing at the mouth by 45 sec.
This behavior is due to the common user perception that 
placing a phone call and getting a connection is supposed to take a lot longer than just hanging up.
In some cases (such as this one), the scheduler cannot do anything about the response time,
but in other cases it can, especially when the delay is due to a poor choice of process order.

Real-time systems have different properties than interactive systems, and thus different scheduling goals.
They are characterized by having deadlines that must or at least should be met.
For example, if a computer is controlling a device that produces data at a regular rate, 
failure to run the data-collection process on time may result in lost data.
Thus the foremost need in a real-time system is meeting all (or most) deadlines.

In some real-time systems, especially those involving multimedia, predictability is important.
Missing an occasional deadline is not fatal, but if the audio process-runs too erratically, the sound quality will deteriorate rapidly.
Video is also an issue, but the ear is much more sensitive to jitter than the eyr.
To avoid this problem, process scheduling must be highly predictable and regualr.

\subsection{Scheduling in Batch Systems}
It is now time to turn from general scheduling issues to specific scheduling algorithms.
In this section we will look at algorithms used in batch systems.
In the following ones we will examine interactive and real-time systems.
It is worth pointing out that some algorithms are used in both batch and interactive systems.
We will study these later.
Here we will focus on algorithms that are only suitable in batch systems.

\subsubsection*{First-Come First-Served}
Probably the simplest of all scheduling algorithms is nonpreemptive \kw{first-come first-served}.
With this algorithm, processes are assigned the CPU in the order they request it.
Basically, there is a single queue of ready process.
When the first job enters the system from the outside in the morning, 
it is started immediately and allowed to run as long as it wants to.
As other jobs come in, they are put onto the end of the queue.
When the running process blocks, the first process on the queue is run next.
When a blocked process becomes ready, like a newly arrived job, it is put on the end of the queue.

The great strength of this algorithm is that it is easy to understand and equally easy to program.
It is also fair in the same sense that allocating scarce sports or concert tickets to people 
who are willing to stand on line starting at 2 A.M. is fair.
WIth this algorithm, a single linked list keeps track of all ready processes.
Picking a process to run just requires removing one from the front of the queue.
Adding a new job or unblocked process just requires attaching it to the end of the queue.
What could be simpler?

Unfortunately, first-come first-served also has a powerful disadvantage.
Suppose that there is one compute-bound process that runs for 1 sec at a time and 
many I/O-bound processes that use little CPU time but each have to perform 1000 disk reads in order to complete.
The compute-bound process runs for 1 sec, then it reads a disk block, it runs for another 1 sec,
followed by all the I/O-bound processes in quick succession.

The net result is that each I/O-bound process gets to read 1 block per second and will take 1000 sec to finish.
With a scheduling algorithm that preempted the compute-bound process every 10 msec,
the I/O-bound processes would finish in 10 sec instead of 1000 sec,
and without slowing down the compute-bound process very much.

\subsubsection{Shortest Job First}
Now let us look at another nonpreemptive batch algorithm that assumes the run times are known in advance.
In any insurance company, for example, people can predict quite accurately how long it will take to run a batch of 1000 claims,
since similar work is done every day.
When several equally important jobs are sitting in the input queue waiting to be started, the scheduler picks the \kw{shortest job first}.
Look at Fig. 2-24.
Here we find four jobs A, B, C, and D with run times of 8, 4, 4, and 4 minutes, respectively.
By running them in that order, the turnaround time for A is 8 minutes, for B is 12 minutes, for C is 16 minutes, 
and for D is 20 minutes for an average of 14 minutes.

Now let us consider running these four jobs using shortest job first, as shown in Fig. 2-24(b).
The turnaround times are now 4, 8, 12, and 20 minutes for an average of 11 minutes.
Shortest job first is provable optimal.
Consider the case of four jobs, with run times of a, b, c, and d, respectively.
The first job finished at time a, the second finishes at time a + b, and so on.
The mean turnaround time is (4a + 3b + 2c +d)/4.
It is clear that a contributes more to the average than the other times, so it should be the shortest job,
with b next, then c, and finally d as the longest as it affects only its own turnaround time.
The same argument applies qually well to any number of jobs.

It is worth pointing out that shortest job first is only optimal when all the jobs are available simultaneously.
As a counterexample, consider five jobs, A through E, with run times of 2, 4, 1, 1, and 1, respectively.
Their arrival times are 0, 0, 3, 3, and 3.
Initially, only A or B can be chosen, since the other three jobs have not arrived yet.
Using shortest job first we will run the jobs in the order A, B, C, D, E, for an average wait of 4.6.
However, running them in the order B, C, D, E, A has an average wait of 4.4.

\subsubsection*{Shortest Remaining Time Next}
A preemptive version of shortest job first is \kw{shortest remaining time next}.
With this algorithm, the scheduler always chooses the process whose remainning run time is the shortest.
Again here, the run time has to be known in advance.
When a new job arrives, its total time is compared to the current process' remaining time.
If the new job needs less time to finish than the current process, the current process is suspended and the new job started.
This scheme allows new short jobs to get good service.

\subsubsection*{Three-Level Scheduling}
From a certain perspective, batch systems allows scheduling at three different levels, as illustrated in Fig. 2-25.
As jobs arrive at the system, they are initially placed in an input queue stored on the disk.
The \kw{admission scheduler} decides which jobs to admit to the system.
The others are kept in the input queue until they are selected.
A typical algorithm for admission control might be to look for a mix of compute-bound jobs and I/O-bound jobs.
Alternatively, short jobs could be admitted quickly whereas longer jobs would have to wait.
The admission scheduler is free to hold some jobs in the input queue and admit jobs that arrive later if it so chooses.

Once a job has been admitted to the system, a process can be created for it and it can contend for the CPU.
However, it might well happen that the number of processes is so large that there is not enough room for all of them in memory.
In that case, some of the processes have to be swapped out to disk.
The second level of scheduling is deciding which processes should kept in memory and which ones should kept on disk.
We will call this scheduler the \kw{memory scheduler}, since it determins which processes are kept in memory and which on the disk.

This decision has to be reviewed frequently to allow the processes on disk to get some service.
However, since bringing a process in from disk is expensive, 
the review probably should not happen more often than once per second, maybe less often.
If the contents of main memory are shuffled too often, a large amount of disk bandwidth will be wasted, slowing down file I/O.

To optimize system performance as a whole, the memory scheduler might well want to carefully decide how many processes it wants in memory,
called \kw{degree of multiprogramming}, and what kind of processes.
If it has information about which processes are compute bound and which are I/O bound, 
it can try to keep a mix of these process types in memory.
As a very crude approximation, if a certain class of process computes about 20\% of the time, 
keeoing five of them around is roughly the right number to keep the CPU busy.

To make its decisions, the memory scheduler periodically reviews each process on disk to decide whether or not to bring it into memory.
Among the criteria that it can use to make its decision are following ones:
\begin{enumerate}
  \item How long has it been since the process was swapped in or out?
  \item How much CPU time has the process had recently?
  \item How big is the process? (Small ones do not get in the way.)
  \item How important is the process?
\end{enumerate}

The third level of scheduling is actually picking one of the ready processes in main memory to run next.
Often this is called the \kw{CPU scheduler} and is the one people usually mean when they talk about the ``scheduler''.
Any suitable algorithm can be used here, either preemptive or non-preemptive.
These include the ones described above as well as a number of algorithms to be described in the next section.

\subsection{Scheduling in Iteractive Systems}
We will now look at some algorithms that can be used in interactive systems.
All of these can also be used as the CPU scheduler in batch systems as well.
While three-level scheduling is not possible here, two-level scheduling (memory scheduler and CPU scheduler) is possible and common.
Below we will focus on the CPU scheduler and some common scheduling algorithms.

\subsubsection*{Round-Robin Scheduling}
Now let us look at some specific scheduling algorithms.
One of the oldest, simplest, fairest, and most widely used algorithms is \kw{round robin}.
Each process is assigned a time interval, called its \kw{quantum}, which it is allowed to run.
If the process is still running at the end of the quantum, the CPU is preempted and given to another process.
If the process has blocked or finished before the quantum has elapsed,
the CPU switching is done when the process blocks, of course.
Round robin is easy to implement.
All the scheduler needs to do is maintain a list of runable processes, as shown in Fig. 2-26(a).
When the process uses up its quantum, it is put on the end of the list, as shown in Fig. 2-26(b).

The only intersting issue with round robin is the length of the quantum.
Switching from one process to another requires a certain amount of time 
for doing the administration saving and loading registers and memory maps,
updating various tables and lists, flushing and reloading the memory cache, etc.
Suppose that this \kw{process switch} or \kw{contex switch}, as it sometimes called, takes 1 msec, 
including switching memory maps, flushing and reloading the cache, etc.
Also suppose that the quantum is set at 4 msec.
With these parameters, after doing 4 msec of useful work,
the CPU will have to spend 1 msec on process switching.
Twenty percent of the CPU time will be wasted on administrative overhead.
Clearly, this is too much.

To improve the CPU efficiently, we could set the quantum to, say, 100 msec.
Now the wasted time is only 1 percent.
But consider what happens on a timesharing system if ten interactive users hit the carriage return key at roughly the same time.
Ten processes will be put on the list of runable processes.
If the CPU is idle, the first one will start immediately, the second one may not start until 100 msec later, and so on.
The unlucky last one may have to wait 1 sec before getting a chance, assuming all the others use their full quanta.
Most users will perceive a 1-sec response to a short command as sluggish.

Another factor is that the quantum is set longer than the mean CPU burst, preemption will rarely happen. 
Instead, most processes will perform a blocking operation before the quantum runs out, causing a process switch.
Eliminating preemption improves performance because process switches then only happen when they are logically necessary, 
that is, when a process blocks and cannot continue because it is logically waiting for waiting for something.

The conclusion can be formulated as follows: setting the quantum too short causes too many process switching and lowers the CPU efficiency,
but setting it too long may cause poor response to short interactive requests.
A quantum of around 2050 msec is often a reasonable compromise.


\subsubsection*{Priority Scheduling}
Round-robin scheduling makes the implicit assumption that all processes are equally important.
Frequently, the people who own and operate multiuser computers have different ideas on that subjects.
At a university, the pecking order may be deans first, then professors, secretaries, janitors, and finally students.
The need to take external factors into account leads to \kw{priority scheduling}.
The basic idea is straitforward: each process is assigned a priority, 
and the runnable process with the highest priority is allowed to run.

Even on a PC with a singler owner, there may be multiple processes, some more important than others.
For example, a daemon process sending electronic mail in the background should be assigned a lower priority 
than a process displaying a video film on the screen in real time.

To prevent high-priority processes from running indefinitely, 
the scheduler may decrease the priority of the currently running process at each clock tick (i.e., at each clock interrupt).
If this action causes its priority to drop below that of the next highest process, a process switch occurs.
Alternatively, each process may be assigned a maximum time quantum that it is allowed to run.
When this quantum is used up, the next highest priority process is given a chance to run.

Priorities can be assigned to processes statically or dynamically.
On a military-compute, processes started by generals might begin at priority 100, 
processes started by colonels at 90, majors at 80, captains at 70, lieutenants at 60, and so on.
Alternatively, at a commertial computer center, high-priority jobs might cost 100 dollars and hour,
medium priority 75 dollars an hour, and low priority 50 dollars an hour.
The UNIX system has a command, \sys{nice}, which allows a user to voluntarily reduce the priority of his process,
in order to be nice to the other users.
Nobody ever uses it.

Priorities can also be assigned dynamically by the system to achive certain system goals.
For example, some processes are highly I/O bound and spend most of their time waiting for I/O to cpmplete.
Whenever such a process wants the CPU, it should be given the CPU immediately, to let it start its next I/O request, 
which can then proceed in parallel with another process actually computing.
Making the I/O-bound process wait a long time for the CPU will just mean having it around occupying memory for an unnecessarily long time.
A simple algorithm for giving good service to I/O-bound processes is to set the priority to 1/\sys{f}, 
where \sys{f} is the fraction of the last quantum that a process used.
A process that used only 1 msec of its 50 msec quantum would get priority 50, 
while a process that ran 25 msec before blocking would get priority 2,
and process that used the whole quantum would get priority 1.

It is often convenient to group processes into priority classes and 
use priority scheduling among the classes but round-robin scheduling within each class.
Fig. 2-27 shows a system with four priority classes.
The scheduling algorithm is as follows: as long as there are runnable processes in priority class 4, 
just run each one for one quantum, round-robin fashion, and never bother with lower priority classes.
If priority class 4 is empty, then run the class 3 processes round robin.
If classes 4 and 3 are both empty, then run class 2 round robin, and so on.
If priorities are not adjusted occasionally, lower priority classes may all startve to death.

MINIX 3 uses a similar system to Fig. 2-27, although there are sixteen priority classes in the default configuration.
In MINIX 3, components of the operating system run as processes.
MINIX 3 puts tasks (I/O drivers) and servers (memory manager, file system, and network) in the highest priority classes.
The initial priority of each task or service is defined at compile time;
I/O from a slow device may be given lower priority than I/O from a fast device or even a server.
User processes generally have lower priority than system components, but all priorities can change during execution.

\subsubsection*{Multiple Queues}
One of the earliest priority schedulers was in CTSS (Corbato et al., 1962).
CTSS had the problem that process switching was very show because the 7094 could hold only one process in memory.
Each switch meant swapping the current process to disk and reading in a new one from disk.
The CTSS designers quickly realized that it was more efficient to give CPU-bound processes a large quantum once in a while,
rather than giving them small quanta frequently (to reduce swapping).
On the other hand, giving all processes a large quantum would mean poor response time, as we have already observed.
Their solution was to set up priority classes.
Processes in the highest class were run for one quantum.
Processes in the next highest class were run for two quanta.
Processes in the next class were run for four quanta, and so on.
Whenever a process used up all the quanta allocated to it, it was moved down one class.

As an example, consider a process that needed to compute continuously for 100 quanta.
It would initially be given one quantum, then swapped out.
Next time it would get two quanta before being swapped out.
On succeeding runs it would get 4, 8, 16, 32, and 64 quanta, 
although it would have used only 37 of the final 64 quanta to complete its work.
Only 7 swaps would be neede (including the initial load) instead of 100 with a pure round-robin algorithm.
Furthermore, as the process sank deeper and deeper into the priority queues,
it would be run less and less frequently, saving the CPU for short, interactive processes.

The following policy was adopted to prevent a process that needed to run for a long time 
when it first started but became interactive later, from being punished forever.
Whenever a carriage return was typed at a terminal, the process belonging to that terminal was moved to the highest priority class,
on the assumption that it was about to become interactive.
One fine day, some user with a heavily CPU-bound process discovered that just sitting at the terminal and typing carrige returns at random every few seconds did wounders for his response time.
He told He told all his friends.
Moral of the story: getting it right in practice is much harder than getting it right in principle.

Many other algorithm have been used for assigning processes to priority classes.
For example, the influential XDS 940 system (Lampson, 1968), built at Berkeley, 
had four priority classes, called terminal, I/O, short quantum, and long quantum.
When a process that was waiting for terminal input was finally awakened, it went into the highest priority class (terminal).
When a process waiting for a disk block became ready, it went into the second class.
When a process was still running when its quantum ran out, it was initially placed in the third class.
However, if a process used up its quantum too many times in a row without blocking for terminal or other I/O, 
it was moved down to the bottom queue.
Many other systems use something similar to favor interactive users and processes over backgroud one.

\subsubsection*{Shortest Process Next}
Because shortest job first always produces the minimum average response time for batch systems,
it would be nice if it could be used for interactive processes as well.
To a certain extent, it can be.
INteractive processes generally follow the pattern of wait for command, execute command, wait for command, execute command, and so on.
If we regard the execution of each command as a separate ``jon'', then we could minimize overall response time by running the shortest one first.
The only problem is figuring out which of the currently runnable processes is the shortest one.

One approach is to make estimates based on past behavior and run the process with the shortest estimated running time.
Suppose that the estimated time per command for some terminal is \sys{T0}.
Now suppose its next run is measured to be \sys{T1}.
We could update our estimateby taking a weighted sum of these two numbers, that is, \sys{aT0 + (1a)T1}.
Though the choice of \sys{a} we can decide to have the estimation process forget old runs quickly, 
or remember them for a long time.
With \sys{a} = 1/2. we get successive estimates of \\
\cmd{T0, T0/2+T1/2, T0/4+T1/4+T2/2, T0/8+T1/8+T2/4+T3/2}
After three new runs, the weight of \sys{T0} in the new estimate has dropped to 1/8.

THe technique of estimating the next value in a series by taking the weighted average 
of the current measured value and the previous estimate is sometimes called \kw{aging}.
It is applicable to many situations where a prediction must be made based on previous values.
Aging is especially easy to implement when \sys{a} = 1/2.
All that is needed is to add the new value to the current estimate and divide the sum by 2 (by shifting it right 1 bit).

\subsubsection*{Guaranteed Scheduling}
A completely different approach to scheduling is to make real promises to the users about performance and then live up to them.
One promise that is realistic to make and easy to live up to is this:
If there are \sys{n} users logged in while you are working, you will receive about 1/n of the CPU power.
Similarly, on a single-user system with \sys{n} processes running, all things being equal, each one should get 1/n of the CPU cycles.

To make good on this promise, the system must keep track of how much CPU each process has had since its creation.
It then computes the amount of CPU each one is entitled to, namely the time since creation divided by \sys{n}.
Since the amount of CPU time each process has actually had is also known, it is straightforward to compute the ratio of actual CPU time consumed to CPU time entitled.
A ration of 0.5 means that a process has only had half of what it should have had,
and a ratio of 2.0 means that a process has had twice as much as it was entitled to.
The algorithm is then to run the process with the lowest ration until its ration has moved above its closest competitor.

\subsubsection*{Lottery Scheduling}
While making promises to the users and then living up to them is a fine idea, it is difficult to implement.
However, another algorithm can be used to give similarly predictable results with a much simpler implementation. 
It is called \kw{lottery scheduling} (Waldspurger and Weihl, 1994).

The basic idea is to give processes lottery tickets for various system resources, such as CPU time.
Whenever a scheduling decision has to be made, a lottery ticket is chosen at random, and the process holding that ticket gets the resource.
When applied to CPU scheduling, the system might hold a lottery 50 times a second, with each winner getting 20 msec of CPU time as a prize.

To paraphrase George Orwell: ``All processes are equal, but some processes are more equal.''
More important processes can be given extra tickets, to increase their odds of winning.
If there are 100 tickets outstanding, and one process holds 20 of them, it will have a 20 percent chance of winning each lottery.
In the long run, it will get about 20 percent of the CPU.
In contrast to a priority scheduler, where it is very hard to state what having a priority of 40 actually means,
here the rule is clear: a process holding a fraction \sys{f} of the tickets will get about a fraction \sys{f} of the resource in question.

Lottery scheduling has several intersting properties.
For example, if a new process shows up and is granted some tickets, at the very next lottery 
it will have a chance of winning in proportion to the number of tickets it holds.
In other words, ;lottery scheduling is highly responsive.

Cooperating processes may exchange tickets if they wish.
For example, when a client process sends a message to a sever process and then blocks, it may give all of its tickets to the server,
to increase the chance of the server running next.
When the server is finished, it returns the tickets so the client can run again.
In fact, in the absence of clients, servers need no tickets at all.

Lottery shceduling can be used to solve problems that are difficult to handle with other methods.
One example is a video server in which several processes are feeding videostreams to their clients, but at different frame rates.
Suppose that the processes need frames at 10, 20, and 25 frames/sec.
By allocating these processes 10, 20, and 25 tickets, respectively,
they will automatically divide the CPU in approximately the correct proportion, that is , 10 : 20 : 25.

\subsubsection*{Fair-Share Scheduling}
So far we have assumed that each process is scheduled on its own, without regard to who its owner is.
As a result, if user 1 starts up 9 processes and user 2 starts up 1 processes,
with round robin or equal priorities, user 1 will get 90\% of the CPU and user 2 get only 10\% of it.

To prevent this situation, some systems taken into account who owns a process before scheduling it.
In this model, each user is allocated some fraction of the CPU and scheduler picks processes in such a way as to enforece it.
Thus if two users have each been promised 50\% of the CPU, they will each get that, 
no mattern how many processes they have in existence.

As an example, consider a system with two users, each of which has been promised 50\% of the CPU.
User 1 has four processes, A, B, C, and D, and user 2 has only 1 process, E.
If round-robin scheduling is used, a possible scheduling sequence that meets all the constraints is this one:\\
A E B E C E A E B E C E D E...

On the other hand, if user 1 is entitled twice as much CPU time as user 2, we might get\\
A B E C D E A B E C D E...

Numerous other possibilities exist, of course, and can be exploited, depending on what the notion of fairness is.

\subsection{Scheduling in Real-Time Systems}
A \kw{real-time} system is one in which time plays an essential role.
Typically, one or more physical devices external to the computer generate stimuli, 
and the computer must react appropriately to them within a fixed amount of time.
For example, the computer in a compact disc plater gets the bits as they come off the drive 
and must convert them into music within a very tight time interval.
If the caculation takes too long, the music will sound peculiar.
Other real-time systems are patient monitoring in a hospital intersive-care unit, 
the autopilot in an aircraft, and robot control in an automated factory.
In all these cases, having the right answer but having too late is aften just as bad as not having it at all.

Real-time systems are generally categorized as \sys{hard real time}, meaning there are absolute deadlines that must be met,
or else, and \sys{soft real time}, meaning that missing an occasional deadline is undesirable, but nevertheless tolerable.
In both cases, real-time behavior is achived by diving the program into a number of processes, 
each of whose behavior is predictable and known in advance.
These processes are generally short lived and can run to completion in well under a second.
When an external event is detected, it is the job of the scheduler to schedule the processes in such a way that all deadlines are met.

The events that a real-time system may have to respond to can further categorized as 
\kw{periodic} (occuring at regular intervals) or \kw{aperiodic} (occuring unpredictably).
A stystem may have to respond to multiple periodic event streams.
Depending on how much time each event requires for processing, 
it may not even be possible to handle them all.
For example, if there are \sys{m} periodic events and event \sys{i} occurs 
with period \(P_i\) and requires \(C_i\) seconds of CPU time to handle each event, 
then the load can only be handled if 
\[
\sum_{i=1}^{m}\frac{C_i}{P_i}\leq1
\]
A real-time system that meets this criteria is said to be \kw{schedule}.

As an example, consider a soft real-time system with three periodic events,
with periods of 100, 200, and 500 msec, respectively.
If these events require 50, 30, and 100 msec of CPU time per event, respectively, the system is schedulable because 0.5 + 0.15 + 0.2 < 1.
If a fourth event with a period of 1 sec is added, 
the system will remain schedulable as long as this event does not need more than 150 msec of CPU time per event.
Implicit in this calculation is the assumption that the context-switching overhead is so small that it can be ignore.

Real-time scheduling algorithms can be static or dynamic.
The former make their scheduling decisions before the system starts running.
The latter make their scheduling decisions at run time.
Static shceduling only works when there is perfect information available in advance 
about the work needed to be done and the deadlines that have to be met.
Dynamic shceduling algorithms do not have these restrictions.

\subsection{Policy versus Mechanism}
Up until now, we have tacitly assumed that all the processes in the system belong to different users and are thus competing for the CPU.
While this is often trur, sometimes it happens that one process has many children running under its control.
For example, a database management system process may have many children.
Each child might be working on a different request, or each one might have some specific function to perform (query parsing, disk access, etc.).
It is entirely possible that the main process has an excellent idea of 
which of its children are the most important (or the most time critical) and which the least.
Unfortunately, none of the shcedulers discusses above accept any input from user processes about scheduling decisions.
As a result, the scheduler rarely makes the best choice.

The solution to this problem is to seperate the \kw{scheduling mechanism} from the \kw{scheduling policy}.
What this means is that the scheduling algorithm is parameterized in some way, but the parameters can be filled in by user processes.
Let us consider the datebase example once again.
Suppose that the kernel uses a priority shceduling algorithm but provides a system call 
by which a process can set (and change) the priorities of its children.
In this way the parent can control in detail how its children are scheduled, even though it does not do the scheduling itself.
Here the mechanism is in the kernel but policy is set by user process.

\subsection{Thread Scheduling}
When several processes each have multiple threads, we have two levels of parallelism present: processes and threads.
Scheduling in such systems differs substantially on whether user-level threads or kernel-level threads (or both) are supported.

Let us consider user-level threads first.
Since the kernel is not aware of the existence of threads,
it operates as it always does, picking a process, say, \sys{A}, and giving \sys{A} control for its quantum.
The thread scheduler inside \sys{A} decides which thread to run, say \sys{A1}.
SInce there are no clock interrupts to multiprogram threads, this thread may continue running as long as it wants to.
If it uses up the process' entire quantum, the kernel will select another process to run.

When the process \sys{A} finally runs again, thread \sys{A1} will resume running.
It will continue to consume all of \sys{A}'s time until it is finished.
However, its antisocial behavior will not affect other processes.
They will get whatever the scheduler considers their appropriate share, no matter what is going on inside process s\sys{A}.

Now consider the case that \sys{A}'s threads have relatively little work to do per CPU burst, for example, 5 msec of work within a 50-msec quantum.
Consequently, each one runs for a little while , then yields the CPU back to the thread scheduler.
THis might lead to the sequence \sys{A1, A2, A3, A1, A2, A3, A1}, before the kernel switches to process B.
This situation is illustrated in Fig. 2-28(a).

The scheduling algorithm used by the run-time system can be any of the ones described above.
In practice, round-robin scheduling and priority shceduling are most common.
The only constraint is the absence of a clock to interrupt a thread that has run too long.

Now consider the situation with kernel-level threads.
Here the kernel picks a particular thread to run.
It dose not have to take into account with process the thread belongs to, but it can if it wants to.
The thread is given a quantum and is forceably suspended if it exceeds the quantum.
With a 50-msec quantum but threads that block after 5 msec, the thread order for some period of 30 msec might be \sys{A1, B1, A2, B2, A3, B3},
something not possible with these parameters and user-level threads.
This situation is partially depicted in Fig. 2-28(b).

A major difference between user-level threads and kernel-level threads is the performance.
Doing a thread switch with user-level threads takes a handful of machine instructions.
With kernel-level threads it requires a full context switch, changing the memory map, and invalidating the cache, 
which is several orders of magnitude slower.
On the onther hand, with kernel-level threads, having a thread block on I/O does not suspend the entire process as it soes with user-level threads.

Since the kernel knowns that switching from a thread in process \sys{A} to a thread in process \sys{B} is more expensive 
that running a second thread in process A (due to having to change the memory map and having the memory cache spoiled),
it can take this information into account when making a decision.
For example, given two threads that are otherwise equally important, with one of them belonging to the same process as a thread that just blocked
and one belonging to a different process, preference could be given to the former.

Another important factor to consider is that user-level threads can employ an application-specific thread scheduler.
For example, consider a web server which has a dispatcher thread to accept and distribute incoming requests to worker threads.
Suppose that a worker thread has just blocked and the dispatcher thread and two worker threads are ready.
Who should run next?
The run-time system, knowing what all the threads do, can easily pick the dispatcher to run next,
so it can start another worker running.
This strategy maximizes the amount of parallelism in an environment where workers frequently block on disk I/O.
With kernel-level threads, the kernel would never known what each thread did (although they could be assigned different priorities).
In general, however, application-specific thread shcedulers can tune an application better than the kernel can.

\section{Overview of Processes in MINIX 3}
Having completed our study of the principles of process management, interprocess communication, and shceduling, 
we can now take a look at how they are applied in MINIX 3.
Unlike UNIX, whose kernel is a monolithic program not split up into modules, 
MINIX 3 itself is a collection of process that communicate with each other and also with user processes,
using a single interprocess commucation primitive message passing.
This design gives a more modular and flexible structure, making it easy,
for example, to replace the entire file system by a completely different one,
without having even to recompile the kernel.

\subsection{The Internal Structure of MINIX 3}
Let us begin our study of MINIX 3 by taking a bird's-eye view of the system.
MINIX 3 is structed in four layers, with each layer performing a well-defined function.
The four layers are illustrated in Fig. 2-29.

The \kw{kernel} in the bottom layer shcedules processes and manages the transitions between the ready, running, and blocked states of Fig. 2-2.
The kernel also handles all messages between processes.
Massage handling requires checking for legal destinations, locating the send and receive buffers in physical memory,
and copying bytes from sender to receiver.
Also part of the kernel is support for access to I/O ports and interrupts,
which on modern processors require use of privileged \kw{kernel mode} instructions not available to ordinary processes.

In addition to the kernel itself, this layer contains two modules that function similarly to device drivers.
The \kw{clock task} is an I/O device driver in the sense that it interacts with the hardware that generates timing signals,
but it is not user-accessible like a disk or communications line driverit interfaces only with the kernel.

One of the main function of layer 1 is to provide a set of privileged \kw{kernel calls} to the drivers and servers above it.
These including reading and writing I/O ports, copying data between address spaces, and so on.
Implementation of these calls is done by the \kw{system task}.
Although the system task and the clock task are compiled into the kernel's address space,
they are scheduled as separate processes and have their own call stacks.

Most of the kernel and all of the clock and system tasks are witten in C.
However, a small amount of the kernel is written in assembly language.
The assembly language parts deal with interrupt handling, the low-level mechanics of managing context switches between processes 
(saving and restoreing registers and the like), and low-level parts of manipulating the MMU hardware.
By and large, the assembly-language code handles those parts of the kernel 
that deal directly with the hardware at a very low level and which cannot be expresses in C.
These parts have to be rewritten when MINIX 3 is ported to a new architecture.

The three layers above the kernel could be considered to be a single layer because the kernel fundamentally treats them all of them the same way.
Each one is limited to \kw{user mode} instructions, and each is scheduled to run by the kernel.
None of them can access I/O ports directly.
Furthermore, none of them can access memory outside the segments allocated to it.

However, processes potentially have special privileges (such as the ability to make kernel calls).
This is the real difference between processes in layers 2, 3, and 4.
The processes in layer 2 have the most privileges, those in layer 3 have some privileges, and those in layer 4 have no special privileges.
For example, processes in layer 2, called \kw{device drivers}, are allowed to request that the system task 
read data from or write data to I/O ports on their behalf.
A driver is needed for each device type, including disks, printers, terminals, and network interfaces.
If other I/O devices are present, a driver is needed for each one of those, as well.
Device drivers may also make onther kernel calls, such as requesting that newly-read data to copied to the address space of a different process.

The third layer contains \kw{severs}, processes that provide useful services to the user processes.
Two servers are essential.
The \kw{process manager (PM)} carries out all the MINIX 3 system calls that involve starting or stopping process execution,
such as \cmd{fork}, \cmd{exec}, and \cmd{exit}, as well as system calls related to signals, 
such as \cmd{alrm} and \cmd{kill}, which can alter the execution state of a process.
The process manager also is responsible for managing memory, for instance, with the \cmd{brk} system call.
The \kw{file system (FS)} carries out all the system calls, such as \cmd{read}, \cmd{mount}, and \cmd{chdir}.

It is important to understand the difference between kernel calls and POSIX system calls.
Kernel calls are low-level functions provided by the system task to allow the drivers and servers to do their work.
Reading a hardware I/O port is a typical kernel call.
In contrast, the POSIX system calls such as \cmd{read}, \cmd{fork}, and \cmd{unlink} are high-level calls defined by the POSIX standard,
and are available to user programs in layer 4.
User programs contain many POSIX calls but no kernel calls.
Occasionally when we are not being careful with our language we may call a kernel call a system call.
The mechanisms used to make these calls are similar, and kernel calls can be considered a special subset of system calls.

In addition to the PM and FS, other servers exist in layer 3.
They perform functions that are specific to MINIX 3.
It is safe to say that the functionality of the process manager and the file system wii be found in any operating system.
The \kw{information server (IS)} handles jobs such as providing debugging and status information about other drivers and servers, 
something that is more necessary in a system like MINIX 3, designed for experimentation, 
that would be the case for a commercial operating system which users cannot alter.
The \kw{reincarnation server (RS)} starts, and if necessary restarts, device drivers that are not loaded into memory at the same time as the kernel.
In particular, if a driver fails during operation, the reincarnation server detects this failure,
kill the driver if it is not already dead, and starts a fresh copy of the driver,
making the system highly fault tolerant.
This functionality is absent from most operating systems.
On a networked system the optional \kw{network server (inet)} is also in level 3.
Servers cannot do I/O directly, but they can communicate with drivers to request I/O.
Servers can also communicate with the kernel via the system task.

As we noted at the start of Chap. 1, operating system do two things: manage resources and provide an extended machine by implementing system calls.
In MINIX 3 the resource management is largely done by the drivers in layer 2, 
with help from the kernel layer when privileged access to I/O ports or the interrupt system is required.
System call interpretation is done by the process manager and file system servers in layer 3.
The file system has been carefully designed as a file ``server'' and counld be moved to a remote machine with few changes.

The system does not need to be recompiled to include additional servers.
The process manager and the file system can be supplemented with the network server and other servers 
by attaching additional servers as required when MINIX 3 starts up or later.
Device drivers, although typically started when the system is started, can also be started later.
Both device drivers and servers are compiled and stored on disk as ordinary executable files,
but when properly started up they are granted access to the special privileges needed.
Although the drivers and servers are independent processes, 
they differ from user processes in that normally they never terminate while the system is active.

We will often refer to the drivers and servers in layers 2 and 3 as \kw{system processes}.
Arguably, system processes are part of the operating system.
They do not belong to any user, and many if not all of them will be activated before the first user logs on.
Another difference between system processes and user processes is that
system processes have higher execution priority than user processes.
IN fact, normally drivers have higher execution priority than servers, but this is not automatic.
Execution priority is assigned on a case-by-case basis in MINIX 3;
it is possible for a driver that services a slow device to be given lower priority than a server that must respond quickly.

Finally, layer 4 contains all the user processes shells, editors, compilers, and user-written \sys{a.out} programs.
Many user processes come and go as users log in, do work, and log out.
A running system normally has some user processes that are started when the system is booted and which run forever.
One of these is \sys{init}, which we will describe in the next section.
ALso, several daemons are likely to be running.
A \kw{daemon} is a backgroud process that executes periodically or always waits for some event,
such as the arrival of a packet from the network.
In a sense a daemon is a server that is started independently and runs as a user process.
Like true servers installed at startup time, it is possible to configure a daemon to have a higher priority than ordinary user processes.

A note about the term \kw{task} and \kw{device driver} is needed.
IN older versions of MINIX all device drivers were compiled together with the kernel,
which gave them access to data structures belonging to the kernel and each other.
They also could all access I/O port directly.
They were referred to as ``tasks'' to distinguish them from pure independent user-space processes.
In MINIX 3, device drivers have been implemented completely in user-space.
The only exception is the clock task, which is arguably not a device driver in the same sense as drivers 
that can accessed through device files by user processes.
Within the text we have taken pains to use the term ``task'' only when referring to the clock task or the system task,
both of which are compiled into the kernel to function.
We have been careful to replace the word ``task'' with ``device driver'' where we refer to user-space device drivers.
However, function names, variable names, and comments in the source code have not been as carefully updated.
Thus, as you look at source code during your study of MINIX 3 you may find the word ``task'' where ``device driver'' is meant. 

\subsection{Process Management in MINIX 3}
Processes in MINIX 3 follow the general process model described at length earlier in this chapter.
Processes can create subprocesses, which in turn can create more subprocesses, yielding a tree of processes.
In fact, all the user processes in the whole system are part of a single tree with \sys{init} (see Fig. 2-29) at the root.
Severs and drivers are a special case, of course, since some of them must be started before any user process, including \sys{init}.

\subsubsection*{MINIX 3 Startup}
How does an operating system start up?
We will summarize the MINIX 3 stratup sequence in the next few pages.
For a look at how some other operating system do this, see Dodge et al. (2005).

On most computers with disk devices, there is a \kw{noot disk} hierarchy.
TYpically, if a floppy disk is in the first floppy disk driveit will be the boot disk.
If no floppy disk is present and a CD-ROM is present in the first CD-ROM dive, it becomes the boot disk.
If there is neither a floppy disk nor a CD-ROM present, the first hard drive becomes the boot disk.
The order of this hierarchy may be configurable by entering the BIOS immediately after powering the computer up.
Additional devices, especially other removable storage devices, may be supported as well.

When the computer is turn on, if the boot device is a diskette, 
the hardware reads the first sector of the first track of the boot disk into memory and executes the code it find there.
On a diskette this sector contains the \kw{bootstrap} program.
It is very small, since it has to fit in one sector (512 bytes).
The MINIX 3 bootstrap loads a large program, \sys{boot}, which then loads the operating system itself.

In contrast, hard disks require an intermediate step.
A hard disk is divided into \kw{partions}, and the first sector of a hard disk contains a small program and the disk's \kw{partion table}.
Collectively thesetwo pieces are called the \kw{master boot record}.
The program part is executed to read the partion table and to select the \kw{active partion}.
The active partion has a bootstrap on its first sector, which is then loaded and executed to find and start a copy of \sys{boot} in the partion,
exactly as is done when booting from a diskette.

CD-ROMs came along later in the history of computers than floppy disks and hard disks,
and when support for booting from a CD-RON is present it is capable of more than just loading one sector.
A computer that supports booting from a CD-ROM can load a large block of data into memory immediately.
Typically what is loaded from the CD-ROM is an exact copy of a bootable floppy disk, 
which is placed in memory and used as a \kw{RAM disk}.
After the first step control is transferred to the RAM disk and booting continues exactly as if a physical floppy disk were the boot device.
On an oler computer which has a CD-ROM drive but does not support booting from a CD-ROM, 
the bootable floppy disk image can be copied to a floppy disk which can then be used to start the system.
The CD-ROM must be in the CD-ROM drive, of course, since the bootable floppy disk image expects that.

In any case, the MINIX 3 \sys{boot} program looks for a specific multipart file on the diskette or partition 
and loads the individual parts into memory at the proper locations.
This is the \kw{boot image}.
The most important parts are the kernel (which include the clock task and the system task),
the process manager, and the file system.
Additionally, at least one disk driver must be loaded as part of the boot image.
There are several other programs loaded in the boot image.
These include the reincarnation server, the RAM disk, console, and log drivers, and \sys{init}.

It should be strongly emphasized that all parts of the boot image are seperate programs.
After the essential kernel, process manager and file system have been loaded many other parts could be loaded separately.
An exception is the reincarnation server.
It must be part of the boot image.
It gives ordinary processes loaded after initialization the special priorities and privileges 
which make them into system processes, it can also restart a crashed driver, which explains its name.
As mentioned above, at least one disk driver is essential.
If the root file system is to be copied to a RAM disk, the memory driver is also required, otherwise it could be loaded later.
The \sys{tty} and \sys{log} drivers are optional in the boot image.
They are loaded early just because it is useful to be able to display messages on the console 
and save information to a log early in the startup process.
\sys{Init} could certainly be loaded later, but it controls initial configuration of the system, 
and it was easiest just to include it in the boot image file.

Startup is not a trivial operation.
Operations that are in the realms of the disk driver and the file system must be performed by \sys{boot} before these parts of the system are active.
In a later section we will detail how MINIX 3 is tarted.
For now, suffice it to say that once the loading operation is complete the kernel starts running.

During its initialization phase the kernel starts the system and clock tasks,
and then the process manager and the file system.
The process manager and the file system then cooperate in starting other servers and drivers that are part of the boot image.
When all these have run and initialized themselves, they will block, waiting for something to do.
MINIX 3 shceduling prioritizes processes.
Only when all tasks, drivers, and servers loaded in the boot image have blocked will \sys{init}, the first user process, be executed.
System components loaded with the boot image or during initialization are shown in Fig. 2-30.

\subsubsection*{Initialization of the Process Tree}
\kw{Init} is the first user process, and also the last process loaded as part of the boot image.
You might think building of a process tree such as that of Fig. 1-5 begins once \sys{init} starts running.
Well, not exactly.
That wold be true in a conventional operating system, but MINIX 3 is different.
First, there are already quite a few system processes running by the time \sys{init} gets to run.
The tasks \sys{CLOCK} and \sys{SYSTEM} that run within the kernel are unique processes that are not visible outside of the kernel.
They receive no PIDs and are not considred part of amy tree of processes.
The process manager is the first process to run in user space;
it is given PID 0 and is neither a child nor a parent of nay other process.
The reincarnation server is made the parent of all the other processes started from the boot image (e.g., the drivers and servers).
The logic of this is that the reincarnation server is the process that should be informed if any of these should need to be restarted.

As we will see, even after \sys{init} starts running there are differences between the way a process tree is built in MINIX 3 
and the conventional concept.
\sys{Init} in a UNIX-like is given PID 1, and even though \sys{init} is not the process to run, 
the traditional PID 1 is reserved for it in MINIX 3.
Like all the user space processes in the boot image (except the process manager),
\sys{init} is made one of the children of the reincarnation server.
As in a standard UNIX-like system, \sys{init} first execytes the \kw{/etc/rc} shell script.
This script starts additional drivers and servers that are not part of the boot image.
Any program started by the \sys{rc} script will be a child of \sys{init}.
One of the first programs run is a utility called \sys{service}.
\sys{Service} itself runs as a child of \sys{init}, as would be expected.
But now things once again vary from the conventional.

\sys{Service} is the user interface to the reincarnation server.
The reincarnation server starts an ordinary program and converts it into a system process.
It starts \sys{floppy} (if it was used in booting the system), \sys{cmos} (which is needed to read the real-time clock), 
and \sys{is}, the information server which manage the debug dumps that are produced by pressing function keys (F1, F2, etc.) on concole keyboard.
One of the actions of the inreincarnation server is to adopt all system processes except the process manager as its own children.

After the \sys{cmos} device driver has been started the \sys{rc} script can initialize the real-time clock.
Up to this point all files needed must be found on the root device.
The servers and drivers needed initially are in the \sys{/sbin} directory;
other commands needed for startup are in \sys{/bin}.
Once the initial startup steps have been completed other file systems such as \sys{/usr} are mounted.
An important of the \sys{rc} script is to check for file system problems that might have resulted from a previous system crash.
The test is simple when the system is shutdown correctly by executing the \sys{shutdown} command, 
an entry is written to the login history file, \sys{/usr/adm/wtmp}.
The command \cmd{shutdown} checks whether the last ebtry in \sys{wtmp} is a shutdown entry.
If not, it assumed an abnormal shutdown occurred, and the \sys{fsck} utility is run to check all file systems.
The final job of \sys{/etc/rc} is to start daemons.
This may be done by subsidiary scripts.
If you look at the output of a \cmd{ps axl} command, which shows both PIDs and parent PIDs (PPIDs),
you will see that daemons such as \sys{update} and \sys{usyslogd} will normally be the among the first presisten processes
which are children of \sys{init}.

Finally \sys{init} reads the file \sys{/etc/ttytab}, which lists all potential terminal devices.
Those devices that can be used as login terminals 
(in the standard distribution, just the main console and up to three virtual consoles, 
but serial lines and network pseudo terminal can be added) 
have an entry in the \sys{getty} field of \sys{/etc/ttytab}, 
and \sys{init} forks off a child process for each such terminal.
Normally, each child executes \sys{/usr/bin/getty} which prints a message, then wait for a name to be typed.
If a particular terminal requires special treatment (e.g., a dial-up line) \sys{/etc/ttytab} can specify a command 
(such as \sys{/usr/bin/stty}) to be executed to initialize the line before running \sys{getty}.

When a user types a name to log in, \sys{usr/bin/login} is called with the name as its argument.
\sys{Login} determins if a password is required, and if so prompts for and verifies the password.
After a successful login, \sys{login} executes the user's shell (by default \sys{/bin/sh}, but another shell may be specified in the \sys{/etc/passwd}).
The shell wait for commands to be typed and then forks off a new process for each command.
In this way, the shells are the children of \sys{init}, the usr processes are granchildren of \sys{init},
and all the user processes in the system are part of a single tree.
In fact, except for the tasks compiled into the kernel and the process manager, all processes, 
both system processes and user processes, form a tree.
But unlike the process tree of a conventional UNIX system, \sys{init} is not the root of the tree,
and the structure of the tree does not allow one to determin the order in which system processes were started.

The two principal MINIX 3 system calls for process management are \cmd{fork} and \cmd{exec}.
\cmd{Fork} is the only way to create a new process.
\cmd{Exec} allows a process to execute a specified program.
When a program is executed, it is allocated a portion of memory whose size is specified in the program file's header.
It keeps this amount of memory throught its execution, 
although the distribution among data segment, stack segment, and unused can vary as the process runs.

All the information about a process is kept in the process table, which is divided up among the kernel, process manager, and file system,
with each one having those fields that it needs.
When a new process comes into existense (by \cmd{fork}),
or an old process terminates (by \cmd{exit} or a signal),
the process manager first updates its part of the process table and then sends messages to the file system and kernel telling them to do likewise.

\subsection{Interprocess Communication in MINIX 3}
Three primitives are provided for sending and receiving messages.
They are called by the C library procudures\\
\cmd{send (dest, \&message);}\\
to send a message to precess \sys{dest},\\
\cmd{receive (source, \&message);}\\
to receive a message from process \sys{source} (or \sys{ANY}), and\\
\cmd{sendrec (src\_dst, \&message);}\\
to send a message and wait for a reply from the same process.
The second parameter in each call is the local address of the message data.
The message passing mechanism in the kernel copies the message from the sender to the receiver.
The reply (for \cmd{sendrec}) overwrites the original message.  
In principle this kernel mechanism could be replaced by a function 
which copies messages over a network to a cerresponding function function on another mechine, to implement a distributed system.
In practice this would be complicated somewaht by the fact that
message contents sometimes include pointers to large data structures,
and a distributed system would have to provide for copying the data itself over the network.

Each task, driver or server process is allowed to exchange messages only with certain other processes.
Details of how this is enforced will be described later.
The usaul flow of message is downward in the layers of Fig. 2-29,
and messages can be between processes in the same layer or between processes in adjacent layers.
User processes cannot send messages to each other.
User processes in layer 4 can initiate message to servers in layer 3, servers in layer 3 can initiate messages to drivers in layer 2.

When a process sends a message to aprocess that is not currently waiting for a message,
the sender blocks until the destination does a \cmd{receive}.
In other words, MINIX 3 uses the rendezvous method to avoid the problems of buggering sent, but not yet received, messages.
The advantage of this approach is that it is simple and eliminates the need for buffer management (including the possibility of running out of buffers).
IN addition, because all messages are of fixed length determined at compile time,
buffer overrun errors, a common source of bugs, are structuarally prevented.

The basic purpose of the restrictions on exchanges of messages is that 
if process A is allowed to generate a \cmd{send} or \cmd{sendrec} directd to process B,
then process B can be allowed to call \cmd{receive} with A designated as the sender, but B should not be allowed to \cmd{send} to A.
Obviously, if A tries to \cmd{send} to B and blocks, and B tries to \cmd{send} to A and blocks we have a deadlock.
The ``resource'' that each would need to complete the operations is not a physical resource like an I/O device,
it is a call to \cmd{receive} by the target of the message.
We will have more to say about deadlock in Chap. 3.

Occasionally something different from a blocking message is needed.
There exists another important message-passing primitive.
It is called by the C library procedure\\
\cmd{notify (dest);}\\
and is used when a process needs to make another process aware that something important has happened.
A \cmd{notify} is nonblocking, which means the sender continues to execute whether or not the receipient is waiting.
Because it does bot block, a notification avoid the possibility of a message deadlock.

The message mechanism is used to deliver a notification, but the information conveyed is limited.
In the general case the message contains only the identity of the sender and a timestamp added by the kernel.
Sometimes this is all that is necessary.
For instance, the keyboard uses a \cmd{notify} call when one of the function keys (F1 TO F12 and shifted F1 to F12) is pressed.
In MINIX 3, function keys are used to trigger debugging dumps.
The Ethernet driver is an example of a process that generates only one kind of debug dump 
and never needs to get any other communication from the console driver.
Thus a notification to the Ethernet driver from the keyboard driver when the dump-Ethernet-states key is pressed is unambiguous.
In other cases a notification is not sufficient, 
but upon receiving a notification the target process can send a message to the originator of the notification to request more information.

There is a reason notification message are so simple.
Because a \cmd{notify} call does not block, it can be made when the recipient has not yet done a \cmd{receive}.
But the simplicity of the message means that a notification that cannot be received is easily stored 
so the recipient can be informed of it the next time the recipient calls \cmd{receive}.
In fact, a single bit suffices.
Notifications are meant for use between system processes, of which there can be only a relatively samll number.
Every system process has a bitmap for pending notifications, with a distinct bit for every system process.
So if process A needs to send a notification to process B at a time when process B is not blocked on a receive,
the message-passing mechanism sets a bit which corresponds to A in B's bitmap of pending notifications.
When B finally does a \cmd{receive}, the first step is to check its pending notifications bitmap.
It can learn of attempted notifications from multiple sources this way.
The single bit is enough to regenerate the information content of the notification.
It tells the identity of the sender, and the message passing code in the kernel adds the timestamp when it is delivered.
Timestamps are used primarily to see if timers have expired, 
so it does bot matter that the timestamp may be for a time later than the time when the sender first tried to send the notification. 

There is a further refinement to the notification mechanism.
In certain cases an additional field of the notification message is used.
When the notification is generated to inform a recipient of an interrupt, 
a bitmap of all possible sources of interrupts is included in the message.
And when the notification is from the system task a bitmap of all pending signals for the recipient is part of the message.
The natural question at this point is, 
how can this additional information be stored when the notification must be sent to a process that is not trying to receive a message?
The answer is that these bitmaps are in kernel data structures.
They do not need to be copied to be preserved.
If a notification must be deffered and reduced to seting a single bit, 
when the recipient eventually does a \cmd{receive} and the notification message is generated, 
knowing the origin of the notification is enough to specify which additional information needs to be include in the message.
And for the recipient, the origin of the notification also tells whether or not the message contains additional information,
and, if so, how it is to be interpreted.

A few other primitives related to interprocess communication exist.
They will be mentioned ina later section.
They are less important than \cmd{send}, \cmd{receive}, \cmd{sendrec}, and \cmd{notify}. 

\subsection{Processing Scheduling in MINIX 3}
The interrupt system is what keeps a multiprogramming operating system going.
Processes block when they make requests for input, allowing other processes to execute.
When input becomes available, the current running process is interrupted by the disk, keyboard, or other hardware.
The clock also generates interrupts that are used to make sure a running user process that has not requested input eventually relinquishes the CPU,
to give other processes their chance to run.
It is the job of the lowest layer of MINIX 3 to hide these interrupts by turning them into messages.
A far as processes are concerned, when an I/O device completes an operation it sends a message to some process, 
waking it up and making it eligible to run.

Interrupts are also generated by software, in which case they are often called \kw{traps}.
The \cmd{send} and \cmd{receive} operations that we described above are translated by the system library into \kw{software interrupt} instructions
which have exactly the same effect as hardware-generated interrupts.
The process that executes a software interrupt is immediately blocked and the kernel is activated to process the interrupt.
User programs do not refer to \cmd{send} or \cmd{receive} directly, but any time one of the system calls listed in Fig. 1-9 is invoked, 
either directly or by a library routine, \cmd{sendrec} is used internally and a software interrupt is generated.

Each time a process is interrupted (whether by a conventional I/O device or by the clock) or due to execution of a software interrupt instruction,
there is an opportunity to redetermin which process is most deserving of an opportunity to run.
Of course, this must be done whenever a process terminates, as well, but in a system like MINIX 3 interruptions due to I/O operations 
or the clock or message passing occur more frequently than process termination.

The MINIX 3 shceduler uses a multilevel queueing system.
Sixteen queues are defined, although recompiling to use more or fewer queue is easy.
The lowest priority queue is used only by the \sys{IDLE} process which runs when there is nothing else to do.
User processes start by default in a queue several levels higher than the lowest one.

Severs are normally scheduled in queues with priorities higher than alloed allowed for user processes,
drivers in queues with priorities higher than those of servers, and clock and system tasks are shceduled in the highest priority queue.
Not all of the sixteen available queues are likely to be in use at any time.
Processes are started in only a few of them.
A process may be moved to a different priority queue by the system or (with certain limitis) by a user who invokes the \sys{nice} command.
The extra levels are available for experimentation, and as additional drivers are added to MINIX 3 
the default settings can be adjusted for best performance.
For instance, if it were desired to add a server to stream digital audio or video to a network,
such a server might be assigned a higher starting priority than current servers,
or the initial priority of a current server or driver might be reduced in order for the new server to achieve bettern performance.

In addition to the priority determined by the queue on which a process is paced, 
another mechanism is used to give some processes an edge over others.
The quantum, the time interval allowed before a process is preempted, is not the same for all processes.
User processes have a relatively low quantum.
Drivers and servers normally should run until they block.
However, as a hedge against malfunction they are made preemptable, but are given a large quantum.
They are allowed to run for a large but finite number of clock ticks,
but if they use their entire quantum they are preempted in order not to hang the system.
In such a case the time-out process will be considered ready, and can be put on the end of its queue.
However, if a process that has used up its entire quantum is found to have been the process that ran last, 
this is taken as a sign it may be stuck in a loop and preventing other processes with lower priority from running.
In this case its priority is lowered by putting it on the end of a lower priority queue.
If the process times out again and another process still has not been able to run, its priority will again be lowered.
Eventually, something else should get a chance to run.

A process that has been demoted in priority can earn its way back to a higher priority queue.
If a process uses all its quantum but is not preventing other processes from running it will be promoted to a higher priority queue,
up to the maximum priority permitted for it.
Such a process apparently needs its quantum, but is not being inconsiderate of others.

Otherwise, processes are shceduled using a slightly modified round robin.
If a process has not used its entire quantum when it becomes unready,
this is taken to mean that it blocked waiting for I/O, and when it becomes ready again it is put one the head of the queue,
but with only the left-over part of its previous quantum.
This is intended to give user processes quick response to I/O.
A process that become unready because it used its entire quantum is placed at the end of the queue in pure round robin fashion.

With tasks normally having the highest priority, drivers next, servers below drivers, and user processes last, 
a user process will not run unless all system processes have nothing to do,
and a system process cannot be prevented from running by a user process.

When picking a process to run, the sheduler checks to see if any processes are queued in the highest priority queue.
If one or more are ready, the one at the head of the queue is run.
If none is ready the next lower priority queue is similarly tested, and so on.
Since drivers response to requests from servers and servers respond to requests from user processes,
eventually all high priority processes should complete whatever work was requested of them.
They will then block with nothing to do until user processes get a turn to run and make more requests.
If no process is ready, the \sys{IDLE} process is chosen.
This puts the CPU in a low-power mode until the next interrupt occurs.

At each clock tick, a check is made to see if the current process has run for more than its allocatted quantum.
If it has, the scheduler moves it to the end of its queue (which may require do nothing if it is alone on the queue).
Then the next process to run is picked, as described above.
Only if there are no proceses on high-priority queue and if the previous process is alone on its queue will it get run again immediately.
Otherwise the process at the head of the highest priority nonempty queue will run next.
Essential drivers and servers are given such large quanta that normally they are normally never preempted by the clock.
But something goes wrong their priority can be temporarily lowered to prevent the system from coming to a total standstill.
Probably nothing useful can be done if this happens to an essential server,
but it may be possible to shut the system down gracefully,
preventing data loss and possibly collecting information that ...

\section{Implementation of Processes in MINIX 3}
We are now moving closer to look at the actual code,
so a few words about the nonation we will use are perhaps in order.
The term ``procedure'', ``function'', and ``rotine'' will be used interchangeably.
Name of variables, procedures, and files will be written in italics, as in \textit{rw\_flag}.
When a variable, procedure, or file name starts a sentense, it will be capitalized, but the actual names begin with lower case letters.
There are a few exceptions, the tasks which are compiled into the kernel are identified by upper case names, 
such as \sys{CLOCK}, \sys{SYSTEM}, and \sys{IDLE}.
System calls will be in lower case Helvetica, for example, \cmd{read}.

The book and software, both of which are continuously evolving, did not ``go to press'' on the same day, 
so there may be minor discrepancies between the references to the code, the printed listing, and the CD-ROM version.
Such differences generally only affect a line or two, however.
The source code printed in the book has been simplified by omitting code used to compile options that are not discussed in the book.
The complete version is on the CD-ROM.
The MINIX 3 Web Site (\www{www.minix3.org}) has the current version, which has new features and additional software and documentation.

\subsection{Organization of the MINIX 3 Source Code}
The implementation of MINIX 3 as described in this book is for an IBM PC-type machine with an advanced processor chip
(e.g., 80386, 80486, Pentium , Pentium Pro, II, III, 4, M or D) that uses 32-bit words.
We will refer to all of these as Intel 32-bit processors.
The full path to the C language source code on a standard Intel-based platform is \sys{/usr/src} 
(a trailing ``/'' in a path name indicates that it refers to a directory).
The source directory tree for other platforms may be in a different location.
Throughout the book, MINIX 3 source code files will be referred to using a path starting with the top \sys{src/} directory.
An important subdirectory of the source tree is \sys{src/include},
where the master copy of the C header files are located.
We will refer to this directory as \sys{include/}.

Each directory in the source tree contains a file named \kw{Makefile} which directs the operation of the UNIX-standard \sys{make} utility.
The \sys{Makefile} controls compilation of files in its directory and may also direct compilation of files in one or more subdirectories.
The operation of \sys{make} is complex and a full description is beyond the scope of this section,
but it can be summarized by saying that \sys{make} manages efficient compilation of programs involving multiple source files.
\sys{Make} assures that all necessary files are compiled.
It tests previously compiled modules to see if they are up to data 
and recompiles any whose source file have been modified since the previous compilation.
This saves time by avoiding recompilation of files that do not need to be recompiled.
Finally, \sys{make} directs the compilation of separately compiled modules into an executable program 
and may also manage installation of the completed program.

Al  or part of the \sys{src/} tree can be relocated, since the \sys{Makefile} in each source directory uses a relative path to C source directories.
For instance, you may want to make a source directory on the root filesystem, \sys{/src/},
for speedy compilation if the root device ia a RAM disk.
If you are developing a special version you can make a copy of \sys{src/} under another name.

The path to the C header files is a special case.
During compilation every \sys{Makefile} expects to find header file in \sys{/usr/inclu} (or the equivalent path on a non-Intel platform).
However, \sys{src/tools/Makefile}, used to recompile the system, 
expects to find a master copy of the headers in \sys{/usr/src/include} (on an Intel system).
Before recompiling the system, however, the entire \sys{/usr/include} directory tree is detected 
and \sys{/usr/src/include} is copied to \sys{/usr/include}.
This was done to make it possible to keep all files needed in the development of MINIX 3 in one place.
This also makes it easy to maintain multiple copies of the entire source and headers trees 
for experimenting with different configurations of the MINIX 3 system.
However, if you want to edit a header file as part of such experiment, 
you must be sure to edit the copy in the \sys{/src/include} directory and not one in \sys{/src/include}.

This is a good place to point out for newcomers to the C language how file names are quoted in a \cmd{\#include} statement.
Every C compiler has a default directory where it looks for include files.
Frequently, this is \sys{/usr/include}.
When the name of a file to include is quoted between less-than and great-than symbols (``<...>'') then the compiler searches for the file in the default header directory or a specified subdirectory, for example,\\
\cmd{\#include <filename>}\\
include a file from \sys{/usr/include}.

Many program also require definations in local header files that are not meant to be shared system-wide.
Such a header may have the same name as and be meant to replace or supplement a standard header.
When the name is quoted between ordinary quote characters (\cmd{"..."}) the file is searched for first in the same directory as the source file
(or a specified subdirectory) and then, if not found there, in the default directory.
Thus\\
\cmd{\#include "filename"}\\
reads a local file.

The \sys{include/} directory contains a number of POSIX standard header files.
In addition, it has three subdirectories:\\
\sys{sys/}		additional POSIX headers.\\
\sys{minix/}	header files used by the MINIX 3 operating system.\\
\sys{ibm/}		header files with IBM PC-specific definitions.

To support extensions to MINIX 3 and programs that run in the MINIX 3 environment, 
other files and subdirectories are also present in \sys{include/} as provided on the CD-RON and also on the MINIX 3 Web site.
For instance, \sys{include/arpa/} and the \sys{include/net/} directory and its subdirectory \sys{include/net/gen/} support network extensions.
These are not necessary for compiling the basic MINIX 3 system,
and files in these directories are not listed in Appendix B.

In addition to \sys{src/include}, the \sys{src/} directory contains three other important subdirectories with operating system source code:\\
\sys{kernel/}    layer 1 (scheduling, messages, clock and system tasks).\\
\sys{drivers/}   layer 2 (device drivers for disk, console, printer, etc.).\\
\sys{servers/}   layer 3 (process manager, file system, other servers).

Three other source code directories are not printed or discussed in the next, but are essential to producing a working system:\\
\sys{src/lib/}    source code for library procedures (e.g., open, read).\\
\sys{src/tools/}  Makefile and scripts for building the MINIX 3 system.\\
\sys{src/boot/}   the code for booting and installing MINIX 3. 

The standard distribution of MINIX 3 includes many additional source files not discussed in this text.
In addition to the process manager and file system source code,
the system source directory \sys{src/servers/} contains source code for the \sys{init} program and the reincarnation server, 
\sys{rs}, both of which are essential parts of a running MINIX 3 system.
The network server source code is in \sys{src/servers/inet}.
\sys{Src/drivers/} has source code for device drivers not discussed in this text,
including alternative disk drivers, sound cards , and network adapters.
Since MINIX 3 is an experimental operating system, meant to be modified, 
there is a \sys{src/test} directory with programs designed to test thoroughly a newly compiled MINIX 3 system.
An operating system exists, of course, to support commands (programs) that will run on it,
so there is a large \sys{src/commands/} directory with source code for the utility programs 
(e.g., \sys{cat}, \sys{cp}, \sys{date}, \sys{ls}, \sys{pwd} and more than 200 others).
Source code for some major open source applications originally developed by the GNU and BSD projects is here, too.

The ``book'' version of MINIX 3 is configured with many of the optional parts ommitted 
(trust us: we cannot fit everything into one book or into your head in a semester-long course).
The ``book'' version is compiled using modified \sys{Makefile}s that do not refer to unnecessary files.
(A standard \sys{Makefile} requires that files for optional cpmponents be present, even if not to be compiled.)
Ommitting these files and the conditional statements that select them makes reading the code easier.

For convennience we will usually refer to simple file names when it is clear from the contex what the complete path is.
However, be aware that some file names appear in more than one directory.
For instance, there are several files named \sys{const.h}.
\sys{src/kernel/const.h} defines constants used in the kernel, 
while \sys{src/servers/pm/const.h} defines constants used by the process manager, etc.

The files in a particular directory will be discussed together,
so there should not be any confusion.
The files are listed in Appendix B in the order they are discussed in the text, to make it easy to follw along.
Acquisition of a couple of bookmarks might be of use at this point,
so you can go back and forth between the text and the listing.
To keep the size of the listing reasonable, code for every file is not printed.
In general, those functions that are described in detail in the text are listed in Appendix B;
those that are just mentioned in passing are not listed, but the complete source code is on the CD-ROM and Web site,
both of which also provide an index to functions, definitions, and global variables in the source code.

Appendix C contains an alphabetical list of all files described in Appendix B, i
divided into sections for headers, drivers, kernel, file system, and process manager. 
This appendix and Web site and CD-ROM indices reference the listed objects by line number in the source code.

The code for layer 1 is contained in the directory \sys{src/kernel}.
Files in this directory support process control, the lowest layer of the MINIX 3 structure we saw in Fig. 2-29.
This layer includes functions which handle system initialization, interrupts, message passing and process shceduling.
Itimately connected with these are two modules compiled into the same binary,
but which run as independent processes.
These are the system task which provides an interface between kernel services and processes in high layers,
and the clock task which providing timing signals to the kernel.
In Chap. 3, we will look at files in several of the subdirectories of \sys{src/drivers}, which support various device drivers,
the second lyer in Fig. 2-29.
Then in Chap. 3, we will look at the process manager files in \sys{src/servers/pm/}.
Finally, in Chap. 5, we will study the file system, whise source files are located in \sys{src/servers/fs}.

\subsection{Compiling and Running MINIX 3}
To compile MINIX 3, run \cmd{make} in \sys{src/tools/}.
There are several options, for installing MINIX 3 in different ways.
To see the possibilities run \cmd{make} with no argument.
The simplest methods is \cmd{make image}.

When \cmd{make image} is executed, a fresh copy of the header files in \sys{src/include/} is copied to \sys{/usr/include}.
Then source code files in \sys{src/kernel/} and several subdirectories of \sys{src/servers} and \sys{src/drivers} are compiled to object files.
All the object files in \sys{src/kernel} are linked to form a single executable program, \sys{kernel}.
The object files in \sys{src/servers/pm/} are also linked to form a single executable program, \sys{pm},
and all the object files in \sys{src/servers/fs} are linked to form \sys{fs}.
The additional program listed are part of the boot image in Fig. 2-30 are also compiled and linked in their own directories.
These includes \sys{rs} and \sys{init} in subdirectories of \sys{src/servers} 
and \sys{memory/}, \sys{log/}, and \sys{tty} in subdirectories of \sys{src/drivers}.
The component designated ``driver'' in Fig. 2-30 can be one of several disk drivers;
we discuss here a MINIX 3 system configured to boot from the hard disk using the standard \sys{at\_wini} driver, 
which will be compiled in \sys{src/drivers/at\_wini/}.
Other drivers can be added, but most drivers need not be compiled into the boot image.
The same is true for networking support;
compilation of the basic MINIX 3 system is the same whether or not networking will be used.

To install a working MINIX 3 system capable of being booted, 
a program called \sys{installboot} (whose source is in \sys{src/boot/}) adds names to \sys{kernel}, 
\sys{pm}, \sys{fs}, \sys{init}, and other components of the boot image,
pads each one out so that its length is a multiple of the disk sector size 
(to make it easier to load the parts independently), and concatenates them onto a single file.
This new file is the boot image and can be copied into the \sys{/boot/} directory or 
the \sys{/boot/image/} directory of a floppy disk or a hard disk partion.
Later, the boot monitor program can load the boot image and transfer control to the operating system.

Fig. 2-31 shows the layout of memory after the concatenated programs are separated and loaded.
The kernel is loaded in low memory, all the other parts of the boot image are loaded above 1 MB.
When user programs are run, the available memory above the kernel will be used first.
When a new program will not fit there, it will be loaded in the high memory range, above \sys{init}.
Details, of course, depend upon the system configuration.
For instance, the example in the figure is for a MINIX 3 file system configured with a block cached that can hold 512 4-KB disk blocks.
This is a modest amount; more is recommended if adequate memory is available. 
On the other hand, if the size of the block cache were reduced drastically 
it would be possible to make the entire system fit into less than 640K of memory,
with room for a few user processes as well.

It is important to realize that MINIX 3 consists of several totally independent programs that communicate only by passing messages.
A procedure called \sys{panic} in the directory \sys{src/servers/fs/} dose not conflict with
a procedure called \sys{panic} in \sys{src/servers/pm/} because they ultimately are linked into different executable files.
The only procedures that the three pieces of the operating system have in commom are afew of the library routines in \sys{src/lib/}.
This modular structure makes it very easy to modify, say, the file system, without having these changes affect the process manager.
It also makes it straightforward to remove the file system altogether and to put it on a different machine as a file server,
communicating with user machines by sending messages over a network.

As another example of the modularity of MINIX 3, adding network support makes absolutely no difference to the process manager,
the file system, or the kernel.
Both an Ethernet driver and the \sys{inet} server can be actived after the boot image is loaded;
they would appear in Fig. 2-30 with the processes started by \sys{/etc/rc},
and they would be loaded into one of the ``Memory available for user programs'' region of Fig. 2-31.
A MINIX 3 system with networking enabled can be used as a remote terminal or an ftp and web server.
Only if you want to allow incoming logins to the MINIX 3 system over the network would any part of MINIX as described in the text need modification:
this is \sys{tty}, the console driver, which would need to be recompiled with pseudo terminals configured to allow remote logins.

\subsection{The Common Header Files}
The \sys{include/} directory and its subdirectories contain a collection of files defining constants, macros, and types.
The POSIX standard requires many of these definitions and specifies in which files of the main \sys{include/} directory 
and its subdirectory \sys{include/sys/} each required definiation is to be found.
The files in these directories are \kw{header} or \kw{include} files,
identified by the suffix .h, and used by means of \cmd{\#include} statements in C source files.
These statements are a built-in feature of the C language.
Include files make maintanance of a large system easier.

Headers likely to be needed for compiling user programs are mainly found in \sys{include/} 
whereas \sys{include/sys/} traditonally is used for files that are used primarily for compiling system programs and utilities.
The distinction is not terribly important, and a typical compilation, whether of a user program or part of the operating system, 
will include files from both of these directories.
We will discuss here the files that are needed to compile the standard MINIX 3 system, 
first treating those in \sys{include/} and then those in \sys{include/sys/}.
In the next section we will discuss files in the \sys{include/minix/} and \sys{include/ibm/} directories, 
which, as the directory names indicate, are unique to MINIX 3 and its implementation on IBM-type (really, Intel-type) computers.

The first headers to be considered are truly general purpose ones, 
so much so that they are not referenced directly by any of the C language source files for the MINIX 3 system.
Rather, they are themselves included in other header files.
Each major component of MINIX 3 has a master header file, 
such as \sys{src/kernel/kernel.h}, \sys{src/servers/pm/pm.h}, and \sys{src/servers/fs/fs.h}.
These are included in every compilation of these components.
Source code for each of the device drivers includes a somewhat similar file, \sys{src/drivers/drivers.h}.
Each master header is tailored to the needs of the corresponding part of the MINIX 3 system,
but each one starts with a section like the one shown in Fig. 2-32 and includes most of the files shown there.
The master headers will be discussed again in other sections of this book.
This preview is to emphasize that headers from several directories are used together.
In this section and the next one we will mention each of the files referenced in Fig. 2-32.

Let us start with the first header in \sys{include/}, \sys{ansi.h} (line 0000).
This is the second header that is processed whenever any part of the MINIX 3 system is compiled;
only \sys{include/minix/config.h} is processed earlier.
The purpose of \sys{ansi.h} is to test whether the compiler meets the requirements of Standard C,
as defined by the International Organization for Standards.
Standard C is also often referred to as ANSI C,
since the standard was originally developed by the American National Standards Institute before gaining the international recognition.
A Standard C compiler defines several macros that can then be tested in programs being compiled.
\sys{\_\_STDC\_\_} is such a macro, and it is defined by a standard compiler to have a value of 1, 
just as if the C preprocessor had read a line like\\
\cmd{\#define\_\_STDC\_\_1}

The compiler distributed with current current versions of MINIX 3 conforms to Standard C,
but older version of MINIX were developed before the adoption of the standard,
and it is still possible to compile MINIX 3 with a classic (Kernighan \& Ritchie) C compiler.
It is intended that MINIX 3 should be easy to port to new machines,
and allowing older compilers is part of this.
At lines 0023 to 0025 the statement\\
\cmd{\#define \_ANSI}\\
is processed if a Standard C compiler is in use.
\sys{ansi.h} defines several macros in different ways,
depending upon whether the \sys{\_ANSI} macro is defined.
This is an example of a \kw{feature test macro}.

Another feature test macro defined here is \sys{\_POSIX\_SOURCE}(line 0065).
This is required by POSIX.
Here we ensure it is defined if other macros that imply POSIX comformance are defined.

When compiling a C program the data types of the arguments and the returned values of functions must be known before code 
that references such data can be generated.
In a complex system ordering of function definitions to meet this requirement is difficult,
so C allows use of \kw{function prototypes} to \kw{declare} the arguments and return value types of a function before it is \kw{defined}.
The most important macro in \sys{ansi.h} is \sys{\_PROTOTYPE}.
This macro allows us to write function prototypes in the form\\
\cmd{\_PROTOTYPE (return-type function-name, (argument-type argument, ...))}\\
and have this transformed by the C preprocessor into\\
\cmd{return-type function-name (argument-type, argument, ...)}\\
if the compiler is an ANSI Standard C compiler, or\\
\cmd{return-type function-name ()}\\
if the compiler is an old-fashioned (i.e., Kernighan \& Ritchie) compiler.

Before we leave \sys{ansi.h} let us mention one additional feature.
The entire file (except for initial comments) is enclosed between lines that read\\
\cmd{\#ifndef \_ANSI\_H}\\
and\\
\cmd{\#endif /* \_ANSI\_H */}

On the line immediately following the \cmd{\#ifndef \_ANSI\_H} itself is defined.
A header file should be included only once in a compilation;
this construction ensurs that the contents of the file will be ignored if it is included multiple times.
We will see this technique used in all the header files in the \sys{include/} directory.

Two points about this deserve mention.
First, in all of the \cmd{\#ifndef ... \#define} sequences for files in the mater header directories,
the filename is preceded by an underscore,
Another header with the same name may exist within the C source code directories,
and the same mechanism will be used there, but underscores will not be used.
Thus inclusion of a file from the master header directory will not prevent processing of another header file with the same name in local directory.
Second, note that the comment \cmd{/* \_ANSI\_H */} after the \cmd{\#ifndef} is not required.
Such comments can be helpful in keeping track of nested \cmd{\#ifndef ... \#endif} and \cmd{\#ifdef ... \#endif} sections.
However, care is needed in writing such comments: if incorrect they are worse than no comment at all.

The second file in \sys{include/} that is indirectly included in most MINIX 3 source files is the \sys{limits.h} header (line 0100).
The file defines many basic sizes, both language types such as the number of bits in an integer,
as well as operating system limits such as the length of a file name.

Note that for convenience, the line numbering in Appendix B is ratcheted up to the next multiple of 100 when a new file is listed.
Thus do not expect \sys{ansi.h} contain 100 lines (00000 through 00099).
In this way, small changes to one file will (probably) not affect subsequent files in a revised listing.
Also note that when a new file is encountered in the listing,
a special three-line header consisting of a row of + signs, the file name, and another row of + signs is present (without line numbering).
An example of this header is shown between lines 00068 and 00100.

\sys{Errno.h} (line 0200), is also included by most of the master headers.
It contains the error numbers that are returned to user programs in the global variable \sys{errno} when a system call fails.
\sys{Errno} is also used to identify some internal errors, 
such as trying to send a message to a nonexistent task.
INternally, it would be inefficient to examine a global variable after a call to a function
that might generate an error, but functions must often return other integers,
for instance, the number of bytes transferred during an I/O operation.
The MINIX 3 solution is to return error numbers as negtive value to mark them as error codes within the system,
and then to convert them to positive values before being returned to user programs.
The trick that is used is that each error code is defined in a line like \\
\cmd{\#define EPERM (\_SIGN 1)}\\
(line 0236).
THe master header file for each part of the operating system defines the \sys{\_SYSTEM} macro, 
but \sys{\_SYSTEM} is never defined when a user program is compiled.
If \sys{\_SYSTEM} is defined, then \sys{\_SIGN} is defined as ``-''; otherwise it is given a null definition.

The next group of files to be considered are not included in all the master headers,
but are nevertheless used in many source files in all parts of the MINIX 3 system.
The most important is \sys{unistd.h} (line 0400).
THis header defines many constants, most of which are required by POSIX.
In addition, it includes prototypes for many C functions,
including all those used to access MINIX 3 system calls.
Another widely used file is \sys{string.h} (line 0600),
which provides prototypes for many C functions used for string manipulation.
The header \sys{signal.h} (line 0700) defines the standard signal names.
Several MINIX 3-SPECIFIC signals for operating system use are defined, as well.
The fact that 
operating systems functions are handle by independent processes rather than within a monolitic kernel
requires some special signal - like communication between the system components.
\sys{Signal.h} also contains prototypes for some signal-related functions.
As well will see later, signal handling involves all parts of MINIX 3.

\sys{Fcntl.h} (line 0900) symbolically defines many parameters used in file control operations.
For instance, it allows one to use the macro \sys{O\_RDONLY} instead of the numeric value 0 as a parameter to a \sys{open} call.
Although this file is referenced mostly by the file system,
its definitions are also needed in a number of places in the kernel and the process manager.

As we will see when we look at the device driver layer in Chap. 3,
the console and terminal interface of an operating system is complex,
because many different types of hardware have to interact with the operating system and user programs in a standardized way.
\sys{Termios.h} (line 1000) defines constants, macros, and function prototypes 
used for control of terminal-type I/O devices.
The most important structure is the \sys{termios} structure.
It contains flags to signal various modes of operation,variables to set input and output transmission speeds,
and an array to hold special special characters (e.g., the \sys{INTR} and \sys{KILL} characters).
This structure is required by POSIX,
as are many of the macros and function prototypes defined in this file.

However, as all-encompassing as the POSIX standard is meant to be, it does not provide everything one might want,
and the last part of the file, from line 1140 onward, provides extensions to POSIX.
Some of these are of obvious value, such as extensions to define standard baud rates of 57,600 baud and higher,
and support for terminal dispaly screen windows.
The POSIX standard does not forbid extensions, as no reasonable standard can ever be all-inclusive.
But when writing a program in MINIX 3 environment which is intended to portable to other envionments, 
some caution is required to avoid the use of definitions specific to MINIX 3.
This is fairly easy to do.
In this file and other files that define MINIX 3-specific extensions the use of the extensuins is controlled by the \\
\cmd{\#ifdef \_MINIX}\\
statement.
If the macro \sys{\_MINIX}is not defined, the compiler will not even see the MINIX 3 extensions;
they will all be completely ignored.

Watchdog timers are supported by \sys{timer.h} (line 1300),
which is included in the kernel's master header.
It defines a \sys{struct} timer, as well as prototypes of functions used to operate on lists of timers.
On line 1321 appears a \sys{typedef} for \sys{tmr\_func\_t}.
This data type is a pointer to a function.
At line 1332 its use is seen: within a \sys{timer} structure, used as an element in a list of timers,
one element is a \sys{tmr\_func\_t} to specify a function to be called when the timer expires.

We will mention four more files in the \sys{include/} directory that are not listed in Appendix B.
\sys{Stdlib.h} defines types, macros, and function prototypes 
that are likely to be needed in the compilation of all but the most simple of C programs.
It is one of the most frequently used headers in compiling user programs,
although within the MINIX 3 system source it is referenced by only a few files in the kernel.
\sys{Stdio.h} is familiar to everyone who has started to learn programming in C by writing the famous  ``Hello World!'' program.
A \sys{out.h} defines the format of the files in which executable programs are stored on disk.
An \sys{exec} structure is defined here, and the information in this structure is used by the process manager 
to load a new program image when an \cmd{exec} call is made.

New let us go on to the subdirectory \sys{include/sys}.
As shown in Fig. 2-32, the master headers fo rthe main parts of the MINIX 3 system 
all cause \sys{sys/type.h} (line 1400) to be read immediately after reading \sys{ansi.h}.
\sys{sys/types.h} defines many data types used in MINIX 3.
Errors 
that could arise from misunderstanding which fundamental data types are used in a particular situation 
could avoided by using the definiations provided here.
Fig2. 33 shows the way the sizes, in bits, of a few types defined in this file differ when compiled for 16-bit or 32-bit processor.
Note that all type names end with ``\_t''. 
This is not just a convention; it is a requirement of the POSIX standard.
This is an example of a \kw{reserved suffix},
and ``\_t'' should not be used as a suffix of any name which is not a type name.

MINIX 3 currently runs natively on 32-bit microprocessors, but 64-processors will be increasingly important in the future.
A type that is not provided by the hardware  can be synthesized if necessary.
On line 1471 the \sys{u64\_t} is defined as \cmd{struct \{u32\_t[2]\}}.
This type is not needed very often in the current implementation, but it can be useful.
For instance, all disk and partition data (offsets and sizes) is tored as 64 bit numbers,
allowing for very large disks.

MINIX 3 uses many type definitions
that ultimately are interpreted by the compiler as a relatively small number of common types.
This is intended to help make the code more readable;
for instance, a variable declared as the type \sys{dev\_t} is recognizable as a variable meant to hold the major and minor device number
that identify an I/O device.
For the compiler, declaring such a variable as a \sys{short} would work equally well.
Another thing to note is that many of the types defined here are matched by corresponding types with the first letter capitalized,
for instance, \sys{dev\_t} and \sys{Dev\_t}.
The capitalized variants are all equivalent to type \sys{int} to the compiler;
these are provided to be used in function prototypes which must use types compatible with the \sys{int} type to support K\&R compilers.
The comments in \sys{type.h} explain this in more detail.

One other item worth mention is the section of conditional code that starts with\\
\cmd{\#if \_EM\_WSIZE == 2}\\
(line 1502 to 1516).
As noted earlier, most conditional code has been removed from the source as discussed in the text.
This example was retained so we could point out one way that conditional definitions can be used.
The macro used , \sys{\_EM\_WSIZE}, is another example of a compiler-defined feature test macro.
It tells the word size for the target system in bytes.
The \cmd{\#if ... \#else ... \#endif} sequence is a way of getting some definitions right once and for all,
to make subsequent code compile correctly whether a 16-bit or 32-bit system is in use.

Several other files in \sys{include/sys/} are widely used in the MINIX 3 system.
The file \sys{sys/sigcontext.h} (line 1600) defines structures 
used to preserve and restore normal system operation before and after execution of a signal handling routine 
and is used both in the kernel and the process manager.
\sys{Sys/stat.h} (line 1700) defines the structure which we see in Fig. 1-12,
returned by the \cmd{stat} and \cmd{fstat} system calls,
as well as the prototypes of the functions \sys{stst} and \sys{fstat} 
and other functions used to manipulate file properties.
It is referenced in several parts of the file system and the process manager.

Other files we will disscuss in this section are not as widely referenced as the ones discussed above.
\sys{Sys/dir.h} (line 1800) defines the structure of a MINIX 3 directory entry.
It is only referenced directly once, but this reference includes it in another header that widely used in the file system.
It is important because, among other things, it tells how many characters a file name may contain (60).
The \sys{sys/wait.h} (line 1900) header defines macros used by the \cmd{wait} and \cmd{waitpid} system calls,
which are implemented in the process manager.

Several other files in \sys{include/sys/} should be mentioned, although they are not listed in Appendix B.
MINIX 3 supports tracing executables and analyzing core dumps with a debugger program,
and \sys{sys/ptrace.h} defines the various operations possible with the \cmd{ptrace} system call.
\sys{Sys/svrctl.h} defines data structures and macros used by \cmd{svrctl},
which is not really a system call, but is used like one.
\cmd{Svrctl} is used to coordinate server-level processes as the system starts up.
The \cmd{select} system call permits waiting for input on multiple channels,
for instance, pseudo terminals waiting for network connections.
Definitions needed by this call are in \sys{sys/select.h}.

We have deliberately left duscussion of \sys{sys/ioctl.h} and related files until last,
because they cannot be fully understood without also looking at file in the next directory, \sys{minix/ioctl.h}.
The \cmd{ioctl} system call is used for device control operations.
The number of devices which can be interfaced with a modern computer system is ever increasing.
All need various kind of control.
Indeed, the main difference between MINIX 3 as described in this book and other versions is that
for purposes of the book we describe MINIX 3 with relatively few input/output devices.
Many others, such as network interfaces, SCSI controllers, and sound cards, can be added.

To make things more managerable, a number of small files, each containing one group of definitions, are used.
They are all included by \sys{sys/ioctl.h} (line 2000), which functions similarly to the master header of Fig. 2-32.
We have listed only one of these included files, \sys{sys/ioc\_disk.h} (line 2100), in Appendix B.
This and the other files included by \sys{sys\_ioctl.h} are located in the \sys{include/sys/} directory
because they are considered part of the ``published interface'',
meaning a programmer can use them in writing any program to be run in the MINIX 3 environment.
However, they all depend upon additional macro definitions provided in \sys{minix/ioctl.h} (line 2200), which is included by each.
Minix/ioctl.h should not be used by itself in writing programs,
which is why it is in \sys{include/minix/} rather than \sys{include/sys/}.

The macros defined together by these files define 
how the various elements needed for each possible function are picked into a 32 bit integer to be passed to \cmd{ioctl}.
For instance, disk devices need five types of operations, as can be seen in \sys{sys/ioc\_disk.h} at lines 2110 to 2114.
The alphabetic 'd' parameter tells \cmd{ioctl} that the operation is for a disk device,
an integer from 3 through 7 codes for the operation,
and the third parameter for a write or read operation tells the size of the structure in which data is to be passed.
In \sys{minix/ioctl.h} lines 2225 to 2231 show that 8 bits of the alphabetic code are shifted 8 bits to the left,
the 13 least significant bits of the size of the structure are shifted 16 bits to the left,
and these are then logically ANDed with the small integer operation code.
Another code in the most significant 3 bits of a 32-bit number encodes the type of return value.

Although this look like a lot of work,
this work is done at compile time and makes for a much more efficient interface to the system call at run time,
since the parameter actually passed is the most natural data type for the host machine CPU.
It does, however, bring to mind a famous comment Ken Thompson put into the source code of an early version of UNIX:\\
/*You are not expected to understand this*/

\sys{Minix/ioctl.h} also contains the prototype for the \cmd{ioctl} system call at line 2241.
This call is not directly invoked by programmers in many case,
since the POSIX defined functions prototyped in \sys{include/termios.h} 
have replaced many uses of the old \sys{ioctl} library function for dealing with terminals, consoles, and similar devices.
Nevertheless, it is still necessary.
In fact, the POSIX functions for control of terminal devices are converted into \cmd{ioctl} system calls by the library.


 






























%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%r
\end{document}

